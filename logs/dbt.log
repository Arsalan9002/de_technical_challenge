2021-06-03 10:44:49.246636 (MainThread): Running with dbt=0.19.1
2021-06-03 10:44:50.571787 (MainThread): running dbt with arguments Namespace(cls=<class 'dbt.task.run.RunTask'>, debug=False, defer=None, exclude=None, fail_fast=False, full_refresh=False, log_cache_events=False, log_format='default', models=None, partial_parse=None, profile=None, profiles_dir='/Users/mac/.dbt', project_dir=None, record_timing_info=None, rpc_method='run', selector_name=None, single_threaded=False, state=None, strict=False, target=None, test_new_parser=False, threads=None, use_cache=True, use_colors=None, vars='{}', version_check=True, warn_error=False, which='run', write_json=True)
2021-06-03 10:44:50.573599 (MainThread): Tracking: tracking
2021-06-03 10:44:50.585656 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ff7a701b250>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ff7a701b490>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ff7a701b190>]}
2021-06-03 10:44:50.611316 (MainThread): Partial parsing not enabled
2021-06-03 10:44:50.627322 (MainThread): Parsing macros/etc.sql
2021-06-03 10:44:50.644206 (MainThread): Parsing macros/catalog.sql
2021-06-03 10:44:50.662263 (MainThread): Parsing macros/adapters.sql
2021-06-03 10:44:50.700326 (MainThread): Parsing macros/materializations/seed.sql
2021-06-03 10:44:50.705899 (MainThread): Parsing macros/materializations/view.sql
2021-06-03 10:44:50.711790 (MainThread): Parsing macros/materializations/table.sql
2021-06-03 10:44:50.726578 (MainThread): Parsing macros/materializations/copy.sql
2021-06-03 10:44:50.734523 (MainThread): Parsing macros/materializations/incremental.sql
2021-06-03 10:44:50.752567 (MainThread): Parsing macros/materializations/snapshot.sql
2021-06-03 10:44:50.759853 (MainThread): Parsing macros/core.sql
2021-06-03 10:44:50.768789 (MainThread): Parsing macros/materializations/helpers.sql
2021-06-03 10:44:50.782470 (MainThread): Parsing macros/materializations/snapshot/snapshot_merge.sql
2021-06-03 10:44:50.786390 (MainThread): Parsing macros/materializations/snapshot/strategies.sql
2021-06-03 10:44:50.811721 (MainThread): Parsing macros/materializations/snapshot/snapshot.sql
2021-06-03 10:44:50.857794 (MainThread): Parsing macros/materializations/seed/seed.sql
2021-06-03 10:44:50.937207 (MainThread): Parsing macros/materializations/incremental/helpers.sql
2021-06-03 10:44:50.951497 (MainThread): Parsing macros/materializations/incremental/incremental.sql
2021-06-03 10:44:50.963506 (MainThread): Parsing macros/materializations/common/merge.sql
2021-06-03 10:44:50.983616 (MainThread): Parsing macros/materializations/table/table.sql
2021-06-03 10:44:50.995527 (MainThread): Parsing macros/materializations/view/view.sql
2021-06-03 10:44:51.005450 (MainThread): Parsing macros/materializations/view/create_or_replace_view.sql
2021-06-03 10:44:51.013621 (MainThread): Parsing macros/etc/get_custom_alias.sql
2021-06-03 10:44:51.016128 (MainThread): Parsing macros/etc/query.sql
2021-06-03 10:44:51.018792 (MainThread): Parsing macros/etc/is_incremental.sql
2021-06-03 10:44:51.022185 (MainThread): Parsing macros/etc/datetime.sql
2021-06-03 10:44:51.036525 (MainThread): Parsing macros/etc/get_custom_schema.sql
2021-06-03 10:44:51.040567 (MainThread): Parsing macros/etc/get_custom_database.sql
2021-06-03 10:44:51.044356 (MainThread): Parsing macros/adapters/common.sql
2021-06-03 10:44:51.105790 (MainThread): Parsing macros/schema_tests/relationships.sql
2021-06-03 10:44:51.109746 (MainThread): Parsing macros/schema_tests/not_null.sql
2021-06-03 10:44:51.113014 (MainThread): Parsing macros/schema_tests/unique.sql
2021-06-03 10:44:51.116531 (MainThread): Parsing macros/schema_tests/accepted_values.sql
2021-06-03 10:44:51.127795 (MainThread): Partial parsing not enabled
2021-06-03 10:44:51.162489 (MainThread): Acquiring new bigquery connection "model.werkspot_technical_challenge.my_first_dbt_model".
2021-06-03 10:44:51.240254 (MainThread): Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'b7f5380f-3556-4ddf-84d3-472320686543', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ff7a71bbb50>]}
2021-06-03 10:44:51.258357 (MainThread): Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'b7f5380f-3556-4ddf-84d3-472320686543', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ff7a72f66d0>]}
2021-06-03 10:44:51.258738 (MainThread): Found 1 model, 0 tests, 0 snapshots, 0 analyses, 156 macros, 0 operations, 0 seed files, 0 sources, 0 exposures
2021-06-03 10:44:51.259932 (MainThread): 
2021-06-03 10:44:51.260812 (MainThread): Acquiring new bigquery connection "master".
2021-06-03 10:44:51.262291 (ThreadPoolExecutor-0_0): Acquiring new bigquery connection "list_poetic-genius-315513".
2021-06-03 10:44:51.262606 (ThreadPoolExecutor-0_0): Opening a new connection, currently in state init
2021-06-03 10:44:54.082630 (ThreadPoolExecutor-1_0): Acquiring new bigquery connection "list_poetic-genius-315513_events_information".
2021-06-03 10:44:54.083041 (ThreadPoolExecutor-1_0): Opening a new connection, currently in state closed
2021-06-03 10:44:54.083414 (ThreadPoolExecutor-1_0): Client.dataset is deprecated and will be removed in a future version. Use a string like 'my_project.my_dataset' or a cloud.google.bigquery.DatasetReference object, instead.
2021-06-03 10:44:55.208819 (MainThread): 15:44:55 | Concurrency: 1 threads (target='dev')
2021-06-03 10:44:55.209190 (MainThread): 15:44:55 | 
2021-06-03 10:44:55.211680 (Thread-1): Began running node model.werkspot_technical_challenge.my_first_dbt_model
2021-06-03 10:44:55.212100 (Thread-1): 15:44:55 | 1 of 1 START table model events_information.my_first_dbt_model....... [RUN]
2021-06-03 10:44:55.212691 (Thread-1): Acquiring new bigquery connection "model.werkspot_technical_challenge.my_first_dbt_model".
2021-06-03 10:44:55.212921 (Thread-1): Compiling model.werkspot_technical_challenge.my_first_dbt_model
2021-06-03 10:44:55.213858 (Thread-1): unclosed <socket.socket fd=13, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('192.168.0.101', 52484), raddr=('142.250.185.42', 443)>
2021-06-03 10:44:55.217431 (Thread-1): Writing injected SQL for node "model.werkspot_technical_challenge.my_first_dbt_model"
2021-06-03 10:44:55.218190 (Thread-1): finished collecting timing info
2021-06-03 10:44:55.268950 (Thread-1): unclosed <socket.socket fd=12, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('192.168.0.101', 52483), raddr=('142.250.185.42', 443)>
2021-06-03 10:44:55.269385 (Thread-1): unclosed <socket.socket fd=11, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('192.168.0.101', 52482), raddr=('216.58.210.74', 443)>
2021-06-03 10:44:55.274347 (Thread-1): Writing runtime SQL for node "model.werkspot_technical_challenge.my_first_dbt_model"
2021-06-03 10:44:55.275146 (Thread-1): Opening a new connection, currently in state closed
2021-06-03 10:44:55.275352 (Thread-1): On model.werkspot_technical_challenge.my_first_dbt_model: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "werkspot_technical_challenge", "target_name": "dev", "node_id": "model.werkspot_technical_challenge.my_first_dbt_model"} */


  create or replace table `poetic-genius-315513`.`events_information`.`my_first_dbt_model`
  
  
  OPTIONS()
  as (
    /*
    Welcome to your first dbt model!
    Did you know that you can also configure models directly within SQL files?
    This will override configurations stated in dbt_project.yml

    Try changing "table" to "view" below
*/



SELECT
  DelimitedEventLog[OFFSET(0)] AS EevntID,
  DelimitedEventLog[OFFSET(1)] AS EventType,
  DelimitedEventLog[OFFSET(2)] AS ProfessionalID,
  DelimitedEventLog[OFFSET(3)] AS CreatedAt,
  DelimitedEventLog[OFFSET(4)] AS Metadata
FROM (
  SELECT 
    SPLIT( EventLogEntry, ';') AS DelimitedEventLog
  FROM `poetic-genius-315513.events_information_staging.events_log_data`
)
  );
    
2021-06-03 10:44:59.018823 (Thread-1): finished collecting timing info
2021-06-03 10:44:59.019755 (Thread-1): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'b7f5380f-3556-4ddf-84d3-472320686543', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ff7a742ad10>]}
2021-06-03 10:44:59.020279 (Thread-1): 15:44:59 | 1 of 1 OK created table model events_information.my_first_dbt_model.. [CREATE TABLE (19.0k rows, 1.6 MB processed) in 3.81s]
2021-06-03 10:44:59.020459 (Thread-1): Finished running node model.werkspot_technical_challenge.my_first_dbt_model
2021-06-03 10:44:59.120939 (MainThread): Acquiring new bigquery connection "master".
2021-06-03 10:44:59.121539 (MainThread): 15:44:59 | 
2021-06-03 10:44:59.121787 (MainThread): 15:44:59 | Finished running 1 table model in 7.86s.
2021-06-03 10:44:59.122131 (MainThread): Connection 'master' was properly closed.
2021-06-03 10:44:59.122358 (MainThread): Connection 'model.werkspot_technical_challenge.my_first_dbt_model' was properly closed.
2021-06-03 10:44:59.145679 (MainThread): 
2021-06-03 10:44:59.146032 (MainThread): Completed successfully
2021-06-03 10:44:59.146412 (MainThread): 
Done. PASS=1 WARN=0 ERROR=0 SKIP=0 TOTAL=1
2021-06-03 10:44:59.146921 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ff7a743b850>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ff7a73f6990>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ff7a73f6890>]}
2021-06-03 10:44:59.147296 (MainThread): Flushing usage events
2021-06-03 11:24:09.525583 (MainThread): Running with dbt=0.19.1
2021-06-03 11:24:10.617044 (MainThread): running dbt with arguments Namespace(cls=<class 'dbt.task.run.RunTask'>, debug=False, defer=None, exclude=None, fail_fast=False, full_refresh=False, log_cache_events=False, log_format='default', models=['my_first_dbt_model'], partial_parse=None, profile=None, profiles_dir='/Users/mac/.dbt', project_dir=None, record_timing_info=None, rpc_method='run', selector_name=None, single_threaded=False, state=None, strict=False, target=None, test_new_parser=False, threads=None, use_cache=True, use_colors=None, vars='{}', version_check=True, warn_error=False, which='run', write_json=True)
2021-06-03 11:24:10.618629 (MainThread): Tracking: tracking
2021-06-03 11:24:10.630472 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fcccf10cf90>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fcccf11b490>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fcccf11b1d0>]}
2021-06-03 11:24:10.647029 (MainThread): Partial parsing not enabled
2021-06-03 11:24:10.648825 (MainThread): Parsing macros/etc.sql
2021-06-03 11:24:10.654516 (MainThread): Parsing macros/catalog.sql
2021-06-03 11:24:10.663494 (MainThread): Parsing macros/adapters.sql
2021-06-03 11:24:10.693871 (MainThread): Parsing macros/materializations/seed.sql
2021-06-03 11:24:10.698288 (MainThread): Parsing macros/materializations/view.sql
2021-06-03 11:24:10.703308 (MainThread): Parsing macros/materializations/table.sql
2021-06-03 11:24:10.717543 (MainThread): Parsing macros/materializations/copy.sql
2021-06-03 11:24:10.724977 (MainThread): Parsing macros/materializations/incremental.sql
2021-06-03 11:24:10.745651 (MainThread): Parsing macros/materializations/snapshot.sql
2021-06-03 11:24:10.750242 (MainThread): Parsing macros/core.sql
2021-06-03 11:24:10.756034 (MainThread): Parsing macros/materializations/helpers.sql
2021-06-03 11:24:10.768683 (MainThread): Parsing macros/materializations/snapshot/snapshot_merge.sql
2021-06-03 11:24:10.772235 (MainThread): Parsing macros/materializations/snapshot/strategies.sql
2021-06-03 11:24:10.797942 (MainThread): Parsing macros/materializations/snapshot/snapshot.sql
2021-06-03 11:24:10.850016 (MainThread): Parsing macros/materializations/seed/seed.sql
2021-06-03 11:24:10.878273 (MainThread): Parsing macros/materializations/incremental/helpers.sql
2021-06-03 11:24:10.882658 (MainThread): Parsing macros/materializations/incremental/incremental.sql
2021-06-03 11:24:10.892328 (MainThread): Parsing macros/materializations/common/merge.sql
2021-06-03 11:24:10.913871 (MainThread): Parsing macros/materializations/table/table.sql
2021-06-03 11:24:10.923132 (MainThread): Parsing macros/materializations/view/view.sql
2021-06-03 11:24:10.931546 (MainThread): Parsing macros/materializations/view/create_or_replace_view.sql
2021-06-03 11:24:10.938207 (MainThread): Parsing macros/etc/get_custom_alias.sql
2021-06-03 11:24:10.939583 (MainThread): Parsing macros/etc/query.sql
2021-06-03 11:24:10.941072 (MainThread): Parsing macros/etc/is_incremental.sql
2021-06-03 11:24:10.943337 (MainThread): Parsing macros/etc/datetime.sql
2021-06-03 11:24:10.955284 (MainThread): Parsing macros/etc/get_custom_schema.sql
2021-06-03 11:24:10.959585 (MainThread): Parsing macros/etc/get_custom_database.sql
2021-06-03 11:24:10.962331 (MainThread): Parsing macros/adapters/common.sql
2021-06-03 11:24:11.021007 (MainThread): Parsing macros/schema_tests/relationships.sql
2021-06-03 11:24:11.025376 (MainThread): Parsing macros/schema_tests/not_null.sql
2021-06-03 11:24:11.027886 (MainThread): Parsing macros/schema_tests/unique.sql
2021-06-03 11:24:11.030645 (MainThread): Parsing macros/schema_tests/accepted_values.sql
2021-06-03 11:24:11.041396 (MainThread): Partial parsing not enabled
2021-06-03 11:24:11.084487 (MainThread): Acquiring new bigquery connection "model.werkspot_technical_challenge.fct_fee".
2021-06-03 11:24:11.099999 (MainThread): Acquiring new bigquery connection "model.werkspot_technical_challenge.dim_service".
2021-06-03 11:24:11.108814 (MainThread): Acquiring new bigquery connection "model.werkspot_technical_challenge.dim_professional".
2021-06-03 11:24:11.116391 (MainThread): Acquiring new bigquery connection "model.werkspot_technical_challenge.dim_event".
2021-06-03 11:24:11.123544 (MainThread): Acquiring new bigquery connection "model.werkspot_technical_challenge.my_first_dbt_model".
2021-06-03 11:24:11.188799 (MainThread): Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'e87a14ff-eac6-4cb2-9c0d-a515cc472e5a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fcccf451dd0>]}
2021-06-03 11:24:11.206562 (MainThread): Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'e87a14ff-eac6-4cb2-9c0d-a515cc472e5a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fcccf369a10>]}
2021-06-03 11:24:11.207080 (MainThread): Found 5 models, 0 tests, 0 snapshots, 0 analyses, 156 macros, 0 operations, 0 seed files, 0 sources, 0 exposures
2021-06-03 11:24:11.208091 (MainThread): 
2021-06-03 11:24:11.208580 (MainThread): Acquiring new bigquery connection "master".
2021-06-03 11:24:11.209639 (ThreadPoolExecutor-0_0): Acquiring new bigquery connection "list_poetic-genius-315513".
2021-06-03 11:24:11.209943 (ThreadPoolExecutor-0_0): Opening a new connection, currently in state init
2021-06-03 11:24:14.008231 (ThreadPoolExecutor-1_0): Acquiring new bigquery connection "list_poetic-genius-315513_events_information".
2021-06-03 11:24:14.008578 (ThreadPoolExecutor-1_0): Opening a new connection, currently in state closed
2021-06-03 11:24:14.008869 (ThreadPoolExecutor-1_0): Client.dataset is deprecated and will be removed in a future version. Use a string like 'my_project.my_dataset' or a cloud.google.bigquery.DatasetReference object, instead.
2021-06-03 11:24:15.337756 (MainThread): 16:24:15 | Concurrency: 1 threads (target='dev')
2021-06-03 11:24:15.338163 (MainThread): 16:24:15 | 
2021-06-03 11:24:15.340681 (Thread-1): Began running node model.werkspot_technical_challenge.my_first_dbt_model
2021-06-03 11:24:15.341089 (Thread-1): 16:24:15 | 1 of 1 START table model events_information.my_first_dbt_model....... [RUN]
2021-06-03 11:24:15.341613 (Thread-1): Acquiring new bigquery connection "model.werkspot_technical_challenge.my_first_dbt_model".
2021-06-03 11:24:15.341839 (Thread-1): Compiling model.werkspot_technical_challenge.my_first_dbt_model
2021-06-03 11:24:15.342773 (Thread-1): unclosed <socket.socket fd=13, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('192.168.0.101', 53340), raddr=('142.250.185.42', 443)>
2021-06-03 11:24:15.347466 (Thread-1): finished collecting timing info
2021-06-03 11:24:15.348141 (Thread-1): Compilation Error in model my_first_dbt_model (models/example/my_first_dbt_model.sql)
  'dbt_utils' is undefined
Traceback (most recent call last):
  File "/opt/anaconda3/lib/python3.7/site-packages/dbt/clients/jinja.py", line 501, in catch_jinja
    yield
  File "/opt/anaconda3/lib/python3.7/site-packages/dbt/clients/jinja.py", line 533, in render_template
    return template.render(ctx)
  File "/opt/anaconda3/lib/python3.7/site-packages/jinja2/environment.py", line 1090, in render
    self.environment.handle_exception()
  File "/opt/anaconda3/lib/python3.7/site-packages/jinja2/environment.py", line 832, in handle_exception
    reraise(*rewrite_traceback_stack(source=source))
  File "/opt/anaconda3/lib/python3.7/site-packages/jinja2/_compat.py", line 28, in reraise
    raise value.with_traceback(tb)
  File "<template>", line 24, in top-level template code
  File "/opt/anaconda3/lib/python3.7/site-packages/jinja2/sandbox.py", line 407, in getattr
    value = getattr(obj, attribute)
jinja2.exceptions.UndefinedError: 'dbt_utils' is undefined

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/opt/anaconda3/lib/python3.7/site-packages/dbt/task/base.py", line 344, in safe_run
    result = self.compile_and_execute(manifest, ctx)
  File "/opt/anaconda3/lib/python3.7/site-packages/dbt/task/base.py", line 281, in compile_and_execute
    ctx.node = self.compile(manifest)
  File "/opt/anaconda3/lib/python3.7/site-packages/dbt/task/compile.py", line 32, in compile
    return compiler.compile_node(self.node, manifest, {})
  File "/opt/anaconda3/lib/python3.7/site-packages/dbt/compilation.py", line 509, in compile_node
    node = self._compile_node(node, manifest, extra_context)
  File "/opt/anaconda3/lib/python3.7/site-packages/dbt/compilation.py", line 413, in _compile_node
    node,
  File "/opt/anaconda3/lib/python3.7/site-packages/dbt/clients/jinja.py", line 582, in get_rendered
    return render_template(template, ctx, node)
  File "/opt/anaconda3/lib/python3.7/site-packages/dbt/clients/jinja.py", line 533, in render_template
    return template.render(ctx)
  File "/opt/anaconda3/lib/python3.7/contextlib.py", line 130, in __exit__
    self.gen.throw(type, value, traceback)
  File "/opt/anaconda3/lib/python3.7/site-packages/dbt/clients/jinja.py", line 506, in catch_jinja
    raise CompilationException(str(e), node) from e
dbt.exceptions.CompilationException: Compilation Error in model my_first_dbt_model (models/example/my_first_dbt_model.sql)
  'dbt_utils' is undefined
2021-06-03 11:24:15.388257 (Thread-1): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'e87a14ff-eac6-4cb2-9c0d-a515cc472e5a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fcccf43b810>]}
2021-06-03 11:24:15.389823 (Thread-1): 16:24:15 | 1 of 1 ERROR creating table model events_information.my_first_dbt_model [ERROR in 0.05s]
2021-06-03 11:24:15.390551 (Thread-1): Finished running node model.werkspot_technical_challenge.my_first_dbt_model
2021-06-03 11:24:15.441675 (MainThread): Acquiring new bigquery connection "master".
2021-06-03 11:24:15.442378 (MainThread): 16:24:15 | 
2021-06-03 11:24:15.442701 (MainThread): 16:24:15 | Finished running 1 table model in 4.23s.
2021-06-03 11:24:15.443045 (MainThread): Connection 'master' was properly closed.
2021-06-03 11:24:15.443198 (MainThread): Connection 'model.werkspot_technical_challenge.my_first_dbt_model' was properly closed.
2021-06-03 11:24:15.462899 (MainThread): 
2021-06-03 11:24:15.463249 (MainThread): Completed with 1 error and 0 warnings:
2021-06-03 11:24:15.463563 (MainThread): 
2021-06-03 11:24:15.463836 (MainThread): Compilation Error in model my_first_dbt_model (models/example/my_first_dbt_model.sql)
2021-06-03 11:24:15.464076 (MainThread):   'dbt_utils' is undefined
2021-06-03 11:24:15.464318 (MainThread): 
Done. PASS=0 WARN=0 ERROR=1 SKIP=0 TOTAL=1
2021-06-03 11:24:15.464757 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fcccf44e4d0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fcccf2bb610>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fcccf4456d0>]}
2021-06-03 11:24:15.465125 (MainThread): Flushing usage events
2021-06-03 11:25:02.938529 (MainThread): Running with dbt=0.19.1
2021-06-03 11:25:03.878611 (MainThread): running dbt with arguments Namespace(cls=<class 'dbt.task.deps.DepsTask'>, debug=False, defer=None, log_cache_events=False, log_format='default', partial_parse=None, profile=None, profiles_dir='/Users/mac/.dbt', project_dir=None, record_timing_info=None, rpc_method='deps', single_threaded=False, state=None, strict=False, target=None, test_new_parser=False, use_cache=True, use_colors=None, vars='{}', warn_error=False, which='deps', write_json=True)
2021-06-03 11:25:03.879591 (MainThread): Tracking: tracking
2021-06-03 11:25:03.892575 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f953610ae10>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f953610a750>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f953610afd0>]}
2021-06-03 11:25:03.893452 (MainThread): Warning: No packages were found in packages.yml
2021-06-03 11:25:03.893938 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f9536106710>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f953610a5d0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f953610af10>]}
2021-06-03 11:25:03.894260 (MainThread): Flushing usage events
2021-06-03 11:25:12.407973 (MainThread): Running with dbt=0.19.1
2021-06-03 11:25:13.140048 (MainThread): running dbt with arguments Namespace(cls=<class 'dbt.task.run.RunTask'>, debug=False, defer=None, exclude=None, fail_fast=False, full_refresh=False, log_cache_events=False, log_format='default', models=['my_first_dbt_model'], partial_parse=None, profile=None, profiles_dir='/Users/mac/.dbt', project_dir=None, record_timing_info=None, rpc_method='run', selector_name=None, single_threaded=False, state=None, strict=False, target=None, test_new_parser=False, threads=None, use_cache=True, use_colors=None, vars='{}', version_check=True, warn_error=False, which='run', write_json=True)
2021-06-03 11:25:13.141699 (MainThread): Tracking: tracking
2021-06-03 11:25:13.153809 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fc0fdff1050>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fc0fdff14d0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fc0fdff1210>]}
2021-06-03 11:25:13.170046 (MainThread): Partial parsing not enabled
2021-06-03 11:25:13.171842 (MainThread): Parsing macros/etc.sql
2021-06-03 11:25:13.176384 (MainThread): Parsing macros/catalog.sql
2021-06-03 11:25:13.185986 (MainThread): Parsing macros/adapters.sql
2021-06-03 11:25:13.218216 (MainThread): Parsing macros/materializations/seed.sql
2021-06-03 11:25:13.222725 (MainThread): Parsing macros/materializations/view.sql
2021-06-03 11:25:13.227137 (MainThread): Parsing macros/materializations/table.sql
2021-06-03 11:25:13.240365 (MainThread): Parsing macros/materializations/copy.sql
2021-06-03 11:25:13.246734 (MainThread): Parsing macros/materializations/incremental.sql
2021-06-03 11:25:13.263316 (MainThread): Parsing macros/materializations/snapshot.sql
2021-06-03 11:25:13.267160 (MainThread): Parsing macros/core.sql
2021-06-03 11:25:13.272431 (MainThread): Parsing macros/materializations/helpers.sql
2021-06-03 11:25:13.284227 (MainThread): Parsing macros/materializations/snapshot/snapshot_merge.sql
2021-06-03 11:25:13.286795 (MainThread): Parsing macros/materializations/snapshot/strategies.sql
2021-06-03 11:25:13.310406 (MainThread): Parsing macros/materializations/snapshot/snapshot.sql
2021-06-03 11:25:13.354307 (MainThread): Parsing macros/materializations/seed/seed.sql
2021-06-03 11:25:13.383738 (MainThread): Parsing macros/materializations/incremental/helpers.sql
2021-06-03 11:25:13.388118 (MainThread): Parsing macros/materializations/incremental/incremental.sql
2021-06-03 11:25:13.398446 (MainThread): Parsing macros/materializations/common/merge.sql
2021-06-03 11:25:13.419995 (MainThread): Parsing macros/materializations/table/table.sql
2021-06-03 11:25:13.429258 (MainThread): Parsing macros/materializations/view/view.sql
2021-06-03 11:25:13.438004 (MainThread): Parsing macros/materializations/view/create_or_replace_view.sql
2021-06-03 11:25:13.445531 (MainThread): Parsing macros/etc/get_custom_alias.sql
2021-06-03 11:25:13.447255 (MainThread): Parsing macros/etc/query.sql
2021-06-03 11:25:13.448849 (MainThread): Parsing macros/etc/is_incremental.sql
2021-06-03 11:25:13.451170 (MainThread): Parsing macros/etc/datetime.sql
2021-06-03 11:25:13.463472 (MainThread): Parsing macros/etc/get_custom_schema.sql
2021-06-03 11:25:13.466911 (MainThread): Parsing macros/etc/get_custom_database.sql
2021-06-03 11:25:13.469369 (MainThread): Parsing macros/adapters/common.sql
2021-06-03 11:25:13.527928 (MainThread): Parsing macros/schema_tests/relationships.sql
2021-06-03 11:25:13.531052 (MainThread): Parsing macros/schema_tests/not_null.sql
2021-06-03 11:25:13.533400 (MainThread): Parsing macros/schema_tests/unique.sql
2021-06-03 11:25:13.535906 (MainThread): Parsing macros/schema_tests/accepted_values.sql
2021-06-03 11:25:13.546025 (MainThread): Partial parsing not enabled
2021-06-03 11:25:13.579197 (MainThread): Acquiring new bigquery connection "model.werkspot_technical_challenge.fct_fee".
2021-06-03 11:25:13.592737 (MainThread): Acquiring new bigquery connection "model.werkspot_technical_challenge.dim_service".
2021-06-03 11:25:13.599011 (MainThread): Acquiring new bigquery connection "model.werkspot_technical_challenge.dim_professional".
2021-06-03 11:25:13.605178 (MainThread): Acquiring new bigquery connection "model.werkspot_technical_challenge.dim_event".
2021-06-03 11:25:13.612299 (MainThread): Acquiring new bigquery connection "model.werkspot_technical_challenge.my_first_dbt_model".
2021-06-03 11:25:13.682069 (MainThread): Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'fb666166-8825-4a60-8180-182a343fbbe2', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fc0fe04ac50>]}
2021-06-03 11:25:13.696987 (MainThread): Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'fb666166-8825-4a60-8180-182a343fbbe2', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fc0fe366110>]}
2021-06-03 11:25:13.697375 (MainThread): Found 5 models, 0 tests, 0 snapshots, 0 analyses, 156 macros, 0 operations, 0 seed files, 0 sources, 0 exposures
2021-06-03 11:25:13.698310 (MainThread): 
2021-06-03 11:25:13.698763 (MainThread): Acquiring new bigquery connection "master".
2021-06-03 11:25:13.699698 (ThreadPoolExecutor-0_0): Acquiring new bigquery connection "list_poetic-genius-315513".
2021-06-03 11:25:13.699957 (ThreadPoolExecutor-0_0): Opening a new connection, currently in state init
2021-06-03 11:25:16.480599 (ThreadPoolExecutor-1_0): Acquiring new bigquery connection "list_poetic-genius-315513_events_information".
2021-06-03 11:25:16.481143 (ThreadPoolExecutor-1_0): Opening a new connection, currently in state closed
2021-06-03 11:25:16.481463 (ThreadPoolExecutor-1_0): Client.dataset is deprecated and will be removed in a future version. Use a string like 'my_project.my_dataset' or a cloud.google.bigquery.DatasetReference object, instead.
2021-06-03 11:25:18.108681 (MainThread): 16:25:18 | Concurrency: 1 threads (target='dev')
2021-06-03 11:25:18.109045 (MainThread): 16:25:18 | 
2021-06-03 11:25:18.111333 (Thread-1): Began running node model.werkspot_technical_challenge.my_first_dbt_model
2021-06-03 11:25:18.111727 (Thread-1): 16:25:18 | 1 of 1 START table model events_information.my_first_dbt_model....... [RUN]
2021-06-03 11:25:18.112179 (Thread-1): Acquiring new bigquery connection "model.werkspot_technical_challenge.my_first_dbt_model".
2021-06-03 11:25:18.112376 (Thread-1): Compiling model.werkspot_technical_challenge.my_first_dbt_model
2021-06-03 11:25:18.113301 (Thread-1): unclosed <socket.socket fd=13, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('192.168.0.101', 53372), raddr=('142.250.185.42', 443)>
2021-06-03 11:25:18.118206 (Thread-1): finished collecting timing info
2021-06-03 11:25:18.118709 (Thread-1): Compilation Error in model my_first_dbt_model (models/example/my_first_dbt_model.sql)
  'dbt_utils' is undefined
Traceback (most recent call last):
  File "/opt/anaconda3/lib/python3.7/site-packages/dbt/clients/jinja.py", line 501, in catch_jinja
    yield
  File "/opt/anaconda3/lib/python3.7/site-packages/dbt/clients/jinja.py", line 533, in render_template
    return template.render(ctx)
  File "/opt/anaconda3/lib/python3.7/site-packages/jinja2/environment.py", line 1090, in render
    self.environment.handle_exception()
  File "/opt/anaconda3/lib/python3.7/site-packages/jinja2/environment.py", line 832, in handle_exception
    reraise(*rewrite_traceback_stack(source=source))
  File "/opt/anaconda3/lib/python3.7/site-packages/jinja2/_compat.py", line 28, in reraise
    raise value.with_traceback(tb)
  File "<template>", line 24, in top-level template code
  File "/opt/anaconda3/lib/python3.7/site-packages/jinja2/sandbox.py", line 407, in getattr
    value = getattr(obj, attribute)
jinja2.exceptions.UndefinedError: 'dbt_utils' is undefined

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/opt/anaconda3/lib/python3.7/site-packages/dbt/task/base.py", line 344, in safe_run
    result = self.compile_and_execute(manifest, ctx)
  File "/opt/anaconda3/lib/python3.7/site-packages/dbt/task/base.py", line 281, in compile_and_execute
    ctx.node = self.compile(manifest)
  File "/opt/anaconda3/lib/python3.7/site-packages/dbt/task/compile.py", line 32, in compile
    return compiler.compile_node(self.node, manifest, {})
  File "/opt/anaconda3/lib/python3.7/site-packages/dbt/compilation.py", line 509, in compile_node
    node = self._compile_node(node, manifest, extra_context)
  File "/opt/anaconda3/lib/python3.7/site-packages/dbt/compilation.py", line 413, in _compile_node
    node,
  File "/opt/anaconda3/lib/python3.7/site-packages/dbt/clients/jinja.py", line 582, in get_rendered
    return render_template(template, ctx, node)
  File "/opt/anaconda3/lib/python3.7/site-packages/dbt/clients/jinja.py", line 533, in render_template
    return template.render(ctx)
  File "/opt/anaconda3/lib/python3.7/contextlib.py", line 130, in __exit__
    self.gen.throw(type, value, traceback)
  File "/opt/anaconda3/lib/python3.7/site-packages/dbt/clients/jinja.py", line 506, in catch_jinja
    raise CompilationException(str(e), node) from e
dbt.exceptions.CompilationException: Compilation Error in model my_first_dbt_model (models/example/my_first_dbt_model.sql)
  'dbt_utils' is undefined
2021-06-03 11:25:18.124557 (Thread-1): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'fb666166-8825-4a60-8180-182a343fbbe2', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fc0fe183fd0>]}
2021-06-03 11:25:18.125069 (Thread-1): 16:25:18 | 1 of 1 ERROR creating table model events_information.my_first_dbt_model [ERROR in 0.01s]
2021-06-03 11:25:18.125248 (Thread-1): Finished running node model.werkspot_technical_challenge.my_first_dbt_model
2021-06-03 11:25:18.212413 (MainThread): Acquiring new bigquery connection "master".
2021-06-03 11:25:18.213037 (MainThread): 16:25:18 | 
2021-06-03 11:25:18.213282 (MainThread): 16:25:18 | Finished running 1 table model in 4.51s.
2021-06-03 11:25:18.213613 (MainThread): Connection 'master' was properly closed.
2021-06-03 11:25:18.213832 (MainThread): Connection 'model.werkspot_technical_challenge.my_first_dbt_model' was properly closed.
2021-06-03 11:25:18.230992 (MainThread): 
2021-06-03 11:25:18.231340 (MainThread): Completed with 1 error and 0 warnings:
2021-06-03 11:25:18.231607 (MainThread): 
2021-06-03 11:25:18.231887 (MainThread): Compilation Error in model my_first_dbt_model (models/example/my_first_dbt_model.sql)
2021-06-03 11:25:18.232130 (MainThread):   'dbt_utils' is undefined
2021-06-03 11:25:18.232365 (MainThread): 
Done. PASS=0 WARN=0 ERROR=1 SKIP=0 TOTAL=1
2021-06-03 11:25:18.232796 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fc0fe4450d0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fc0fe467b10>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fc0fe450110>]}
2021-06-03 11:25:18.233170 (MainThread): Flushing usage events
2021-06-03 11:26:43.546573 (MainThread): Running with dbt=0.19.1
2021-06-03 11:26:44.593329 (MainThread): running dbt with arguments Namespace(cls=<class 'dbt.task.deps.DepsTask'>, debug=False, defer=None, log_cache_events=False, log_format='default', partial_parse=None, profile=None, profiles_dir='/Users/mac/.dbt', project_dir=None, record_timing_info=None, rpc_method='deps', single_threaded=False, state=None, strict=False, target=None, test_new_parser=False, use_cache=True, use_colors=None, vars='{}', warn_error=False, which='deps', write_json=True)
2021-06-03 11:26:44.594054 (MainThread): Tracking: tracking
2021-06-03 11:26:44.604720 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fbce5fd69d0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fbce14cdc50>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fbce5fe2f10>]}
2021-06-03 11:26:44.605491 (MainThread): Warning: No packages were found in packages.yml
2021-06-03 11:26:44.605793 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fbce5fd8990>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fbce14cdc50>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fbce5fe2990>]}
2021-06-03 11:26:44.605988 (MainThread): Flushing usage events
2021-06-05 08:18:52.273909 (MainThread): Running with dbt=0.19.1
2021-06-05 08:18:53.414665 (MainThread): running dbt with arguments Namespace(cls=<class 'dbt.task.run.RunTask'>, debug=False, defer=None, exclude=None, fail_fast=False, full_refresh=False, log_cache_events=False, log_format='default', models=['dim_professional'], partial_parse=None, profile=None, profiles_dir='/Users/mac/.dbt', project_dir=None, record_timing_info=None, rpc_method='run', selector_name=None, single_threaded=False, state=None, strict=False, target=None, test_new_parser=False, threads=None, use_cache=True, use_colors=None, vars='{}', version_check=True, warn_error=False, which='run', write_json=True)
2021-06-05 08:18:53.416058 (MainThread): Tracking: tracking
2021-06-05 08:18:53.431961 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fe32c90cf90>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fe32c91c3d0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fe32c91c210>]}
2021-06-05 08:18:53.452545 (MainThread): Partial parsing not enabled
2021-06-05 08:18:53.460612 (MainThread): Parsing macros/etc.sql
2021-06-05 08:18:53.472012 (MainThread): Parsing macros/catalog.sql
2021-06-05 08:18:53.489184 (MainThread): Parsing macros/adapters.sql
2021-06-05 08:18:53.521014 (MainThread): Parsing macros/materializations/seed.sql
2021-06-05 08:18:53.526385 (MainThread): Parsing macros/materializations/view.sql
2021-06-05 08:18:53.534062 (MainThread): Parsing macros/materializations/table.sql
2021-06-05 08:18:53.548833 (MainThread): Parsing macros/materializations/copy.sql
2021-06-05 08:18:53.556002 (MainThread): Parsing macros/materializations/incremental.sql
2021-06-05 08:18:53.573697 (MainThread): Parsing macros/materializations/snapshot.sql
2021-06-05 08:18:53.581151 (MainThread): Parsing macros/core.sql
2021-06-05 08:18:53.588888 (MainThread): Parsing macros/materializations/helpers.sql
2021-06-05 08:18:53.603828 (MainThread): Parsing macros/materializations/snapshot/snapshot_merge.sql
2021-06-05 08:18:53.607739 (MainThread): Parsing macros/materializations/snapshot/strategies.sql
2021-06-05 08:18:53.632940 (MainThread): Parsing macros/materializations/snapshot/snapshot.sql
2021-06-05 08:18:53.678102 (MainThread): Parsing macros/materializations/seed/seed.sql
2021-06-05 08:18:53.707629 (MainThread): Parsing macros/materializations/incremental/helpers.sql
2021-06-05 08:18:53.711412 (MainThread): Parsing macros/materializations/incremental/incremental.sql
2021-06-05 08:18:53.722492 (MainThread): Parsing macros/materializations/common/merge.sql
2021-06-05 08:18:53.742493 (MainThread): Parsing macros/materializations/table/table.sql
2021-06-05 08:18:53.752850 (MainThread): Parsing macros/materializations/view/view.sql
2021-06-05 08:18:53.762491 (MainThread): Parsing macros/materializations/view/create_or_replace_view.sql
2021-06-05 08:18:53.770087 (MainThread): Parsing macros/etc/get_custom_alias.sql
2021-06-05 08:18:53.772504 (MainThread): Parsing macros/etc/query.sql
2021-06-05 08:18:53.775114 (MainThread): Parsing macros/etc/is_incremental.sql
2021-06-05 08:18:53.778718 (MainThread): Parsing macros/etc/datetime.sql
2021-06-05 08:18:53.792274 (MainThread): Parsing macros/etc/get_custom_schema.sql
2021-06-05 08:18:53.796130 (MainThread): Parsing macros/etc/get_custom_database.sql
2021-06-05 08:18:53.800355 (MainThread): Parsing macros/adapters/common.sql
2021-06-05 08:18:53.858618 (MainThread): Parsing macros/schema_tests/relationships.sql
2021-06-05 08:18:53.862051 (MainThread): Parsing macros/schema_tests/not_null.sql
2021-06-05 08:18:53.865014 (MainThread): Parsing macros/schema_tests/unique.sql
2021-06-05 08:18:53.868385 (MainThread): Parsing macros/schema_tests/accepted_values.sql
2021-06-05 08:18:53.878620 (MainThread): Partial parsing not enabled
2021-06-05 08:18:53.913327 (MainThread): Acquiring new bigquery connection "model.werkspot_technical_challenge.fct_fee".
2021-06-05 08:18:53.927125 (MainThread): Acquiring new bigquery connection "model.werkspot_technical_challenge.dim_service".
2021-06-05 08:18:53.933325 (MainThread): Acquiring new bigquery connection "model.werkspot_technical_challenge.dim_professional".
2021-06-05 08:18:53.945772 (MainThread): Acquiring new bigquery connection "model.werkspot_technical_challenge.dim_event".
2021-06-05 08:18:53.953593 (MainThread): Acquiring new bigquery connection "model.werkspot_technical_challenge.my_first_dbt_model".
2021-06-05 08:18:54.019418 (MainThread): Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '1c2e967e-a2e7-462d-9a64-dcd51e3de41f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fe32cb81050>]}
2021-06-05 08:18:54.037918 (MainThread): Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '1c2e967e-a2e7-462d-9a64-dcd51e3de41f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fe32cc01850>]}
2021-06-05 08:18:54.038282 (MainThread): Found 5 models, 0 tests, 0 snapshots, 0 analyses, 156 macros, 0 operations, 0 seed files, 0 sources, 0 exposures
2021-06-05 08:18:54.039208 (MainThread): 
2021-06-05 08:18:54.039637 (MainThread): Acquiring new bigquery connection "master".
2021-06-05 08:18:54.040569 (ThreadPoolExecutor-0_0): Acquiring new bigquery connection "list_poetic-genius-315513".
2021-06-05 08:18:54.040850 (ThreadPoolExecutor-0_0): Opening a new connection, currently in state init
2021-06-05 08:18:56.815050 (ThreadPoolExecutor-1_0): Acquiring new bigquery connection "list_poetic-genius-315513_events_information".
2021-06-05 08:18:56.815404 (ThreadPoolExecutor-1_0): Opening a new connection, currently in state closed
2021-06-05 08:18:56.815690 (ThreadPoolExecutor-1_0): Client.dataset is deprecated and will be removed in a future version. Use a string like 'my_project.my_dataset' or a cloud.google.bigquery.DatasetReference object, instead.
2021-06-05 08:18:58.100689 (MainThread): 13:18:58 | Concurrency: 1 threads (target='dev')
2021-06-05 08:18:58.100942 (MainThread): 13:18:58 | 
2021-06-05 08:18:58.118031 (Thread-1): Began running node model.werkspot_technical_challenge.dim_professional
2021-06-05 08:18:58.118429 (Thread-1): 13:18:58 | 1 of 1 START incremental model events_information.dim_professional... [RUN]
2021-06-05 08:18:58.118870 (Thread-1): Acquiring new bigquery connection "model.werkspot_technical_challenge.dim_professional".
2021-06-05 08:18:58.119058 (Thread-1): Compiling model.werkspot_technical_challenge.dim_professional
2021-06-05 08:18:58.119755 (Thread-1): unclosed <socket.socket fd=13, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('192.168.0.104', 52806), raddr=('142.250.185.42', 443)>
2021-06-05 08:18:58.127511 (Thread-1): Writing injected SQL for node "model.werkspot_technical_challenge.dim_professional"
2021-06-05 08:18:58.128119 (Thread-1): finished collecting timing info
2021-06-05 08:18:58.172107 (Thread-1): Opening a new connection, currently in state closed
2021-06-05 08:18:58.172401 (Thread-1): Client.dataset is deprecated and will be removed in a future version. Use a string like 'my_project.my_dataset' or a cloud.google.bigquery.DatasetReference object, instead.
2021-06-05 08:18:59.480519 (Thread-1): Writing runtime SQL for node "model.werkspot_technical_challenge.dim_professional"
2021-06-05 08:18:59.481682 (Thread-1): On model.werkspot_technical_challenge.dim_professional: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "werkspot_technical_challenge", "target_name": "dev", "node_id": "model.werkspot_technical_challenge.dim_professional"} */

        
        
    

    

    merge into `poetic-genius-315513`.`events_information`.`dim_professional` as DBT_INTERNAL_DEST
        using (
           


SELECT
  DISTINCT 
    ParsedEventLog[OFFSET(2)] AS PK_ProfessionalID,
    CURRENT_DATETIME() as AuditCreatedDateTime,
    CURRENT_DATETIME() as AuditModifiedDateTime
FROM 
(

  SELECT 
    SPLIT(EventLogEntry,';') as ParsedEventLog
  FROM 
   `poetic-genius-315513.events_information_staging.events_log_data_stg`
      
      -- this filter will only be applied on an incremental run
      
        where PARSE_DATETIME('%Y-%m-%d %H:%M:%S', AuditCreatedDatetime) > 
              (select max(PARSE_DATETIME('%Y-%m-%d %H:%M:%S', AuditCreatedDatetime)) from `poetic-genius-315513`.`events_information`.`dim_professional`)
      

)
         ) as DBT_INTERNAL_SOURCE
        on 
            DBT_INTERNAL_SOURCE.PK_ProfessionalID = DBT_INTERNAL_DEST.PK_ProfessionalID
        

    
    when matched then update set
        `PK_ProfessionalID` = DBT_INTERNAL_SOURCE.`PK_ProfessionalID`,`AuditCreatedDateTime` = DBT_INTERNAL_SOURCE.`AuditCreatedDateTime`,`AuditModifiedDateTime` = DBT_INTERNAL_SOURCE.`AuditModifiedDateTime`
    

    when not matched then insert
        (`PK_ProfessionalID`, `AuditCreatedDateTime`, `AuditModifiedDateTime`)
    values
        (`PK_ProfessionalID`, `AuditCreatedDateTime`, `AuditModifiedDateTime`)


  
2021-06-05 08:19:00.661858 (Thread-1): Retry attempt 1 of 1 after error: BadRequest('GET https://bigquery.googleapis.com/bigquery/v2/projects/poetic-genius-315513/queries/c0f8f7ac-a444-499f-992a-1cb03fe3e328?maxResults=0&location=US: No matching signature for function PARSE_DATETIME for argument types: STRING, DATETIME. Supported signature: PARSE_DATETIME(STRING, STRING) at [30:27]')
2021-06-05 08:19:02.328984 (Thread-1): finished collecting timing info
2021-06-05 08:19:02.329681 (Thread-1): Database Error in model dim_professional (models/dim_professional.sql)
  No matching signature for function PARSE_DATETIME for argument types: STRING, DATETIME. Supported signature: PARSE_DATETIME(STRING, STRING) at [30:27]
  compiled SQL at target/run/werkspot_technical_challenge/models/dim_professional.sql
Traceback (most recent call last):
  File "/opt/anaconda3/lib/python3.7/site-packages/dbt/adapters/bigquery/connections.py", line 149, in exception_handler
    yield
  File "/opt/anaconda3/lib/python3.7/site-packages/dbt/adapters/bigquery/connections.py", line 539, in _retry_and_handle
    on_error=reopen_conn_on_error)
  File "/opt/anaconda3/lib/python3.7/site-packages/google/api_core/retry.py", line 184, in retry_target
    return target()
  File "/opt/anaconda3/lib/python3.7/site-packages/dbt/adapters/bigquery/connections.py", line 327, in fn
    return self._query_and_results(client, sql, conn, job_params)
  File "/opt/anaconda3/lib/python3.7/site-packages/dbt/adapters/bigquery/connections.py", line 520, in _query_and_results
    iterator = query_job.result(timeout=timeout)
  File "/opt/anaconda3/lib/python3.7/site-packages/google/cloud/bigquery/job.py", line 3207, in result
    super(QueryJob, self).result(retry=retry, timeout=timeout)
  File "/opt/anaconda3/lib/python3.7/site-packages/google/cloud/bigquery/job.py", line 812, in result
    return super(_AsyncJob, self).result(timeout=timeout)
  File "/opt/anaconda3/lib/python3.7/site-packages/google/api_core/future/polling.py", line 125, in result
    self._blocking_poll(timeout=timeout)
  File "/opt/anaconda3/lib/python3.7/site-packages/google/cloud/bigquery/job.py", line 3103, in _blocking_poll
    super(QueryJob, self)._blocking_poll(timeout=timeout)
  File "/opt/anaconda3/lib/python3.7/site-packages/google/api_core/future/polling.py", line 104, in _blocking_poll
    retry_(self._done_or_raise)()
  File "/opt/anaconda3/lib/python3.7/site-packages/google/api_core/retry.py", line 286, in retry_wrapped_func
    on_error=on_error,
  File "/opt/anaconda3/lib/python3.7/site-packages/google/api_core/retry.py", line 184, in retry_target
    return target()
  File "/opt/anaconda3/lib/python3.7/site-packages/google/api_core/future/polling.py", line 83, in _done_or_raise
    if not self.done():
  File "/opt/anaconda3/lib/python3.7/site-packages/google/cloud/bigquery/job.py", line 3089, in done
    timeout=transport_timeout,
  File "/opt/anaconda3/lib/python3.7/site-packages/google/cloud/bigquery/client.py", line 1362, in _get_query_results
    retry, method="GET", path=path, query_params=extra_params, timeout=timeout
  File "/opt/anaconda3/lib/python3.7/site-packages/google/cloud/bigquery/client.py", line 578, in _call_api
    return call()
  File "/opt/anaconda3/lib/python3.7/site-packages/google/api_core/retry.py", line 286, in retry_wrapped_func
    on_error=on_error,
  File "/opt/anaconda3/lib/python3.7/site-packages/google/api_core/retry.py", line 184, in retry_target
    return target()
  File "/opt/anaconda3/lib/python3.7/site-packages/google/cloud/_http.py", line 423, in api_request
    raise exceptions.from_http_response(response)
google.api_core.exceptions.BadRequest: 400 GET https://bigquery.googleapis.com/bigquery/v2/projects/poetic-genius-315513/queries/5b8a60c9-1629-492a-96b1-0d7e18e2d87a?maxResults=0&location=US: No matching signature for function PARSE_DATETIME for argument types: STRING, DATETIME. Supported signature: PARSE_DATETIME(STRING, STRING) at [30:27]

(job ID: 5b8a60c9-1629-492a-96b1-0d7e18e2d87a)

                                                                                          -----Query Job SQL Follows-----                                                                                           

    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |
   1:/* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "werkspot_technical_challenge", "target_name": "dev", "node_id": "model.werkspot_technical_challenge.dim_professional"} */
   2:
   3:        
   4:        
   5:    
   6:
   7:    
   8:
   9:    merge into `poetic-genius-315513`.`events_information`.`dim_professional` as DBT_INTERNAL_DEST
  10:        using (
  11:           
  12:
  13:
  14:SELECT
  15:  DISTINCT 
  16:    ParsedEventLog[OFFSET(2)] AS PK_ProfessionalID,
  17:    CURRENT_DATETIME() as AuditCreatedDateTime,
  18:    CURRENT_DATETIME() as AuditModifiedDateTime
  19:FROM 
  20:(
  21:
  22:  SELECT 
  23:    SPLIT(EventLogEntry,';') as ParsedEventLog
  24:  FROM 
  25:   `poetic-genius-315513.events_information_staging.events_log_data_stg`
  26:      
  27:      -- this filter will only be applied on an incremental run
  28:      
  29:        where PARSE_DATETIME('%Y-%m-%d %H:%M:%S', AuditCreatedDatetime) > 
  30:              (select max(PARSE_DATETIME('%Y-%m-%d %H:%M:%S', AuditCreatedDatetime)) from `poetic-genius-315513`.`events_information`.`dim_professional`)
  31:      
  32:
  33:)
  34:         ) as DBT_INTERNAL_SOURCE
  35:        on 
  36:            DBT_INTERNAL_SOURCE.PK_ProfessionalID = DBT_INTERNAL_DEST.PK_ProfessionalID
  37:        
  38:
  39:    
  40:    when matched then update set
  41:        `PK_ProfessionalID` = DBT_INTERNAL_SOURCE.`PK_ProfessionalID`,`AuditCreatedDateTime` = DBT_INTERNAL_SOURCE.`AuditCreatedDateTime`,`AuditModifiedDateTime` = DBT_INTERNAL_SOURCE.`AuditModifiedDateTime`
  42:    
  43:
  44:    when not matched then insert
  45:        (`PK_ProfessionalID`, `AuditCreatedDateTime`, `AuditModifiedDateTime`)
  46:    values
  47:        (`PK_ProfessionalID`, `AuditCreatedDateTime`, `AuditModifiedDateTime`)
  48:
  49:
  50:  
    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/anaconda3/lib/python3.7/site-packages/dbt/task/base.py", line 344, in safe_run
    result = self.compile_and_execute(manifest, ctx)
  File "/opt/anaconda3/lib/python3.7/site-packages/dbt/task/base.py", line 287, in compile_and_execute
    result = self.run(ctx.node, manifest)
  File "/opt/anaconda3/lib/python3.7/site-packages/dbt/task/base.py", line 389, in run
    return self.execute(compiled_node, manifest)
  File "/opt/anaconda3/lib/python3.7/site-packages/dbt/task/run.py", line 248, in execute
    result = MacroGenerator(materialization_macro, context)()
  File "/opt/anaconda3/lib/python3.7/site-packages/dbt/clients/jinja.py", line 332, in __call__
    return self.call_macro(*args, **kwargs)
  File "/opt/anaconda3/lib/python3.7/site-packages/dbt/clients/jinja.py", line 259, in call_macro
    return macro(*args, **kwargs)
  File "/opt/anaconda3/lib/python3.7/site-packages/jinja2/runtime.py", line 675, in __call__
    return self._invoke(arguments, autoescape)
  File "/opt/anaconda3/lib/python3.7/site-packages/jinja2/runtime.py", line 679, in _invoke
    rv = self._func(*arguments)
  File "<template>", line 156, in macro
  File "/opt/anaconda3/lib/python3.7/site-packages/jinja2/sandbox.py", line 462, in call
    return __context.call(__obj, *args, **kwargs)
  File "/opt/anaconda3/lib/python3.7/site-packages/jinja2/runtime.py", line 290, in call
    return __obj(*args, **kwargs)
  File "/opt/anaconda3/lib/python3.7/site-packages/dbt/clients/jinja.py", line 332, in __call__
    return self.call_macro(*args, **kwargs)
  File "/opt/anaconda3/lib/python3.7/site-packages/dbt/clients/jinja.py", line 259, in call_macro
    return macro(*args, **kwargs)
  File "/opt/anaconda3/lib/python3.7/site-packages/jinja2/runtime.py", line 675, in __call__
    return self._invoke(arguments, autoescape)
  File "/opt/anaconda3/lib/python3.7/site-packages/jinja2/runtime.py", line 679, in _invoke
    rv = self._func(*arguments)
  File "<template>", line 41, in macro
  File "/opt/anaconda3/lib/python3.7/site-packages/jinja2/sandbox.py", line 462, in call
    return __context.call(__obj, *args, **kwargs)
  File "/opt/anaconda3/lib/python3.7/site-packages/jinja2/runtime.py", line 290, in call
    return __obj(*args, **kwargs)
  File "/opt/anaconda3/lib/python3.7/site-packages/dbt/adapters/base/impl.py", line 230, in execute
    fetch=fetch
  File "/opt/anaconda3/lib/python3.7/site-packages/dbt/adapters/bigquery/connections.py", line 338, in execute
    query_job, iterator = self.raw_execute(sql, fetch=fetch)
  File "/opt/anaconda3/lib/python3.7/site-packages/dbt/adapters/bigquery/connections.py", line 329, in raw_execute
    query_job, iterator = self._retry_and_handle(msg=sql, conn=conn, fn=fn)
  File "/opt/anaconda3/lib/python3.7/site-packages/dbt/adapters/bigquery/connections.py", line 539, in _retry_and_handle
    on_error=reopen_conn_on_error)
  File "/opt/anaconda3/lib/python3.7/contextlib.py", line 130, in __exit__
    self.gen.throw(type, value, traceback)
  File "/opt/anaconda3/lib/python3.7/site-packages/dbt/adapters/bigquery/connections.py", line 153, in exception_handler
    self.handle_error(e, message)
  File "/opt/anaconda3/lib/python3.7/site-packages/dbt/adapters/bigquery/connections.py", line 141, in handle_error
    raise DatabaseException(error_msg)
dbt.exceptions.DatabaseException: Database Error in model dim_professional (models/dim_professional.sql)
  No matching signature for function PARSE_DATETIME for argument types: STRING, DATETIME. Supported signature: PARSE_DATETIME(STRING, STRING) at [30:27]
  compiled SQL at target/run/werkspot_technical_challenge/models/dim_professional.sql
2021-06-05 08:19:02.396615 (Thread-1): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '1c2e967e-a2e7-462d-9a64-dcd51e3de41f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fe32ccd75d0>]}
2021-06-05 08:19:02.397315 (Thread-1): 13:19:02 | 1 of 1 ERROR creating incremental model events_information.dim_professional [ERROR in 4.28s]
2021-06-05 08:19:02.397577 (Thread-1): Finished running node model.werkspot_technical_challenge.dim_professional
2021-06-05 08:19:02.490624 (MainThread): Acquiring new bigquery connection "master".
2021-06-05 08:19:02.491226 (MainThread): 13:19:02 | 
2021-06-05 08:19:02.491475 (MainThread): 13:19:02 | Finished running 1 incremental model in 8.45s.
2021-06-05 08:19:02.491810 (MainThread): Connection 'master' was properly closed.
2021-06-05 08:19:02.492038 (MainThread): Connection 'model.werkspot_technical_challenge.dim_professional' was properly closed.
2021-06-05 08:19:02.535574 (MainThread): 
2021-06-05 08:19:02.535911 (MainThread): Completed with 1 error and 0 warnings:
2021-06-05 08:19:02.536176 (MainThread): 
2021-06-05 08:19:02.536456 (MainThread): Database Error in model dim_professional (models/dim_professional.sql)
2021-06-05 08:19:02.536698 (MainThread):   No matching signature for function PARSE_DATETIME for argument types: STRING, DATETIME. Supported signature: PARSE_DATETIME(STRING, STRING) at [30:27]
2021-06-05 08:19:02.536918 (MainThread):   compiled SQL at target/run/werkspot_technical_challenge/models/dim_professional.sql
2021-06-05 08:19:02.537148 (MainThread): 
Done. PASS=0 WARN=0 ERROR=1 SKIP=0 TOTAL=1
2021-06-05 08:19:02.537568 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fe32caeb2d0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fe32cba39d0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fe32cba3e10>]}
2021-06-05 08:19:02.537938 (MainThread): Flushing usage events
2021-06-05 10:41:09.710629 (MainThread): Running with dbt=0.19.1
2021-06-05 10:41:10.911381 (MainThread): running dbt with arguments Namespace(cls=<class 'dbt.task.run.RunTask'>, debug=False, defer=None, exclude=None, fail_fast=False, full_refresh=False, log_cache_events=False, log_format='default', models=['dim_professional'], partial_parse=None, profile=None, profiles_dir='/Users/mac/.dbt', project_dir=None, record_timing_info=None, rpc_method='run', selector_name=None, single_threaded=False, state=None, strict=False, target=None, test_new_parser=False, threads=None, use_cache=True, use_colors=None, vars='{}', version_check=True, warn_error=False, which='run', write_json=True)
2021-06-05 10:41:10.913039 (MainThread): Tracking: tracking
2021-06-05 10:41:10.925087 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fc6a411d0d0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fc6a411d4d0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fc6a411d410>]}
2021-06-05 10:41:10.941606 (MainThread): Partial parsing not enabled
2021-06-05 10:41:10.943436 (MainThread): Parsing macros/etc.sql
2021-06-05 10:41:10.948680 (MainThread): Parsing macros/catalog.sql
2021-06-05 10:41:10.958185 (MainThread): Parsing macros/adapters.sql
2021-06-05 10:41:10.988935 (MainThread): Parsing macros/materializations/seed.sql
2021-06-05 10:41:10.993545 (MainThread): Parsing macros/materializations/view.sql
2021-06-05 10:41:10.998170 (MainThread): Parsing macros/materializations/table.sql
2021-06-05 10:41:11.012361 (MainThread): Parsing macros/materializations/copy.sql
2021-06-05 10:41:11.019648 (MainThread): Parsing macros/materializations/incremental.sql
2021-06-05 10:41:11.038215 (MainThread): Parsing macros/materializations/snapshot.sql
2021-06-05 10:41:11.043051 (MainThread): Parsing macros/core.sql
2021-06-05 10:41:11.048668 (MainThread): Parsing macros/materializations/helpers.sql
2021-06-05 10:41:11.061392 (MainThread): Parsing macros/materializations/snapshot/snapshot_merge.sql
2021-06-05 10:41:11.064367 (MainThread): Parsing macros/materializations/snapshot/strategies.sql
2021-06-05 10:41:11.090296 (MainThread): Parsing macros/materializations/snapshot/snapshot.sql
2021-06-05 10:41:11.135452 (MainThread): Parsing macros/materializations/seed/seed.sql
2021-06-05 10:41:11.166975 (MainThread): Parsing macros/materializations/incremental/helpers.sql
2021-06-05 10:41:11.169708 (MainThread): Parsing macros/materializations/incremental/incremental.sql
2021-06-05 10:41:11.178570 (MainThread): Parsing macros/materializations/common/merge.sql
2021-06-05 10:41:11.197636 (MainThread): Parsing macros/materializations/table/table.sql
2021-06-05 10:41:11.206843 (MainThread): Parsing macros/materializations/view/view.sql
2021-06-05 10:41:11.215323 (MainThread): Parsing macros/materializations/view/create_or_replace_view.sql
2021-06-05 10:41:11.222322 (MainThread): Parsing macros/etc/get_custom_alias.sql
2021-06-05 10:41:11.223787 (MainThread): Parsing macros/etc/query.sql
2021-06-05 10:41:11.225555 (MainThread): Parsing macros/etc/is_incremental.sql
2021-06-05 10:41:11.228341 (MainThread): Parsing macros/etc/datetime.sql
2021-06-05 10:41:11.242934 (MainThread): Parsing macros/etc/get_custom_schema.sql
2021-06-05 10:41:11.246893 (MainThread): Parsing macros/etc/get_custom_database.sql
2021-06-05 10:41:11.249701 (MainThread): Parsing macros/adapters/common.sql
2021-06-05 10:41:11.308703 (MainThread): Parsing macros/schema_tests/relationships.sql
2021-06-05 10:41:11.311916 (MainThread): Parsing macros/schema_tests/not_null.sql
2021-06-05 10:41:11.314365 (MainThread): Parsing macros/schema_tests/unique.sql
2021-06-05 10:41:11.316913 (MainThread): Parsing macros/schema_tests/accepted_values.sql
2021-06-05 10:41:11.328070 (MainThread): Partial parsing not enabled
2021-06-05 10:41:11.361842 (MainThread): Acquiring new bigquery connection "model.werkspot_technical_challenge.fct_fee".
2021-06-05 10:41:11.376218 (MainThread): Acquiring new bigquery connection "model.werkspot_technical_challenge.dim_service".
2021-06-05 10:41:11.389625 (MainThread): Acquiring new bigquery connection "model.werkspot_technical_challenge.dim_professional".
2021-06-05 10:41:11.403059 (MainThread): Acquiring new bigquery connection "model.werkspot_technical_challenge.dim_event".
2021-06-05 10:41:11.410677 (MainThread): Acquiring new bigquery connection "model.werkspot_technical_challenge.my_first_dbt_model".
2021-06-05 10:41:11.478124 (MainThread): Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '677abc10-f64e-47dd-a9c8-a7e2056fac26', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fc6a37349d0>]}
2021-06-05 10:41:11.494690 (MainThread): Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '677abc10-f64e-47dd-a9c8-a7e2056fac26', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fc6a438c610>]}
2021-06-05 10:41:11.495208 (MainThread): Found 5 models, 0 tests, 0 snapshots, 0 analyses, 156 macros, 0 operations, 0 seed files, 0 sources, 0 exposures
2021-06-05 10:41:11.496603 (MainThread): 
2021-06-05 10:41:11.497183 (MainThread): Acquiring new bigquery connection "master".
2021-06-05 10:41:11.498173 (ThreadPoolExecutor-0_0): Acquiring new bigquery connection "list_poetic-genius-315513".
2021-06-05 10:41:11.498469 (ThreadPoolExecutor-0_0): Opening a new connection, currently in state init
2021-06-05 10:41:14.884280 (ThreadPoolExecutor-1_0): Acquiring new bigquery connection "list_poetic-genius-315513_events_information".
2021-06-05 10:41:14.884657 (ThreadPoolExecutor-1_0): Opening a new connection, currently in state closed
2021-06-05 10:41:14.884975 (ThreadPoolExecutor-1_0): Client.dataset is deprecated and will be removed in a future version. Use a string like 'my_project.my_dataset' or a cloud.google.bigquery.DatasetReference object, instead.
2021-06-05 10:41:16.058251 (MainThread): 15:41:16 | Concurrency: 1 threads (target='dev')
2021-06-05 10:41:16.058561 (MainThread): 15:41:16 | 
2021-06-05 10:41:16.060915 (Thread-1): Began running node model.werkspot_technical_challenge.dim_professional
2021-06-05 10:41:16.061525 (Thread-1): 15:41:16 | 1 of 1 START incremental model events_information.dim_professional... [RUN]
2021-06-05 10:41:16.062025 (Thread-1): Acquiring new bigquery connection "model.werkspot_technical_challenge.dim_professional".
2021-06-05 10:41:16.062237 (Thread-1): Compiling model.werkspot_technical_challenge.dim_professional
2021-06-05 10:41:16.063045 (Thread-1): unclosed <socket.socket fd=13, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('192.168.0.104', 53307), raddr=('142.250.185.42', 443)>
2021-06-05 10:41:16.071622 (Thread-1): Writing injected SQL for node "model.werkspot_technical_challenge.dim_professional"
2021-06-05 10:41:16.072210 (Thread-1): finished collecting timing info
2021-06-05 10:41:16.125162 (Thread-1): Opening a new connection, currently in state closed
2021-06-05 10:41:16.125443 (Thread-1): Client.dataset is deprecated and will be removed in a future version. Use a string like 'my_project.my_dataset' or a cloud.google.bigquery.DatasetReference object, instead.
2021-06-05 10:41:17.327889 (Thread-1): Writing runtime SQL for node "model.werkspot_technical_challenge.dim_professional"
2021-06-05 10:41:17.329208 (Thread-1): On model.werkspot_technical_challenge.dim_professional: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "werkspot_technical_challenge", "target_name": "dev", "node_id": "model.werkspot_technical_challenge.dim_professional"} */

        
        
    

    

    merge into `poetic-genius-315513`.`events_information`.`dim_professional` as DBT_INTERNAL_DEST
        using (
           


SELECT
  DISTINCT 
    ParsedEventLog[OFFSET(2)] AS PK_ProfessionalID,
    CURRENT_DATETIME() as AuditCreatedDateTime,
    CURRENT_DATETIME() as AuditModifiedDateTime
FROM 
(

  SELECT 
    SPLIT(EventLogEntry,';') as ParsedEventLog
  FROM 
   `poetic-genius-315513.events_information_staging.events_log_data_stg`
      
      -- this filter will only be applied on an incremental run
      
        where PARSE_DATETIME('%Y-%m-%d %H:%M:%S', AuditCreatedDatetime) > 
          (select max(AuditCreatedDatetime) from `poetic-genius-315513`.`events_information`.`dim_professional`)
      

)
         ) as DBT_INTERNAL_SOURCE
        on 
            DBT_INTERNAL_SOURCE.PK_ProfessionalID = DBT_INTERNAL_DEST.PK_ProfessionalID
        

    
    when matched then update set
        `PK_ProfessionalID` = DBT_INTERNAL_SOURCE.`PK_ProfessionalID`,`AuditCreatedDateTime` = DBT_INTERNAL_SOURCE.`AuditCreatedDateTime`,`AuditModifiedDateTime` = DBT_INTERNAL_SOURCE.`AuditModifiedDateTime`
    

    when not matched then insert
        (`PK_ProfessionalID`, `AuditCreatedDateTime`, `AuditModifiedDateTime`)
    values
        (`PK_ProfessionalID`, `AuditCreatedDateTime`, `AuditModifiedDateTime`)


  
2021-06-05 10:41:21.264469 (Thread-1): finished collecting timing info
2021-06-05 10:41:21.265017 (Thread-1): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '677abc10-f64e-47dd-a9c8-a7e2056fac26', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fc6a42f0350>]}
2021-06-05 10:41:21.265509 (Thread-1): 15:41:21 | 1 of 1 OK created incremental model events_information.dim_professional [MERGE (0.0 rows, 2.0 MB processed) in 5.20s]
2021-06-05 10:41:21.265707 (Thread-1): Finished running node model.werkspot_technical_challenge.dim_professional
2021-06-05 10:41:21.302628 (MainThread): Acquiring new bigquery connection "master".
2021-06-05 10:41:21.303335 (MainThread): 15:41:21 | 
2021-06-05 10:41:21.303658 (MainThread): 15:41:21 | Finished running 1 incremental model in 9.81s.
2021-06-05 10:41:21.303949 (MainThread): Connection 'master' was properly closed.
2021-06-05 10:41:21.304191 (MainThread): Connection 'model.werkspot_technical_challenge.dim_professional' was properly closed.
2021-06-05 10:41:21.319277 (MainThread): 
2021-06-05 10:41:21.319678 (MainThread): Completed successfully
2021-06-05 10:41:21.320060 (MainThread): 
Done. PASS=1 WARN=0 ERROR=0 SKIP=0 TOTAL=1
2021-06-05 10:41:21.320456 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fc6a438a9d0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fc6a444fc90>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fc6a43ada10>]}
2021-06-05 10:41:21.320724 (MainThread): Flushing usage events
2021-06-05 10:47:49.612949 (MainThread): Running with dbt=0.19.1
2021-06-05 10:47:50.721394 (MainThread): running dbt with arguments Namespace(cls=<class 'dbt.task.run.RunTask'>, debug=False, defer=None, exclude=None, fail_fast=False, full_refresh=False, log_cache_events=False, log_format='default', models=['dim_professional'], partial_parse=None, profile=None, profiles_dir='/Users/mac/.dbt', project_dir=None, record_timing_info=None, rpc_method='run', selector_name=None, single_threaded=False, state=None, strict=False, target=None, test_new_parser=False, threads=None, use_cache=True, use_colors=None, vars='{}', version_check=True, warn_error=False, which='run', write_json=True)
2021-06-05 10:47:50.722933 (MainThread): Tracking: tracking
2021-06-05 10:47:50.733838 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fd937dabd50>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fd93981b490>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fd93981b2d0>]}
2021-06-05 10:47:50.749016 (MainThread): Partial parsing not enabled
2021-06-05 10:47:50.750632 (MainThread): Parsing macros/etc.sql
2021-06-05 10:47:50.755215 (MainThread): Parsing macros/catalog.sql
2021-06-05 10:47:50.803969 (MainThread): Parsing macros/adapters.sql
2021-06-05 10:47:50.835827 (MainThread): Parsing macros/materializations/seed.sql
2021-06-05 10:47:50.840213 (MainThread): Parsing macros/materializations/view.sql
2021-06-05 10:47:50.844392 (MainThread): Parsing macros/materializations/table.sql
2021-06-05 10:47:50.859053 (MainThread): Parsing macros/materializations/copy.sql
2021-06-05 10:47:50.865571 (MainThread): Parsing macros/materializations/incremental.sql
2021-06-05 10:47:50.883426 (MainThread): Parsing macros/materializations/snapshot.sql
2021-06-05 10:47:50.887352 (MainThread): Parsing macros/core.sql
2021-06-05 10:47:50.892937 (MainThread): Parsing macros/materializations/helpers.sql
2021-06-05 10:47:50.905578 (MainThread): Parsing macros/materializations/snapshot/snapshot_merge.sql
2021-06-05 10:47:50.908222 (MainThread): Parsing macros/materializations/snapshot/strategies.sql
2021-06-05 10:47:50.933259 (MainThread): Parsing macros/materializations/snapshot/snapshot.sql
2021-06-05 10:47:50.993664 (MainThread): Parsing macros/materializations/seed/seed.sql
2021-06-05 10:47:51.024673 (MainThread): Parsing macros/materializations/incremental/helpers.sql
2021-06-05 10:47:51.036839 (MainThread): Parsing macros/materializations/incremental/incremental.sql
2021-06-05 10:47:51.060356 (MainThread): Parsing macros/materializations/common/merge.sql
2021-06-05 10:47:51.088431 (MainThread): Parsing macros/materializations/table/table.sql
2021-06-05 10:47:51.099829 (MainThread): Parsing macros/materializations/view/view.sql
2021-06-05 10:47:51.111877 (MainThread): Parsing macros/materializations/view/create_or_replace_view.sql
2021-06-05 10:47:51.119699 (MainThread): Parsing macros/etc/get_custom_alias.sql
2021-06-05 10:47:51.121378 (MainThread): Parsing macros/etc/query.sql
2021-06-05 10:47:51.123261 (MainThread): Parsing macros/etc/is_incremental.sql
2021-06-05 10:47:51.125725 (MainThread): Parsing macros/etc/datetime.sql
2021-06-05 10:47:51.138102 (MainThread): Parsing macros/etc/get_custom_schema.sql
2021-06-05 10:47:51.141118 (MainThread): Parsing macros/etc/get_custom_database.sql
2021-06-05 10:47:51.143836 (MainThread): Parsing macros/adapters/common.sql
2021-06-05 10:47:51.203221 (MainThread): Parsing macros/schema_tests/relationships.sql
2021-06-05 10:47:51.206084 (MainThread): Parsing macros/schema_tests/not_null.sql
2021-06-05 10:47:51.208555 (MainThread): Parsing macros/schema_tests/unique.sql
2021-06-05 10:47:51.211083 (MainThread): Parsing macros/schema_tests/accepted_values.sql
2021-06-05 10:47:51.224076 (MainThread): Partial parsing not enabled
2021-06-05 10:47:51.259019 (MainThread): Acquiring new bigquery connection "model.werkspot_technical_challenge.fct_fee".
2021-06-05 10:47:51.274318 (MainThread): Acquiring new bigquery connection "model.werkspot_technical_challenge.dim_service".
2021-06-05 10:47:51.287857 (MainThread): Acquiring new bigquery connection "model.werkspot_technical_challenge.dim_professional".
2021-06-05 10:47:51.303143 (MainThread): Acquiring new bigquery connection "model.werkspot_technical_challenge.dim_event".
2021-06-05 10:47:51.309207 (MainThread): Acquiring new bigquery connection "model.werkspot_technical_challenge.my_first_dbt_model".
2021-06-05 10:47:51.376365 (MainThread): Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '1973c2d7-d2a5-4980-b0e2-9f96a429fb0b', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fd9399b0dd0>]}
2021-06-05 10:47:51.392691 (MainThread): Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '1973c2d7-d2a5-4980-b0e2-9f96a429fb0b', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fd939a8f6d0>]}
2021-06-05 10:47:51.393201 (MainThread): Found 5 models, 0 tests, 0 snapshots, 0 analyses, 156 macros, 0 operations, 0 seed files, 0 sources, 0 exposures
2021-06-05 10:47:51.394391 (MainThread): 
2021-06-05 10:47:51.394933 (MainThread): Acquiring new bigquery connection "master".
2021-06-05 10:47:51.395916 (ThreadPoolExecutor-0_0): Acquiring new bigquery connection "list_poetic-genius-315513".
2021-06-05 10:47:51.396214 (ThreadPoolExecutor-0_0): Opening a new connection, currently in state init
2021-06-05 10:47:54.066937 (ThreadPoolExecutor-1_0): Acquiring new bigquery connection "list_poetic-genius-315513_events_information".
2021-06-05 10:47:54.067304 (ThreadPoolExecutor-1_0): Opening a new connection, currently in state closed
2021-06-05 10:47:54.067614 (ThreadPoolExecutor-1_0): Client.dataset is deprecated and will be removed in a future version. Use a string like 'my_project.my_dataset' or a cloud.google.bigquery.DatasetReference object, instead.
2021-06-05 10:47:55.219001 (MainThread): 15:47:55 | Concurrency: 1 threads (target='dev')
2021-06-05 10:47:55.219305 (MainThread): 15:47:55 | 
2021-06-05 10:47:55.222353 (Thread-1): Began running node model.werkspot_technical_challenge.dim_professional
2021-06-05 10:47:55.222781 (Thread-1): 15:47:55 | 1 of 1 START incremental model events_information.dim_professional... [RUN]
2021-06-05 10:47:55.223272 (Thread-1): Acquiring new bigquery connection "model.werkspot_technical_challenge.dim_professional".
2021-06-05 10:47:55.223578 (Thread-1): Compiling model.werkspot_technical_challenge.dim_professional
2021-06-05 10:47:55.225236 (Thread-1): unclosed <socket.socket fd=13, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('192.168.0.104', 53455), raddr=('142.250.185.42', 443)>
2021-06-05 10:47:55.231596 (Thread-1): Writing injected SQL for node "model.werkspot_technical_challenge.dim_professional"
2021-06-05 10:47:55.269714 (Thread-1): finished collecting timing info
2021-06-05 10:47:55.379247 (Thread-1): Writing runtime SQL for node "model.werkspot_technical_challenge.dim_professional"
2021-06-05 10:47:55.380401 (Thread-1): Opening a new connection, currently in state closed
2021-06-05 10:47:55.380917 (Thread-1): On model.werkspot_technical_challenge.dim_professional: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "werkspot_technical_challenge", "target_name": "dev", "node_id": "model.werkspot_technical_challenge.dim_professional"} */


  create or replace table `poetic-genius-315513`.`events_information`.`dim_professional`
  partition by datetime_trunc(AuditCreatedDateTime, day)
  
  OPTIONS()
  as (
    


SELECT
  DISTINCT 
    ParsedEventLog[OFFSET(2)] AS PK_ProfessionalID,
    CURRENT_DATETIME() as AuditCreatedDateTime,
    CURRENT_DATETIME() as AuditModifiedDateTime
FROM 
(

  SELECT 
    SPLIT(EventLogEntry,';') as ParsedEventLog
  FROM 
   `poetic-genius-315513.events_information_staging.events_log_data_stg`
      
      -- this filter will only be applied on an incremental run
      

)
  );
  
2021-06-05 10:47:59.401245 (Thread-1): finished collecting timing info
2021-06-05 10:47:59.402186 (Thread-1): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '1973c2d7-d2a5-4980-b0e2-9f96a429fb0b', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fd9399c22d0>]}
2021-06-05 10:47:59.402735 (Thread-1): 15:47:59 | 1 of 1 OK created incremental model events_information.dim_professional [CREATE TABLE (1.5k rows, 1.6 MB processed) in 4.18s]
2021-06-05 10:47:59.403013 (Thread-1): Finished running node model.werkspot_technical_challenge.dim_professional
2021-06-05 10:47:59.436378 (MainThread): Acquiring new bigquery connection "master".
2021-06-05 10:47:59.437642 (MainThread): 15:47:59 | 
2021-06-05 10:47:59.438069 (MainThread): 15:47:59 | Finished running 1 incremental model in 8.04s.
2021-06-05 10:47:59.438375 (MainThread): Connection 'master' was properly closed.
2021-06-05 10:47:59.438556 (MainThread): Connection 'model.werkspot_technical_challenge.dim_professional' was properly closed.
2021-06-05 10:47:59.452168 (MainThread): 
2021-06-05 10:47:59.452722 (MainThread): Completed successfully
2021-06-05 10:47:59.453003 (MainThread): 
Done. PASS=1 WARN=0 ERROR=0 SKIP=0 TOTAL=1
2021-06-05 10:47:59.453385 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fd939a93090>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fd9399c22d0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fd93986c750>]}
2021-06-05 10:47:59.453669 (MainThread): Flushing usage events
2021-06-05 11:07:00.574708 (MainThread): Running with dbt=0.19.1
2021-06-05 11:07:01.542169 (MainThread): running dbt with arguments Namespace(cls=<class 'dbt.task.run.RunTask'>, debug=False, defer=None, exclude=None, fail_fast=False, full_refresh=False, log_cache_events=False, log_format='default', models=['dim_service'], partial_parse=None, profile=None, profiles_dir='/Users/mac/.dbt', project_dir=None, record_timing_info=None, rpc_method='run', selector_name=None, single_threaded=False, state=None, strict=False, target=None, test_new_parser=False, threads=None, use_cache=True, use_colors=None, vars='{}', version_check=True, warn_error=False, which='run', write_json=True)
2021-06-05 11:07:01.543932 (MainThread): Tracking: tracking
2021-06-05 11:07:01.555629 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f82b811d190>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f82b80dbe50>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f82b811d150>]}
2021-06-05 11:07:01.571589 (MainThread): Partial parsing not enabled
2021-06-05 11:07:01.574019 (MainThread): Parsing macros/etc.sql
2021-06-05 11:07:01.579362 (MainThread): Parsing macros/catalog.sql
2021-06-05 11:07:01.588922 (MainThread): Parsing macros/adapters.sql
2021-06-05 11:07:01.619165 (MainThread): Parsing macros/materializations/seed.sql
2021-06-05 11:07:01.623449 (MainThread): Parsing macros/materializations/view.sql
2021-06-05 11:07:01.627864 (MainThread): Parsing macros/materializations/table.sql
2021-06-05 11:07:01.642715 (MainThread): Parsing macros/materializations/copy.sql
2021-06-05 11:07:01.650235 (MainThread): Parsing macros/materializations/incremental.sql
2021-06-05 11:07:01.669047 (MainThread): Parsing macros/materializations/snapshot.sql
2021-06-05 11:07:01.674948 (MainThread): Parsing macros/core.sql
2021-06-05 11:07:01.681408 (MainThread): Parsing macros/materializations/helpers.sql
2021-06-05 11:07:01.694523 (MainThread): Parsing macros/materializations/snapshot/snapshot_merge.sql
2021-06-05 11:07:01.697684 (MainThread): Parsing macros/materializations/snapshot/strategies.sql
2021-06-05 11:07:01.723130 (MainThread): Parsing macros/materializations/snapshot/snapshot.sql
2021-06-05 11:07:01.770844 (MainThread): Parsing macros/materializations/seed/seed.sql
2021-06-05 11:07:01.802289 (MainThread): Parsing macros/materializations/incremental/helpers.sql
2021-06-05 11:07:01.805332 (MainThread): Parsing macros/materializations/incremental/incremental.sql
2021-06-05 11:07:01.814956 (MainThread): Parsing macros/materializations/common/merge.sql
2021-06-05 11:07:01.836708 (MainThread): Parsing macros/materializations/table/table.sql
2021-06-05 11:07:01.846386 (MainThread): Parsing macros/materializations/view/view.sql
2021-06-05 11:07:01.855006 (MainThread): Parsing macros/materializations/view/create_or_replace_view.sql
2021-06-05 11:07:01.862948 (MainThread): Parsing macros/etc/get_custom_alias.sql
2021-06-05 11:07:01.864664 (MainThread): Parsing macros/etc/query.sql
2021-06-05 11:07:01.866484 (MainThread): Parsing macros/etc/is_incremental.sql
2021-06-05 11:07:01.869012 (MainThread): Parsing macros/etc/datetime.sql
2021-06-05 11:07:01.881468 (MainThread): Parsing macros/etc/get_custom_schema.sql
2021-06-05 11:07:01.884434 (MainThread): Parsing macros/etc/get_custom_database.sql
2021-06-05 11:07:01.886794 (MainThread): Parsing macros/adapters/common.sql
2021-06-05 11:07:01.945010 (MainThread): Parsing macros/schema_tests/relationships.sql
2021-06-05 11:07:01.948161 (MainThread): Parsing macros/schema_tests/not_null.sql
2021-06-05 11:07:01.950688 (MainThread): Parsing macros/schema_tests/unique.sql
2021-06-05 11:07:01.953327 (MainThread): Parsing macros/schema_tests/accepted_values.sql
2021-06-05 11:07:01.963538 (MainThread): Partial parsing not enabled
2021-06-05 11:07:01.997330 (MainThread): Acquiring new bigquery connection "model.werkspot_technical_challenge.fct_fee".
2021-06-05 11:07:02.017791 (MainThread): Acquiring new bigquery connection "model.werkspot_technical_challenge.dim_service".
2021-06-05 11:07:02.026799 (MainThread): Acquiring new bigquery connection "model.werkspot_technical_challenge.dim_professional".
2021-06-05 11:07:02.039518 (MainThread): Acquiring new bigquery connection "model.werkspot_technical_challenge.dim_event".
2021-06-05 11:07:02.045841 (MainThread): Acquiring new bigquery connection "model.werkspot_technical_challenge.my_first_dbt_model".
2021-06-05 11:07:02.113665 (MainThread): Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '1bfa1ec6-77c6-41b1-bd1d-da56ef706561', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f82b8431f50>]}
2021-06-05 11:07:02.129338 (MainThread): Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '1bfa1ec6-77c6-41b1-bd1d-da56ef706561', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f82b8426290>]}
2021-06-05 11:07:02.129706 (MainThread): Found 5 models, 0 tests, 0 snapshots, 0 analyses, 156 macros, 0 operations, 0 seed files, 0 sources, 0 exposures
2021-06-05 11:07:02.130574 (MainThread): 
2021-06-05 11:07:02.131000 (MainThread): Acquiring new bigquery connection "master".
2021-06-05 11:07:02.131971 (ThreadPoolExecutor-0_0): Acquiring new bigquery connection "list_poetic-genius-315513".
2021-06-05 11:07:02.132255 (ThreadPoolExecutor-0_0): Opening a new connection, currently in state init
2021-06-05 11:07:05.376342 (ThreadPoolExecutor-1_0): Acquiring new bigquery connection "list_poetic-genius-315513_events_information".
2021-06-05 11:07:05.376695 (ThreadPoolExecutor-1_0): Opening a new connection, currently in state closed
2021-06-05 11:07:05.377003 (ThreadPoolExecutor-1_0): Client.dataset is deprecated and will be removed in a future version. Use a string like 'my_project.my_dataset' or a cloud.google.bigquery.DatasetReference object, instead.
2021-06-05 11:07:06.707611 (MainThread): 16:07:06 | Concurrency: 1 threads (target='dev')
2021-06-05 11:07:06.708012 (MainThread): 16:07:06 | 
2021-06-05 11:07:06.711655 (Thread-1): Began running node model.werkspot_technical_challenge.dim_service
2021-06-05 11:07:06.712071 (Thread-1): 16:07:06 | 1 of 1 START incremental model events_information.dim_service........ [RUN]
2021-06-05 11:07:06.712575 (Thread-1): Acquiring new bigquery connection "model.werkspot_technical_challenge.dim_service".
2021-06-05 11:07:06.712779 (Thread-1): Compiling model.werkspot_technical_challenge.dim_service
2021-06-05 11:07:06.713781 (Thread-1): unclosed <socket.socket fd=13, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('192.168.0.104', 53707), raddr=('142.250.185.42', 443)>
2021-06-05 11:07:06.718088 (Thread-1): Writing injected SQL for node "model.werkspot_technical_challenge.dim_service"
2021-06-05 11:07:06.718644 (Thread-1): finished collecting timing info
2021-06-05 11:07:06.808460 (Thread-1): Writing runtime SQL for node "model.werkspot_technical_challenge.dim_service"
2021-06-05 11:07:06.810508 (Thread-1): Opening a new connection, currently in state closed
2021-06-05 11:07:06.811019 (Thread-1): On model.werkspot_technical_challenge.dim_service: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "werkspot_technical_challenge", "target_name": "dev", "node_id": "model.werkspot_technical_challenge.dim_service"} */


  create or replace table `poetic-genius-315513`.`events_information`.`dim_service`
  partition by datetime_trunc(AuditCreatedDateTime, day)
  
  OPTIONS()
  as (
    

SELECT
  DISTINCT 
    ParsedMetdata[OFFSET(0)] AS PK_ServiceID,
    ParsedMetdata[OFFSET(1)] AS ServiceNameEnglish,
    ParsedMetdata[OFFSET(2)] AS ServiceNameDutch,
    CURRENT_DATETIME() as AuditCreatedDateTime,
    CURRENT_DATETIME() as AuditModifiedDateTime
FROM 
(
  SELECT 
    SPLIT(ParsedEventLog,'_') AS ParsedMetdata
  FROM 
  (
    SELECT 
      SPLIT(EventLogEntry,';')[OFFSET(4)] as ParsedEventLog
    FROM 
     `poetic-genius-315513.events_information_staging.events_log_data_stg`
  ) 
  WHERE ParsedEventLog!=''
)
  );
  
2021-06-05 11:07:10.802690 (Thread-1): finished collecting timing info
2021-06-05 11:07:10.803585 (Thread-1): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '1bfa1ec6-77c6-41b1-bd1d-da56ef706561', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f82b82d8050>]}
2021-06-05 11:07:10.804401 (Thread-1): 16:07:10 | 1 of 1 OK created incremental model events_information.dim_service... [CREATE TABLE (171.0 rows, 1.6 MB processed) in 4.09s]
2021-06-05 11:07:10.804828 (Thread-1): Finished running node model.werkspot_technical_challenge.dim_service
2021-06-05 11:07:10.821323 (MainThread): Acquiring new bigquery connection "master".
2021-06-05 11:07:10.821941 (MainThread): 16:07:10 | 
2021-06-05 11:07:10.822181 (MainThread): 16:07:10 | Finished running 1 incremental model in 8.69s.
2021-06-05 11:07:10.822377 (MainThread): Connection 'master' was properly closed.
2021-06-05 11:07:10.822592 (MainThread): Connection 'model.werkspot_technical_challenge.dim_service' was properly closed.
2021-06-05 11:07:10.839961 (MainThread): 
2021-06-05 11:07:10.840256 (MainThread): Completed successfully
2021-06-05 11:07:10.840496 (MainThread): 
Done. PASS=1 WARN=0 ERROR=0 SKIP=0 TOTAL=1
2021-06-05 11:07:10.840832 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f82b83b0b50>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f82b83a7a90>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f82b81590d0>]}
2021-06-05 11:07:10.841099 (MainThread): Flushing usage events
2021-06-05 11:08:52.152224 (MainThread): Running with dbt=0.19.1
2021-06-05 11:08:53.105538 (MainThread): running dbt with arguments Namespace(cls=<class 'dbt.task.run.RunTask'>, debug=False, defer=None, exclude=None, fail_fast=False, full_refresh=False, log_cache_events=False, log_format='default', models=['dim_service'], partial_parse=None, profile=None, profiles_dir='/Users/mac/.dbt', project_dir=None, record_timing_info=None, rpc_method='run', selector_name=None, single_threaded=False, state=None, strict=False, target=None, test_new_parser=False, threads=None, use_cache=True, use_colors=None, vars='{}', version_check=True, warn_error=False, which='run', write_json=True)
2021-06-05 11:08:53.106925 (MainThread): Tracking: tracking
2021-06-05 11:08:53.117842 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fcb9d11b250>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fcb9d11b450>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fcb9d11b0d0>]}
2021-06-05 11:08:53.134252 (MainThread): Partial parsing not enabled
2021-06-05 11:08:53.137302 (MainThread): Parsing macros/etc.sql
2021-06-05 11:08:53.141947 (MainThread): Parsing macros/catalog.sql
2021-06-05 11:08:53.151210 (MainThread): Parsing macros/adapters.sql
2021-06-05 11:08:53.180012 (MainThread): Parsing macros/materializations/seed.sql
2021-06-05 11:08:53.183938 (MainThread): Parsing macros/materializations/view.sql
2021-06-05 11:08:53.187912 (MainThread): Parsing macros/materializations/table.sql
2021-06-05 11:08:53.201795 (MainThread): Parsing macros/materializations/copy.sql
2021-06-05 11:08:53.209237 (MainThread): Parsing macros/materializations/incremental.sql
2021-06-05 11:08:53.227460 (MainThread): Parsing macros/materializations/snapshot.sql
2021-06-05 11:08:53.232088 (MainThread): Parsing macros/core.sql
2021-06-05 11:08:53.237853 (MainThread): Parsing macros/materializations/helpers.sql
2021-06-05 11:08:53.250745 (MainThread): Parsing macros/materializations/snapshot/snapshot_merge.sql
2021-06-05 11:08:53.253768 (MainThread): Parsing macros/materializations/snapshot/strategies.sql
2021-06-05 11:08:53.278497 (MainThread): Parsing macros/materializations/snapshot/snapshot.sql
2021-06-05 11:08:53.324632 (MainThread): Parsing macros/materializations/seed/seed.sql
2021-06-05 11:08:53.356287 (MainThread): Parsing macros/materializations/incremental/helpers.sql
2021-06-05 11:08:53.359277 (MainThread): Parsing macros/materializations/incremental/incremental.sql
2021-06-05 11:08:53.368020 (MainThread): Parsing macros/materializations/common/merge.sql
2021-06-05 11:08:53.387073 (MainThread): Parsing macros/materializations/table/table.sql
2021-06-05 11:08:53.396711 (MainThread): Parsing macros/materializations/view/view.sql
2021-06-05 11:08:53.405267 (MainThread): Parsing macros/materializations/view/create_or_replace_view.sql
2021-06-05 11:08:53.412363 (MainThread): Parsing macros/etc/get_custom_alias.sql
2021-06-05 11:08:53.414101 (MainThread): Parsing macros/etc/query.sql
2021-06-05 11:08:53.415830 (MainThread): Parsing macros/etc/is_incremental.sql
2021-06-05 11:08:53.418388 (MainThread): Parsing macros/etc/datetime.sql
2021-06-05 11:08:53.430734 (MainThread): Parsing macros/etc/get_custom_schema.sql
2021-06-05 11:08:53.433752 (MainThread): Parsing macros/etc/get_custom_database.sql
2021-06-05 11:08:53.436394 (MainThread): Parsing macros/adapters/common.sql
2021-06-05 11:08:53.494957 (MainThread): Parsing macros/schema_tests/relationships.sql
2021-06-05 11:08:53.497609 (MainThread): Parsing macros/schema_tests/not_null.sql
2021-06-05 11:08:53.499764 (MainThread): Parsing macros/schema_tests/unique.sql
2021-06-05 11:08:53.502099 (MainThread): Parsing macros/schema_tests/accepted_values.sql
2021-06-05 11:08:53.512600 (MainThread): Partial parsing not enabled
2021-06-05 11:08:53.545798 (MainThread): Acquiring new bigquery connection "model.werkspot_technical_challenge.fct_fee".
2021-06-05 11:08:53.567259 (MainThread): Acquiring new bigquery connection "model.werkspot_technical_challenge.dim_service".
2021-06-05 11:08:53.581737 (MainThread): Acquiring new bigquery connection "model.werkspot_technical_challenge.dim_professional".
2021-06-05 11:08:53.589406 (MainThread): Acquiring new bigquery connection "model.werkspot_technical_challenge.dim_event".
2021-06-05 11:08:53.595442 (MainThread): Acquiring new bigquery connection "model.werkspot_technical_challenge.my_first_dbt_model".
2021-06-05 11:08:53.660382 (MainThread): Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '8e1c21b9-41d6-487d-8564-ce1b7e24a750', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fcb9d43ad90>]}
2021-06-05 11:08:53.676953 (MainThread): Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '8e1c21b9-41d6-487d-8564-ce1b7e24a750', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fcb9d41b190>]}
2021-06-05 11:08:53.677333 (MainThread): Found 5 models, 0 tests, 0 snapshots, 0 analyses, 156 macros, 0 operations, 0 seed files, 0 sources, 0 exposures
2021-06-05 11:08:53.678229 (MainThread): 
2021-06-05 11:08:53.678755 (MainThread): Acquiring new bigquery connection "master".
2021-06-05 11:08:53.679766 (ThreadPoolExecutor-0_0): Acquiring new bigquery connection "list_poetic-genius-315513".
2021-06-05 11:08:53.680219 (ThreadPoolExecutor-0_0): Opening a new connection, currently in state init
2021-06-05 11:08:56.255052 (ThreadPoolExecutor-1_0): Acquiring new bigquery connection "list_poetic-genius-315513_events_information".
2021-06-05 11:08:56.255429 (ThreadPoolExecutor-1_0): Opening a new connection, currently in state closed
2021-06-05 11:08:56.255749 (ThreadPoolExecutor-1_0): Client.dataset is deprecated and will be removed in a future version. Use a string like 'my_project.my_dataset' or a cloud.google.bigquery.DatasetReference object, instead.
2021-06-05 11:08:57.411952 (MainThread): 16:08:57 | Concurrency: 1 threads (target='dev')
2021-06-05 11:08:57.412226 (MainThread): 16:08:57 | 
2021-06-05 11:08:57.414513 (Thread-1): Began running node model.werkspot_technical_challenge.dim_service
2021-06-05 11:08:57.414936 (Thread-1): 16:08:57 | 1 of 1 START incremental model events_information.dim_service........ [RUN]
2021-06-05 11:08:57.415702 (Thread-1): Acquiring new bigquery connection "model.werkspot_technical_challenge.dim_service".
2021-06-05 11:08:57.415983 (Thread-1): Compiling model.werkspot_technical_challenge.dim_service
2021-06-05 11:08:57.416943 (Thread-1): unclosed <socket.socket fd=13, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('192.168.0.104', 53746), raddr=('142.250.185.42', 443)>
2021-06-05 11:08:57.422441 (Thread-1): Writing injected SQL for node "model.werkspot_technical_challenge.dim_service"
2021-06-05 11:08:57.423011 (Thread-1): finished collecting timing info
2021-06-05 11:08:57.491829 (Thread-1): Writing runtime SQL for node "model.werkspot_technical_challenge.dim_service"
2021-06-05 11:08:57.492451 (Thread-1): Opening a new connection, currently in state closed
2021-06-05 11:08:57.492664 (Thread-1): On model.werkspot_technical_challenge.dim_service: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "werkspot_technical_challenge", "target_name": "dev", "node_id": "model.werkspot_technical_challenge.dim_service"} */


  create or replace table `poetic-genius-315513`.`events_information`.`dim_service`
  partition by datetime_trunc(AuditCreatedDateTime, day)
  
  OPTIONS()
  as (
    

SELECT
  DISTINCT 
    ParsedMetdata[OFFSET(0)] AS PK_ServiceID,
    ParsedMetdata[OFFSET(1)] AS ServiceNameDutch,
    ParsedMetdata[OFFSET(2)] AS ServiceNameEnglish,
    CURRENT_DATETIME() as AuditCreatedDateTime,
    CURRENT_DATETIME() as AuditModifiedDateTime
FROM 
(
  SELECT 
    SPLIT(ParsedEventLog,'_') AS ParsedMetdata
  FROM 
  (
    SELECT 
      SPLIT(EventLogEntry,';')[OFFSET(4)] as ParsedEventLog
    FROM 
     `poetic-genius-315513.events_information_staging.events_log_data_stg`

      -- this filter will only be applied on an incremental run
      
  ) 
  WHERE ParsedEventLog!=''
)
  );
  
2021-06-05 11:09:01.286239 (Thread-1): finished collecting timing info
2021-06-05 11:09:01.286821 (Thread-1): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '8e1c21b9-41d6-487d-8564-ce1b7e24a750', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fcb9d2bcc90>]}
2021-06-05 11:09:01.287268 (Thread-1): 16:09:01 | 1 of 1 OK created incremental model events_information.dim_service... [CREATE TABLE (171.0 rows, 1.6 MB processed) in 3.87s]
2021-06-05 11:09:01.287469 (Thread-1): Finished running node model.werkspot_technical_challenge.dim_service
2021-06-05 11:09:01.320671 (MainThread): Acquiring new bigquery connection "master".
2021-06-05 11:09:01.321304 (MainThread): 16:09:01 | 
2021-06-05 11:09:01.321568 (MainThread): 16:09:01 | Finished running 1 incremental model in 7.64s.
2021-06-05 11:09:01.321921 (MainThread): Connection 'master' was properly closed.
2021-06-05 11:09:01.322153 (MainThread): Connection 'model.werkspot_technical_challenge.dim_service' was properly closed.
2021-06-05 11:09:01.335260 (MainThread): 
2021-06-05 11:09:01.335529 (MainThread): Completed successfully
2021-06-05 11:09:01.335840 (MainThread): 
Done. PASS=1 WARN=0 ERROR=0 SKIP=0 TOTAL=1
2021-06-05 11:09:01.336231 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fcb9d3ae8d0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fcb9d2bcc90>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fcb9d3a7190>]}
2021-06-05 11:09:01.336546 (MainThread): Flushing usage events
2021-06-05 11:11:40.517038 (MainThread): Running with dbt=0.19.1
2021-06-05 11:11:41.648659 (MainThread): running dbt with arguments Namespace(cls=<class 'dbt.task.run.RunTask'>, debug=False, defer=None, exclude=None, fail_fast=False, full_refresh=False, log_cache_events=False, log_format='default', models=['dim_service'], partial_parse=None, profile=None, profiles_dir='/Users/mac/.dbt', project_dir=None, record_timing_info=None, rpc_method='run', selector_name=None, single_threaded=False, state=None, strict=False, target=None, test_new_parser=False, threads=None, use_cache=True, use_colors=None, vars='{}', version_check=True, warn_error=False, which='run', write_json=True)
2021-06-05 11:11:41.651970 (MainThread): Tracking: tracking
2021-06-05 11:11:41.665451 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ff05c7f1350>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ff05c7f1690>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ff05c7f14d0>]}
2021-06-05 11:11:41.680458 (MainThread): Partial parsing not enabled
2021-06-05 11:11:41.682081 (MainThread): Parsing macros/etc.sql
2021-06-05 11:11:41.687229 (MainThread): Parsing macros/catalog.sql
2021-06-05 11:11:41.696225 (MainThread): Parsing macros/adapters.sql
2021-06-05 11:11:41.725292 (MainThread): Parsing macros/materializations/seed.sql
2021-06-05 11:11:41.729384 (MainThread): Parsing macros/materializations/view.sql
2021-06-05 11:11:41.733631 (MainThread): Parsing macros/materializations/table.sql
2021-06-05 11:11:41.748237 (MainThread): Parsing macros/materializations/copy.sql
2021-06-05 11:11:41.755363 (MainThread): Parsing macros/materializations/incremental.sql
2021-06-05 11:11:41.775256 (MainThread): Parsing macros/materializations/snapshot.sql
2021-06-05 11:11:41.780193 (MainThread): Parsing macros/core.sql
2021-06-05 11:11:41.786459 (MainThread): Parsing macros/materializations/helpers.sql
2021-06-05 11:11:41.800636 (MainThread): Parsing macros/materializations/snapshot/snapshot_merge.sql
2021-06-05 11:11:41.803418 (MainThread): Parsing macros/materializations/snapshot/strategies.sql
2021-06-05 11:11:41.830427 (MainThread): Parsing macros/materializations/snapshot/snapshot.sql
2021-06-05 11:11:41.879606 (MainThread): Parsing macros/materializations/seed/seed.sql
2021-06-05 11:11:41.912036 (MainThread): Parsing macros/materializations/incremental/helpers.sql
2021-06-05 11:11:41.915506 (MainThread): Parsing macros/materializations/incremental/incremental.sql
2021-06-05 11:11:41.928292 (MainThread): Parsing macros/materializations/common/merge.sql
2021-06-05 11:11:41.953993 (MainThread): Parsing macros/materializations/table/table.sql
2021-06-05 11:11:41.963801 (MainThread): Parsing macros/materializations/view/view.sql
2021-06-05 11:11:41.972761 (MainThread): Parsing macros/materializations/view/create_or_replace_view.sql
2021-06-05 11:11:41.979961 (MainThread): Parsing macros/etc/get_custom_alias.sql
2021-06-05 11:11:41.981521 (MainThread): Parsing macros/etc/query.sql
2021-06-05 11:11:41.983175 (MainThread): Parsing macros/etc/is_incremental.sql
2021-06-05 11:11:41.985520 (MainThread): Parsing macros/etc/datetime.sql
2021-06-05 11:11:41.997432 (MainThread): Parsing macros/etc/get_custom_schema.sql
2021-06-05 11:11:42.000119 (MainThread): Parsing macros/etc/get_custom_database.sql
2021-06-05 11:11:42.002776 (MainThread): Parsing macros/adapters/common.sql
2021-06-05 11:11:42.061602 (MainThread): Parsing macros/schema_tests/relationships.sql
2021-06-05 11:11:42.065514 (MainThread): Parsing macros/schema_tests/not_null.sql
2021-06-05 11:11:42.069898 (MainThread): Parsing macros/schema_tests/unique.sql
2021-06-05 11:11:42.074155 (MainThread): Parsing macros/schema_tests/accepted_values.sql
2021-06-05 11:11:42.086064 (MainThread): Partial parsing not enabled
2021-06-05 11:11:42.120598 (MainThread): Acquiring new bigquery connection "model.werkspot_technical_challenge.fct_fee".
2021-06-05 11:11:42.139980 (MainThread): Acquiring new bigquery connection "model.werkspot_technical_challenge.dim_service".
2021-06-05 11:11:42.154412 (MainThread): Acquiring new bigquery connection "model.werkspot_technical_challenge.dim_professional".
2021-06-05 11:11:42.162189 (MainThread): Acquiring new bigquery connection "model.werkspot_technical_challenge.dim_event".
2021-06-05 11:11:42.168584 (MainThread): Acquiring new bigquery connection "model.werkspot_technical_challenge.my_first_dbt_model".
2021-06-05 11:11:42.234304 (MainThread): Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'aa29156b-d64f-480c-b6f4-4e21f98e1daf', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ff05c87e090>]}
2021-06-05 11:11:42.250698 (MainThread): Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'aa29156b-d64f-480c-b6f4-4e21f98e1daf', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ff05cafc2d0>]}
2021-06-05 11:11:42.251228 (MainThread): Found 5 models, 0 tests, 0 snapshots, 0 analyses, 156 macros, 0 operations, 0 seed files, 0 sources, 0 exposures
2021-06-05 11:11:42.252577 (MainThread): 
2021-06-05 11:11:42.253072 (MainThread): Acquiring new bigquery connection "master".
2021-06-05 11:11:42.254115 (ThreadPoolExecutor-0_0): Acquiring new bigquery connection "list_poetic-genius-315513".
2021-06-05 11:11:42.254422 (ThreadPoolExecutor-0_0): Opening a new connection, currently in state init
2021-06-05 11:11:44.700905 (ThreadPoolExecutor-1_0): Acquiring new bigquery connection "list_poetic-genius-315513_events_information".
2021-06-05 11:11:44.701278 (ThreadPoolExecutor-1_0): Opening a new connection, currently in state closed
2021-06-05 11:11:44.701577 (ThreadPoolExecutor-1_0): Client.dataset is deprecated and will be removed in a future version. Use a string like 'my_project.my_dataset' or a cloud.google.bigquery.DatasetReference object, instead.
2021-06-05 11:11:45.829959 (MainThread): 16:11:45 | Concurrency: 1 threads (target='dev')
2021-06-05 11:11:45.830338 (MainThread): 16:11:45 | 
2021-06-05 11:11:45.832735 (Thread-1): Began running node model.werkspot_technical_challenge.dim_service
2021-06-05 11:11:45.833174 (Thread-1): 16:11:45 | 1 of 1 START incremental model events_information.dim_service........ [RUN]
2021-06-05 11:11:45.833670 (Thread-1): Acquiring new bigquery connection "model.werkspot_technical_challenge.dim_service".
2021-06-05 11:11:45.833886 (Thread-1): Compiling model.werkspot_technical_challenge.dim_service
2021-06-05 11:11:45.834774 (Thread-1): unclosed <socket.socket fd=13, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('192.168.0.104', 53795), raddr=('142.250.185.42', 443)>
2021-06-05 11:11:45.840446 (Thread-1): Writing injected SQL for node "model.werkspot_technical_challenge.dim_service"
2021-06-05 11:11:45.841015 (Thread-1): finished collecting timing info
2021-06-05 11:11:45.909374 (Thread-1): Writing runtime SQL for node "model.werkspot_technical_challenge.dim_service"
2021-06-05 11:11:45.909946 (Thread-1): Opening a new connection, currently in state closed
2021-06-05 11:11:45.910126 (Thread-1): On model.werkspot_technical_challenge.dim_service: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "werkspot_technical_challenge", "target_name": "dev", "node_id": "model.werkspot_technical_challenge.dim_service"} */


  create or replace table `poetic-genius-315513`.`events_information`.`dim_service`
  partition by datetime_trunc(AuditCreatedDateTime, day)
  
  OPTIONS()
  as (
    

SELECT  -- ADDING one extra select so that results could be sorted based on PK_ServiceID
  *
FROM 
(
  SELECT
    DISTINCT 
      ParsedMetdata[OFFSET(0)] AS PK_ServiceID,
      ParsedMetdata[OFFSET(1)] AS ServiceNameDutch,
      ParsedMetdata[OFFSET(2)] AS ServiceNameEnglish,
      CURRENT_DATETIME() as AuditCreatedDateTime,
      CURRENT_DATETIME() as AuditModifiedDateTime
  FROM 
  (
    SELECT 
      SPLIT(ParsedEventLog,'_') AS ParsedMetdata
    FROM 
    (
      SELECT 
        SPLIT(EventLogEntry,';')[OFFSET(4)] as ParsedEventLog
      FROM 
       `poetic-genius-315513.events_information_staging.events_log_data_stg`

        -- this filter will only be applied on an incremental run
        
    ) 
    WHERE ParsedEventLog!=''
  )
)
  );
  
2021-06-05 11:11:50.233316 (Thread-1): finished collecting timing info
2021-06-05 11:11:50.233883 (Thread-1): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'aa29156b-d64f-480c-b6f4-4e21f98e1daf', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ff05c9a3510>]}
2021-06-05 11:11:50.234366 (Thread-1): 16:11:50 | 1 of 1 OK created incremental model events_information.dim_service... [CREATE TABLE (171.0 rows, 1.6 MB processed) in 4.40s]
2021-06-05 11:11:50.234588 (Thread-1): Finished running node model.werkspot_technical_challenge.dim_service
2021-06-05 11:11:50.270955 (MainThread): Acquiring new bigquery connection "master".
2021-06-05 11:11:50.271759 (MainThread): 16:11:50 | 
2021-06-05 11:11:50.272103 (MainThread): 16:11:50 | Finished running 1 incremental model in 8.02s.
2021-06-05 11:11:50.272414 (MainThread): Connection 'master' was properly closed.
2021-06-05 11:11:50.272671 (MainThread): Connection 'model.werkspot_technical_challenge.dim_service' was properly closed.
2021-06-05 11:11:50.283735 (MainThread): 
2021-06-05 11:11:50.284103 (MainThread): Completed successfully
2021-06-05 11:11:50.284456 (MainThread): 
Done. PASS=1 WARN=0 ERROR=0 SKIP=0 TOTAL=1
2021-06-05 11:11:50.285246 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ff05c9a3510>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ff05c9a5750>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ff05cb3ed10>]}
2021-06-05 11:11:50.285672 (MainThread): Flushing usage events
2021-06-05 11:14:58.573301 (MainThread): Running with dbt=0.19.1
2021-06-05 11:14:59.539704 (MainThread): running dbt with arguments Namespace(cls=<class 'dbt.task.run.RunTask'>, debug=False, defer=None, exclude=None, fail_fast=False, full_refresh=False, log_cache_events=False, log_format='default', models=['dim_professional'], partial_parse=None, profile=None, profiles_dir='/Users/mac/.dbt', project_dir=None, record_timing_info=None, rpc_method='run', selector_name=None, single_threaded=False, state=None, strict=False, target=None, test_new_parser=False, threads=None, use_cache=True, use_colors=None, vars='{}', version_check=True, warn_error=False, which='run', write_json=True)
2021-06-05 11:14:59.540957 (MainThread): Tracking: tracking
2021-06-05 11:14:59.554485 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f8dcf11b150>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f8dcf11b550>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f8dcf11b450>]}
2021-06-05 11:14:59.570322 (MainThread): Partial parsing not enabled
2021-06-05 11:14:59.572378 (MainThread): Parsing macros/etc.sql
2021-06-05 11:14:59.577260 (MainThread): Parsing macros/catalog.sql
2021-06-05 11:14:59.586483 (MainThread): Parsing macros/adapters.sql
2021-06-05 11:14:59.616514 (MainThread): Parsing macros/materializations/seed.sql
2021-06-05 11:14:59.621302 (MainThread): Parsing macros/materializations/view.sql
2021-06-05 11:14:59.625672 (MainThread): Parsing macros/materializations/table.sql
2021-06-05 11:14:59.640414 (MainThread): Parsing macros/materializations/copy.sql
2021-06-05 11:14:59.648293 (MainThread): Parsing macros/materializations/incremental.sql
2021-06-05 11:14:59.666874 (MainThread): Parsing macros/materializations/snapshot.sql
2021-06-05 11:14:59.671555 (MainThread): Parsing macros/core.sql
2021-06-05 11:14:59.677707 (MainThread): Parsing macros/materializations/helpers.sql
2021-06-05 11:14:59.690472 (MainThread): Parsing macros/materializations/snapshot/snapshot_merge.sql
2021-06-05 11:14:59.693115 (MainThread): Parsing macros/materializations/snapshot/strategies.sql
2021-06-05 11:14:59.717748 (MainThread): Parsing macros/materializations/snapshot/snapshot.sql
2021-06-05 11:14:59.765843 (MainThread): Parsing macros/materializations/seed/seed.sql
2021-06-05 11:14:59.794877 (MainThread): Parsing macros/materializations/incremental/helpers.sql
2021-06-05 11:14:59.797570 (MainThread): Parsing macros/materializations/incremental/incremental.sql
2021-06-05 11:14:59.806354 (MainThread): Parsing macros/materializations/common/merge.sql
2021-06-05 11:14:59.826762 (MainThread): Parsing macros/materializations/table/table.sql
2021-06-05 11:14:59.836158 (MainThread): Parsing macros/materializations/view/view.sql
2021-06-05 11:14:59.844642 (MainThread): Parsing macros/materializations/view/create_or_replace_view.sql
2021-06-05 11:14:59.851642 (MainThread): Parsing macros/etc/get_custom_alias.sql
2021-06-05 11:14:59.853291 (MainThread): Parsing macros/etc/query.sql
2021-06-05 11:14:59.855011 (MainThread): Parsing macros/etc/is_incremental.sql
2021-06-05 11:14:59.857554 (MainThread): Parsing macros/etc/datetime.sql
2021-06-05 11:14:59.869668 (MainThread): Parsing macros/etc/get_custom_schema.sql
2021-06-05 11:14:59.872481 (MainThread): Parsing macros/etc/get_custom_database.sql
2021-06-05 11:14:59.875232 (MainThread): Parsing macros/adapters/common.sql
2021-06-05 11:14:59.933752 (MainThread): Parsing macros/schema_tests/relationships.sql
2021-06-05 11:14:59.936587 (MainThread): Parsing macros/schema_tests/not_null.sql
2021-06-05 11:14:59.938684 (MainThread): Parsing macros/schema_tests/unique.sql
2021-06-05 11:14:59.941005 (MainThread): Parsing macros/schema_tests/accepted_values.sql
2021-06-05 11:14:59.951669 (MainThread): Partial parsing not enabled
2021-06-05 11:14:59.984506 (MainThread): Acquiring new bigquery connection "model.werkspot_technical_challenge.fct_fee".
2021-06-05 11:14:59.997770 (MainThread): Acquiring new bigquery connection "model.werkspot_technical_challenge.dim_service".
2021-06-05 11:15:00.024181 (MainThread): Acquiring new bigquery connection "model.werkspot_technical_challenge.dim_professional".
2021-06-05 11:15:00.031974 (MainThread): Acquiring new bigquery connection "model.werkspot_technical_challenge.dim_event".
2021-06-05 11:15:00.038254 (MainThread): Acquiring new bigquery connection "model.werkspot_technical_challenge.my_first_dbt_model".
2021-06-05 11:15:00.107424 (MainThread): Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '73f02447-6624-4bd7-b520-bcc64ed73330', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f8dcf37ed90>]}
2021-06-05 11:15:00.122853 (MainThread): Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '73f02447-6624-4bd7-b520-bcc64ed73330', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f8dcf384410>]}
2021-06-05 11:15:00.123226 (MainThread): Found 5 models, 0 tests, 0 snapshots, 0 analyses, 156 macros, 0 operations, 0 seed files, 0 sources, 0 exposures
2021-06-05 11:15:00.124129 (MainThread): 
2021-06-05 11:15:00.124624 (MainThread): Acquiring new bigquery connection "master".
2021-06-05 11:15:00.125585 (ThreadPoolExecutor-0_0): Acquiring new bigquery connection "list_poetic-genius-315513".
2021-06-05 11:15:00.125877 (ThreadPoolExecutor-0_0): Opening a new connection, currently in state init
2021-06-05 11:15:02.753487 (ThreadPoolExecutor-1_0): Acquiring new bigquery connection "list_poetic-genius-315513_events_information".
2021-06-05 11:15:02.753862 (ThreadPoolExecutor-1_0): Opening a new connection, currently in state closed
2021-06-05 11:15:02.754179 (ThreadPoolExecutor-1_0): Client.dataset is deprecated and will be removed in a future version. Use a string like 'my_project.my_dataset' or a cloud.google.bigquery.DatasetReference object, instead.
2021-06-05 11:15:03.885106 (MainThread): 16:15:03 | Concurrency: 1 threads (target='dev')
2021-06-05 11:15:03.885520 (MainThread): 16:15:03 | 
2021-06-05 11:15:03.887990 (Thread-1): Began running node model.werkspot_technical_challenge.dim_professional
2021-06-05 11:15:03.888374 (Thread-1): 16:15:03 | 1 of 1 START incremental model events_information.dim_professional... [RUN]
2021-06-05 11:15:03.888839 (Thread-1): Acquiring new bigquery connection "model.werkspot_technical_challenge.dim_professional".
2021-06-05 11:15:03.889045 (Thread-1): Compiling model.werkspot_technical_challenge.dim_professional
2021-06-05 11:15:03.889997 (Thread-1): unclosed <socket.socket fd=13, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('192.168.0.104', 53866), raddr=('142.250.185.42', 443)>
2021-06-05 11:15:03.894807 (Thread-1): Writing injected SQL for node "model.werkspot_technical_challenge.dim_professional"
2021-06-05 11:15:03.895615 (Thread-1): finished collecting timing info
2021-06-05 11:15:03.966550 (Thread-1): Writing runtime SQL for node "model.werkspot_technical_challenge.dim_professional"
2021-06-05 11:15:03.967128 (Thread-1): Opening a new connection, currently in state closed
2021-06-05 11:15:03.967304 (Thread-1): On model.werkspot_technical_challenge.dim_professional: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "werkspot_technical_challenge", "target_name": "dev", "node_id": "model.werkspot_technical_challenge.dim_professional"} */


  create or replace table `poetic-genius-315513`.`events_information`.`dim_professional`
  partition by datetime_trunc(AuditCreatedDateTime, day)
  
  OPTIONS()
  as (
    


SELECT
  DISTINCT 
    CAST(ParsedEventLog[OFFSET(2)] AS INT64) AS PK_ProfessionalID,
    CURRENT_DATETIME() as AuditCreatedDateTime,
    CURRENT_DATETIME() as AuditModifiedDateTime
FROM 
(

  SELECT 
    SPLIT(EventLogEntry,';') as ParsedEventLog
  FROM 
   `poetic-genius-315513.events_information_staging.events_log_data_stg`
      
      -- this filter will only be applied on an incremental run
      

)
  );
  
2021-06-05 11:15:08.609821 (Thread-1): finished collecting timing info
2021-06-05 11:15:08.610419 (Thread-1): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '73f02447-6624-4bd7-b520-bcc64ed73330', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f8dcf303ad0>]}
2021-06-05 11:15:08.610935 (Thread-1): 16:15:08 | 1 of 1 OK created incremental model events_information.dim_professional [CREATE TABLE (1.5k rows, 1.6 MB processed) in 4.72s]
2021-06-05 11:15:08.611155 (Thread-1): Finished running node model.werkspot_technical_challenge.dim_professional
2021-06-05 11:15:08.657900 (MainThread): Acquiring new bigquery connection "master".
2021-06-05 11:15:08.658539 (MainThread): 16:15:08 | 
2021-06-05 11:15:08.658807 (MainThread): 16:15:08 | Finished running 1 incremental model in 8.53s.
2021-06-05 11:15:08.659171 (MainThread): Connection 'master' was properly closed.
2021-06-05 11:15:08.659395 (MainThread): Connection 'model.werkspot_technical_challenge.dim_professional' was properly closed.
2021-06-05 11:15:08.672008 (MainThread): 
2021-06-05 11:15:08.672280 (MainThread): Completed successfully
2021-06-05 11:15:08.672524 (MainThread): 
Done. PASS=1 WARN=0 ERROR=0 SKIP=0 TOTAL=1
2021-06-05 11:15:08.672866 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f8dcf2ce1d0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f8dcf303ad0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f8dcf380390>]}
2021-06-05 11:15:08.673291 (MainThread): Flushing usage events
2021-06-05 15:35:51.627418 (MainThread): Running with dbt=0.19.1
2021-06-05 15:35:52.806085 (MainThread): running dbt with arguments Namespace(cls=<class 'dbt.task.run.RunTask'>, debug=False, defer=None, exclude=None, fail_fast=False, full_refresh=False, log_cache_events=False, log_format='default', models=['dim_professional'], partial_parse=None, profile=None, profiles_dir='/Users/mac/.dbt', project_dir=None, record_timing_info=None, rpc_method='run', selector_name=None, single_threaded=False, state=None, strict=False, target=None, test_new_parser=False, threads=None, use_cache=True, use_colors=None, vars='{}', version_check=True, warn_error=False, which='run', write_json=True)
2021-06-05 15:35:52.808202 (MainThread): Tracking: tracking
2021-06-05 15:35:52.822696 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ff27d91c210>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ff27d91c4d0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ff27d91c110>]}
2021-06-05 15:35:52.870948 (MainThread): Partial parsing not enabled
2021-06-05 15:35:52.872682 (MainThread): Parsing macros/etc.sql
2021-06-05 15:35:52.877632 (MainThread): Parsing macros/catalog.sql
2021-06-05 15:35:52.886726 (MainThread): Parsing macros/adapters.sql
2021-06-05 15:35:52.918305 (MainThread): Parsing macros/materializations/seed.sql
2021-06-05 15:35:52.923823 (MainThread): Parsing macros/materializations/view.sql
2021-06-05 15:35:52.928511 (MainThread): Parsing macros/materializations/table.sql
2021-06-05 15:35:52.942177 (MainThread): Parsing macros/materializations/copy.sql
2021-06-05 15:35:52.948621 (MainThread): Parsing macros/materializations/incremental.sql
2021-06-05 15:35:52.966184 (MainThread): Parsing macros/materializations/snapshot.sql
2021-06-05 15:35:52.970646 (MainThread): Parsing macros/core.sql
2021-06-05 15:35:52.976090 (MainThread): Parsing macros/materializations/helpers.sql
2021-06-05 15:35:52.988157 (MainThread): Parsing macros/materializations/snapshot/snapshot_merge.sql
2021-06-05 15:35:52.990782 (MainThread): Parsing macros/materializations/snapshot/strategies.sql
2021-06-05 15:35:53.015158 (MainThread): Parsing macros/materializations/snapshot/snapshot.sql
2021-06-05 15:35:53.060643 (MainThread): Parsing macros/materializations/seed/seed.sql
2021-06-05 15:35:53.088838 (MainThread): Parsing macros/materializations/incremental/helpers.sql
2021-06-05 15:35:53.091588 (MainThread): Parsing macros/materializations/incremental/incremental.sql
2021-06-05 15:35:53.100573 (MainThread): Parsing macros/materializations/common/merge.sql
2021-06-05 15:35:53.119444 (MainThread): Parsing macros/materializations/table/table.sql
2021-06-05 15:35:53.128571 (MainThread): Parsing macros/materializations/view/view.sql
2021-06-05 15:35:53.136992 (MainThread): Parsing macros/materializations/view/create_or_replace_view.sql
2021-06-05 15:35:53.143615 (MainThread): Parsing macros/etc/get_custom_alias.sql
2021-06-05 15:35:53.144961 (MainThread): Parsing macros/etc/query.sql
2021-06-05 15:35:53.146565 (MainThread): Parsing macros/etc/is_incremental.sql
2021-06-05 15:35:53.148833 (MainThread): Parsing macros/etc/datetime.sql
2021-06-05 15:35:53.160646 (MainThread): Parsing macros/etc/get_custom_schema.sql
2021-06-05 15:35:53.163318 (MainThread): Parsing macros/etc/get_custom_database.sql
2021-06-05 15:35:53.165622 (MainThread): Parsing macros/adapters/common.sql
2021-06-05 15:35:53.223358 (MainThread): Parsing macros/schema_tests/relationships.sql
2021-06-05 15:35:53.226075 (MainThread): Parsing macros/schema_tests/not_null.sql
2021-06-05 15:35:53.228598 (MainThread): Parsing macros/schema_tests/unique.sql
2021-06-05 15:35:53.231217 (MainThread): Parsing macros/schema_tests/accepted_values.sql
2021-06-05 15:35:53.241562 (MainThread): Partial parsing not enabled
2021-06-05 15:35:53.276078 (MainThread): Acquiring new bigquery connection "model.werkspot_technical_challenge.dim_service".
2021-06-05 15:35:53.287232 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ff27d977150>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ff27d975b10>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ff27dabbc50>]}
2021-06-05 15:35:53.287708 (MainThread): Flushing usage events
2021-06-05 15:35:54.571104 (MainThread): Connection 'model.werkspot_technical_challenge.dim_service' was properly closed.
2021-06-05 15:35:54.571366 (MainThread): Encountered an error:
2021-06-05 15:35:54.571575 (MainThread): Compilation Error in model dim_service (models/Dimensions/dim_service.sql)
  invalid syntax for function call expression
    line 2
      config(
2021-06-05 15:35:54.612521 (MainThread): Traceback (most recent call last):
  File "/opt/anaconda3/lib/python3.7/site-packages/dbt/clients/jinja.py", line 501, in catch_jinja
    yield
  File "/opt/anaconda3/lib/python3.7/site-packages/dbt/clients/jinja.py", line 528, in get_template
    return env.from_string(template_source, globals=ctx)
  File "/opt/anaconda3/lib/python3.7/site-packages/jinja2/environment.py", line 941, in from_string
    return cls.from_code(self, self.compile(source), globals, None)
  File "/opt/anaconda3/lib/python3.7/site-packages/jinja2/environment.py", line 638, in compile
    self.handle_exception(source=source_hint)
  File "/opt/anaconda3/lib/python3.7/site-packages/jinja2/environment.py", line 832, in handle_exception
    reraise(*rewrite_traceback_stack(source=source))
  File "/opt/anaconda3/lib/python3.7/site-packages/jinja2/_compat.py", line 28, in reraise
    raise value.with_traceback(tb)
  File "<unknown>", line 2, in template
jinja2.exceptions.TemplateSyntaxError: invalid syntax for function call expression
  line 2
    config(

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/opt/anaconda3/lib/python3.7/site-packages/dbt/main.py", line 125, in main
    results, succeeded = handle_and_check(args)
  File "/opt/anaconda3/lib/python3.7/site-packages/dbt/main.py", line 203, in handle_and_check
    task, res = run_from_args(parsed)
  File "/opt/anaconda3/lib/python3.7/site-packages/dbt/main.py", line 256, in run_from_args
    results = task.run()
  File "/opt/anaconda3/lib/python3.7/site-packages/dbt/task/runnable.py", line 406, in run
    self._runtime_initialize()
  File "/opt/anaconda3/lib/python3.7/site-packages/dbt/task/runnable.py", line 122, in _runtime_initialize
    super()._runtime_initialize()
  File "/opt/anaconda3/lib/python3.7/site-packages/dbt/task/runnable.py", line 79, in _runtime_initialize
    self.load_manifest()
  File "/opt/anaconda3/lib/python3.7/site-packages/dbt/task/runnable.py", line 66, in load_manifest
    self.manifest = get_full_manifest(self.config)
  File "/opt/anaconda3/lib/python3.7/site-packages/dbt/perf_utils.py", line 31, in get_full_manifest
    adapter.connections.set_query_header,
  File "/opt/anaconda3/lib/python3.7/site-packages/dbt/parser/manifest.py", line 862, in load_manifest
    return ManifestLoader.load_all(config, macro_manifest, macro_hook)
  File "/opt/anaconda3/lib/python3.7/site-packages/dbt/parser/manifest.py", line 442, in load_all
    loader.load(macro_manifest=macro_manifest)
  File "/opt/anaconda3/lib/python3.7/site-packages/dbt/parser/manifest.py", line 290, in load
    self.parse_project(project, macro_manifest, old_results)
  File "/opt/anaconda3/lib/python3.7/site-packages/dbt/parser/manifest.py", line 237, in parse_project
    self.parse_with_cache(path, parser, old_results)
  File "/opt/anaconda3/lib/python3.7/site-packages/dbt/parser/manifest.py", line 188, in parse_with_cache
    parser.parse_file(block)
  File "/opt/anaconda3/lib/python3.7/site-packages/dbt/parser/base.py", line 432, in parse_file
    self.parse_node(file_block)
  File "/opt/anaconda3/lib/python3.7/site-packages/dbt/parser/base.py", line 405, in parse_node
    self.render_update(node, config)
  File "/opt/anaconda3/lib/python3.7/site-packages/dbt/parser/base.py", line 380, in render_update
    self.render_with_context(node, config)
  File "/opt/anaconda3/lib/python3.7/site-packages/dbt/parser/base.py", line 294, in render_with_context
    parsed_node.raw_sql, context, parsed_node, capture_macros=True
  File "/opt/anaconda3/lib/python3.7/site-packages/dbt/clients/jinja.py", line 580, in get_rendered
    native=native,
  File "/opt/anaconda3/lib/python3.7/site-packages/dbt/clients/jinja.py", line 528, in get_template
    return env.from_string(template_source, globals=ctx)
  File "/opt/anaconda3/lib/python3.7/contextlib.py", line 130, in __exit__
    self.gen.throw(type, value, traceback)
  File "/opt/anaconda3/lib/python3.7/site-packages/dbt/clients/jinja.py", line 504, in catch_jinja
    raise CompilationException(str(e), node) from e
dbt.exceptions.CompilationException: Compilation Error in model dim_service (models/Dimensions/dim_service.sql)
  invalid syntax for function call expression
    line 2
      config(

2021-06-05 15:37:03.339394 (MainThread): Running with dbt=0.19.1
2021-06-05 15:37:04.256406 (MainThread): running dbt with arguments Namespace(cls=<class 'dbt.task.run.RunTask'>, debug=False, defer=None, exclude=None, fail_fast=False, full_refresh=False, log_cache_events=False, log_format='default', models=['dim_professional'], partial_parse=None, profile=None, profiles_dir='/Users/mac/.dbt', project_dir=None, record_timing_info=None, rpc_method='run', selector_name=None, single_threaded=False, state=None, strict=False, target=None, test_new_parser=False, threads=None, use_cache=True, use_colors=None, vars='{}', version_check=True, warn_error=False, which='run', write_json=True)
2021-06-05 15:37:04.258314 (MainThread): Tracking: tracking
2021-06-05 15:37:04.269506 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ffd5e91b150>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ffd5e91b550>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ffd5e91b350>]}
2021-06-05 15:37:04.283927 (MainThread): Partial parsing not enabled
2021-06-05 15:37:04.285561 (MainThread): Parsing macros/etc.sql
2021-06-05 15:37:04.290232 (MainThread): Parsing macros/catalog.sql
2021-06-05 15:37:04.299012 (MainThread): Parsing macros/adapters.sql
2021-06-05 15:37:04.327419 (MainThread): Parsing macros/materializations/seed.sql
2021-06-05 15:37:04.331262 (MainThread): Parsing macros/materializations/view.sql
2021-06-05 15:37:04.335176 (MainThread): Parsing macros/materializations/table.sql
2021-06-05 15:37:04.348194 (MainThread): Parsing macros/materializations/copy.sql
2021-06-05 15:37:04.354503 (MainThread): Parsing macros/materializations/incremental.sql
2021-06-05 15:37:04.372945 (MainThread): Parsing macros/materializations/snapshot.sql
2021-06-05 15:37:04.377514 (MainThread): Parsing macros/core.sql
2021-06-05 15:37:04.383829 (MainThread): Parsing macros/materializations/helpers.sql
2021-06-05 15:37:04.397446 (MainThread): Parsing macros/materializations/snapshot/snapshot_merge.sql
2021-06-05 15:37:04.400241 (MainThread): Parsing macros/materializations/snapshot/strategies.sql
2021-06-05 15:37:04.424388 (MainThread): Parsing macros/materializations/snapshot/snapshot.sql
2021-06-05 15:37:04.467924 (MainThread): Parsing macros/materializations/seed/seed.sql
2021-06-05 15:37:04.496034 (MainThread): Parsing macros/materializations/incremental/helpers.sql
2021-06-05 15:37:04.498715 (MainThread): Parsing macros/materializations/incremental/incremental.sql
2021-06-05 15:37:04.507063 (MainThread): Parsing macros/materializations/common/merge.sql
2021-06-05 15:37:04.525736 (MainThread): Parsing macros/materializations/table/table.sql
2021-06-05 15:37:04.534908 (MainThread): Parsing macros/materializations/view/view.sql
2021-06-05 15:37:04.543292 (MainThread): Parsing macros/materializations/view/create_or_replace_view.sql
2021-06-05 15:37:04.549821 (MainThread): Parsing macros/etc/get_custom_alias.sql
2021-06-05 15:37:04.551230 (MainThread): Parsing macros/etc/query.sql
2021-06-05 15:37:04.552673 (MainThread): Parsing macros/etc/is_incremental.sql
2021-06-05 15:37:04.554890 (MainThread): Parsing macros/etc/datetime.sql
2021-06-05 15:37:04.566694 (MainThread): Parsing macros/etc/get_custom_schema.sql
2021-06-05 15:37:04.569359 (MainThread): Parsing macros/etc/get_custom_database.sql
2021-06-05 15:37:04.571694 (MainThread): Parsing macros/adapters/common.sql
2021-06-05 15:37:04.629385 (MainThread): Parsing macros/schema_tests/relationships.sql
2021-06-05 15:37:04.632051 (MainThread): Parsing macros/schema_tests/not_null.sql
2021-06-05 15:37:04.634333 (MainThread): Parsing macros/schema_tests/unique.sql
2021-06-05 15:37:04.637000 (MainThread): Parsing macros/schema_tests/accepted_values.sql
2021-06-05 15:37:04.647787 (MainThread): Partial parsing not enabled
2021-06-05 15:37:04.679843 (MainThread): Acquiring new bigquery connection "model.werkspot_technical_challenge.dim_service".
2021-06-05 15:37:04.682562 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ffd5e96e210>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ffd5eaa7e50>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ffd5e556290>]}
2021-06-05 15:37:04.682861 (MainThread): Flushing usage events
2021-06-05 15:37:11.070811 (MainThread): Connection 'model.werkspot_technical_challenge.dim_service' was properly closed.
2021-06-05 15:37:11.071077 (MainThread): Encountered an error:
2021-06-05 15:37:11.071293 (MainThread): Compilation Error in model dim_service (models/Dimensions/dim_service.sql)
  invalid syntax for function call expression
    line 2
      config(
2021-06-05 15:37:11.075204 (MainThread): Traceback (most recent call last):
  File "/opt/anaconda3/lib/python3.7/site-packages/dbt/clients/jinja.py", line 501, in catch_jinja
    yield
  File "/opt/anaconda3/lib/python3.7/site-packages/dbt/clients/jinja.py", line 528, in get_template
    return env.from_string(template_source, globals=ctx)
  File "/opt/anaconda3/lib/python3.7/site-packages/jinja2/environment.py", line 941, in from_string
    return cls.from_code(self, self.compile(source), globals, None)
  File "/opt/anaconda3/lib/python3.7/site-packages/jinja2/environment.py", line 638, in compile
    self.handle_exception(source=source_hint)
  File "/opt/anaconda3/lib/python3.7/site-packages/jinja2/environment.py", line 832, in handle_exception
    reraise(*rewrite_traceback_stack(source=source))
  File "/opt/anaconda3/lib/python3.7/site-packages/jinja2/_compat.py", line 28, in reraise
    raise value.with_traceback(tb)
  File "<unknown>", line 2, in template
jinja2.exceptions.TemplateSyntaxError: invalid syntax for function call expression
  line 2
    config(

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/opt/anaconda3/lib/python3.7/site-packages/dbt/main.py", line 125, in main
    results, succeeded = handle_and_check(args)
  File "/opt/anaconda3/lib/python3.7/site-packages/dbt/main.py", line 203, in handle_and_check
    task, res = run_from_args(parsed)
  File "/opt/anaconda3/lib/python3.7/site-packages/dbt/main.py", line 256, in run_from_args
    results = task.run()
  File "/opt/anaconda3/lib/python3.7/site-packages/dbt/task/runnable.py", line 406, in run
    self._runtime_initialize()
  File "/opt/anaconda3/lib/python3.7/site-packages/dbt/task/runnable.py", line 122, in _runtime_initialize
    super()._runtime_initialize()
  File "/opt/anaconda3/lib/python3.7/site-packages/dbt/task/runnable.py", line 79, in _runtime_initialize
    self.load_manifest()
  File "/opt/anaconda3/lib/python3.7/site-packages/dbt/task/runnable.py", line 66, in load_manifest
    self.manifest = get_full_manifest(self.config)
  File "/opt/anaconda3/lib/python3.7/site-packages/dbt/perf_utils.py", line 31, in get_full_manifest
    adapter.connections.set_query_header,
  File "/opt/anaconda3/lib/python3.7/site-packages/dbt/parser/manifest.py", line 862, in load_manifest
    return ManifestLoader.load_all(config, macro_manifest, macro_hook)
  File "/opt/anaconda3/lib/python3.7/site-packages/dbt/parser/manifest.py", line 442, in load_all
    loader.load(macro_manifest=macro_manifest)
  File "/opt/anaconda3/lib/python3.7/site-packages/dbt/parser/manifest.py", line 290, in load
    self.parse_project(project, macro_manifest, old_results)
  File "/opt/anaconda3/lib/python3.7/site-packages/dbt/parser/manifest.py", line 237, in parse_project
    self.parse_with_cache(path, parser, old_results)
  File "/opt/anaconda3/lib/python3.7/site-packages/dbt/parser/manifest.py", line 188, in parse_with_cache
    parser.parse_file(block)
  File "/opt/anaconda3/lib/python3.7/site-packages/dbt/parser/base.py", line 432, in parse_file
    self.parse_node(file_block)
  File "/opt/anaconda3/lib/python3.7/site-packages/dbt/parser/base.py", line 405, in parse_node
    self.render_update(node, config)
  File "/opt/anaconda3/lib/python3.7/site-packages/dbt/parser/base.py", line 380, in render_update
    self.render_with_context(node, config)
  File "/opt/anaconda3/lib/python3.7/site-packages/dbt/parser/base.py", line 294, in render_with_context
    parsed_node.raw_sql, context, parsed_node, capture_macros=True
  File "/opt/anaconda3/lib/python3.7/site-packages/dbt/clients/jinja.py", line 580, in get_rendered
    native=native,
  File "/opt/anaconda3/lib/python3.7/site-packages/dbt/clients/jinja.py", line 528, in get_template
    return env.from_string(template_source, globals=ctx)
  File "/opt/anaconda3/lib/python3.7/contextlib.py", line 130, in __exit__
    self.gen.throw(type, value, traceback)
  File "/opt/anaconda3/lib/python3.7/site-packages/dbt/clients/jinja.py", line 504, in catch_jinja
    raise CompilationException(str(e), node) from e
dbt.exceptions.CompilationException: Compilation Error in model dim_service (models/Dimensions/dim_service.sql)
  invalid syntax for function call expression
    line 2
      config(

2021-06-05 15:40:35.293333 (MainThread): Running with dbt=0.19.1
2021-06-05 15:40:36.180752 (MainThread): running dbt with arguments Namespace(cls=<class 'dbt.task.run.RunTask'>, debug=False, defer=None, exclude=None, fail_fast=False, full_refresh=False, log_cache_events=False, log_format='default', models=['dim_professional'], partial_parse=None, profile=None, profiles_dir='/Users/mac/.dbt', project_dir=None, record_timing_info=None, rpc_method='run', selector_name=None, single_threaded=False, state=None, strict=False, target=None, test_new_parser=False, threads=None, use_cache=True, use_colors=None, vars='{}', version_check=True, warn_error=False, which='run', write_json=True)
2021-06-05 15:40:36.182503 (MainThread): Tracking: tracking
2021-06-05 15:40:36.193964 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fb80f0cc950>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fb80eb75c50>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fb80f0db1d0>]}
2021-06-05 15:40:36.207678 (MainThread): Partial parsing not enabled
2021-06-05 15:40:36.209258 (MainThread): Parsing macros/etc.sql
2021-06-05 15:40:36.213590 (MainThread): Parsing macros/catalog.sql
2021-06-05 15:40:36.222483 (MainThread): Parsing macros/adapters.sql
2021-06-05 15:40:36.250435 (MainThread): Parsing macros/materializations/seed.sql
2021-06-05 15:40:36.254294 (MainThread): Parsing macros/materializations/view.sql
2021-06-05 15:40:36.258482 (MainThread): Parsing macros/materializations/table.sql
2021-06-05 15:40:36.272691 (MainThread): Parsing macros/materializations/copy.sql
2021-06-05 15:40:36.279590 (MainThread): Parsing macros/materializations/incremental.sql
2021-06-05 15:40:36.298620 (MainThread): Parsing macros/materializations/snapshot.sql
2021-06-05 15:40:36.302667 (MainThread): Parsing macros/core.sql
2021-06-05 15:40:36.308605 (MainThread): Parsing macros/materializations/helpers.sql
2021-06-05 15:40:36.321263 (MainThread): Parsing macros/materializations/snapshot/snapshot_merge.sql
2021-06-05 15:40:36.323916 (MainThread): Parsing macros/materializations/snapshot/strategies.sql
2021-06-05 15:40:36.347545 (MainThread): Parsing macros/materializations/snapshot/snapshot.sql
2021-06-05 15:40:36.392522 (MainThread): Parsing macros/materializations/seed/seed.sql
2021-06-05 15:40:36.423394 (MainThread): Parsing macros/materializations/incremental/helpers.sql
2021-06-05 15:40:36.426069 (MainThread): Parsing macros/materializations/incremental/incremental.sql
2021-06-05 15:40:36.434438 (MainThread): Parsing macros/materializations/common/merge.sql
2021-06-05 15:40:36.453121 (MainThread): Parsing macros/materializations/table/table.sql
2021-06-05 15:40:36.462446 (MainThread): Parsing macros/materializations/view/view.sql
2021-06-05 15:40:36.470910 (MainThread): Parsing macros/materializations/view/create_or_replace_view.sql
2021-06-05 15:40:36.477514 (MainThread): Parsing macros/etc/get_custom_alias.sql
2021-06-05 15:40:36.478850 (MainThread): Parsing macros/etc/query.sql
2021-06-05 15:40:36.480393 (MainThread): Parsing macros/etc/is_incremental.sql
2021-06-05 15:40:36.482742 (MainThread): Parsing macros/etc/datetime.sql
2021-06-05 15:40:36.494998 (MainThread): Parsing macros/etc/get_custom_schema.sql
2021-06-05 15:40:36.497688 (MainThread): Parsing macros/etc/get_custom_database.sql
2021-06-05 15:40:36.499999 (MainThread): Parsing macros/adapters/common.sql
2021-06-05 15:40:36.558740 (MainThread): Parsing macros/schema_tests/relationships.sql
2021-06-05 15:40:36.561664 (MainThread): Parsing macros/schema_tests/not_null.sql
2021-06-05 15:40:36.563871 (MainThread): Parsing macros/schema_tests/unique.sql
2021-06-05 15:40:36.566185 (MainThread): Parsing macros/schema_tests/accepted_values.sql
2021-06-05 15:40:36.576227 (MainThread): Partial parsing not enabled
2021-06-05 15:40:36.610089 (MainThread): Acquiring new bigquery connection "model.werkspot_technical_challenge.dim_service".
2021-06-05 15:40:36.612807 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fb80f0a8dd0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fb80f27bc50>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fb80f27bfd0>]}
2021-06-05 15:40:36.613091 (MainThread): Flushing usage events
2021-06-05 15:40:37.751412 (MainThread): Connection 'model.werkspot_technical_challenge.dim_service' was properly closed.
2021-06-05 15:40:37.751684 (MainThread): Encountered an error:
2021-06-05 15:40:37.751903 (MainThread): Compilation Error in model dim_service (models/Dimensions/dim_service.sql)
  invalid syntax for function call expression
    line 2
      config(
2021-06-05 15:40:37.755827 (MainThread): Traceback (most recent call last):
  File "/opt/anaconda3/lib/python3.7/site-packages/dbt/clients/jinja.py", line 501, in catch_jinja
    yield
  File "/opt/anaconda3/lib/python3.7/site-packages/dbt/clients/jinja.py", line 528, in get_template
    return env.from_string(template_source, globals=ctx)
  File "/opt/anaconda3/lib/python3.7/site-packages/jinja2/environment.py", line 941, in from_string
    return cls.from_code(self, self.compile(source), globals, None)
  File "/opt/anaconda3/lib/python3.7/site-packages/jinja2/environment.py", line 638, in compile
    self.handle_exception(source=source_hint)
  File "/opt/anaconda3/lib/python3.7/site-packages/jinja2/environment.py", line 832, in handle_exception
    reraise(*rewrite_traceback_stack(source=source))
  File "/opt/anaconda3/lib/python3.7/site-packages/jinja2/_compat.py", line 28, in reraise
    raise value.with_traceback(tb)
  File "<unknown>", line 2, in template
jinja2.exceptions.TemplateSyntaxError: invalid syntax for function call expression
  line 2
    config(

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/opt/anaconda3/lib/python3.7/site-packages/dbt/main.py", line 125, in main
    results, succeeded = handle_and_check(args)
  File "/opt/anaconda3/lib/python3.7/site-packages/dbt/main.py", line 203, in handle_and_check
    task, res = run_from_args(parsed)
  File "/opt/anaconda3/lib/python3.7/site-packages/dbt/main.py", line 256, in run_from_args
    results = task.run()
  File "/opt/anaconda3/lib/python3.7/site-packages/dbt/task/runnable.py", line 406, in run
    self._runtime_initialize()
  File "/opt/anaconda3/lib/python3.7/site-packages/dbt/task/runnable.py", line 122, in _runtime_initialize
    super()._runtime_initialize()
  File "/opt/anaconda3/lib/python3.7/site-packages/dbt/task/runnable.py", line 79, in _runtime_initialize
    self.load_manifest()
  File "/opt/anaconda3/lib/python3.7/site-packages/dbt/task/runnable.py", line 66, in load_manifest
    self.manifest = get_full_manifest(self.config)
  File "/opt/anaconda3/lib/python3.7/site-packages/dbt/perf_utils.py", line 31, in get_full_manifest
    adapter.connections.set_query_header,
  File "/opt/anaconda3/lib/python3.7/site-packages/dbt/parser/manifest.py", line 862, in load_manifest
    return ManifestLoader.load_all(config, macro_manifest, macro_hook)
  File "/opt/anaconda3/lib/python3.7/site-packages/dbt/parser/manifest.py", line 442, in load_all
    loader.load(macro_manifest=macro_manifest)
  File "/opt/anaconda3/lib/python3.7/site-packages/dbt/parser/manifest.py", line 290, in load
    self.parse_project(project, macro_manifest, old_results)
  File "/opt/anaconda3/lib/python3.7/site-packages/dbt/parser/manifest.py", line 237, in parse_project
    self.parse_with_cache(path, parser, old_results)
  File "/opt/anaconda3/lib/python3.7/site-packages/dbt/parser/manifest.py", line 188, in parse_with_cache
    parser.parse_file(block)
  File "/opt/anaconda3/lib/python3.7/site-packages/dbt/parser/base.py", line 432, in parse_file
    self.parse_node(file_block)
  File "/opt/anaconda3/lib/python3.7/site-packages/dbt/parser/base.py", line 405, in parse_node
    self.render_update(node, config)
  File "/opt/anaconda3/lib/python3.7/site-packages/dbt/parser/base.py", line 380, in render_update
    self.render_with_context(node, config)
  File "/opt/anaconda3/lib/python3.7/site-packages/dbt/parser/base.py", line 294, in render_with_context
    parsed_node.raw_sql, context, parsed_node, capture_macros=True
  File "/opt/anaconda3/lib/python3.7/site-packages/dbt/clients/jinja.py", line 580, in get_rendered
    native=native,
  File "/opt/anaconda3/lib/python3.7/site-packages/dbt/clients/jinja.py", line 528, in get_template
    return env.from_string(template_source, globals=ctx)
  File "/opt/anaconda3/lib/python3.7/contextlib.py", line 130, in __exit__
    self.gen.throw(type, value, traceback)
  File "/opt/anaconda3/lib/python3.7/site-packages/dbt/clients/jinja.py", line 504, in catch_jinja
    raise CompilationException(str(e), node) from e
dbt.exceptions.CompilationException: Compilation Error in model dim_service (models/Dimensions/dim_service.sql)
  invalid syntax for function call expression
    line 2
      config(

2021-06-05 15:41:30.905117 (MainThread): Running with dbt=0.19.1
2021-06-05 15:41:31.795288 (MainThread): running dbt with arguments Namespace(cls=<class 'dbt.task.run.RunTask'>, debug=False, defer=None, exclude=None, fail_fast=False, full_refresh=False, log_cache_events=False, log_format='default', models=['dim_professional'], partial_parse=None, profile=None, profiles_dir='/Users/mac/.dbt', project_dir=None, record_timing_info=None, rpc_method='run', selector_name=None, single_threaded=False, state=None, strict=False, target=None, test_new_parser=False, threads=None, use_cache=True, use_colors=None, vars='{}', version_check=True, warn_error=False, which='run', write_json=True)
2021-06-05 15:41:31.796668 (MainThread): Tracking: tracking
2021-06-05 15:41:31.807370 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fba3e91b310>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fba3e91b4d0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fba3e91b190>]}
2021-06-05 15:41:31.820610 (MainThread): Partial parsing not enabled
2021-06-05 15:41:31.822323 (MainThread): Parsing macros/etc.sql
2021-06-05 15:41:31.826929 (MainThread): Parsing macros/catalog.sql
2021-06-05 15:41:31.835631 (MainThread): Parsing macros/adapters.sql
2021-06-05 15:41:31.863321 (MainThread): Parsing macros/materializations/seed.sql
2021-06-05 15:41:31.867151 (MainThread): Parsing macros/materializations/view.sql
2021-06-05 15:41:31.871074 (MainThread): Parsing macros/materializations/table.sql
2021-06-05 15:41:31.884553 (MainThread): Parsing macros/materializations/copy.sql
2021-06-05 15:41:31.893010 (MainThread): Parsing macros/materializations/incremental.sql
2021-06-05 15:41:31.911425 (MainThread): Parsing macros/materializations/snapshot.sql
2021-06-05 15:41:31.917129 (MainThread): Parsing macros/core.sql
2021-06-05 15:41:31.922508 (MainThread): Parsing macros/materializations/helpers.sql
2021-06-05 15:41:31.934997 (MainThread): Parsing macros/materializations/snapshot/snapshot_merge.sql
2021-06-05 15:41:31.937948 (MainThread): Parsing macros/materializations/snapshot/strategies.sql
2021-06-05 15:41:31.961671 (MainThread): Parsing macros/materializations/snapshot/snapshot.sql
2021-06-05 15:41:32.005668 (MainThread): Parsing macros/materializations/seed/seed.sql
2021-06-05 15:41:32.036895 (MainThread): Parsing macros/materializations/incremental/helpers.sql
2021-06-05 15:41:32.039544 (MainThread): Parsing macros/materializations/incremental/incremental.sql
2021-06-05 15:41:32.047889 (MainThread): Parsing macros/materializations/common/merge.sql
2021-06-05 15:41:32.067001 (MainThread): Parsing macros/materializations/table/table.sql
2021-06-05 15:41:32.076293 (MainThread): Parsing macros/materializations/view/view.sql
2021-06-05 15:41:32.084903 (MainThread): Parsing macros/materializations/view/create_or_replace_view.sql
2021-06-05 15:41:32.091527 (MainThread): Parsing macros/etc/get_custom_alias.sql
2021-06-05 15:41:32.092963 (MainThread): Parsing macros/etc/query.sql
2021-06-05 15:41:32.094441 (MainThread): Parsing macros/etc/is_incremental.sql
2021-06-05 15:41:32.096678 (MainThread): Parsing macros/etc/datetime.sql
2021-06-05 15:41:32.108493 (MainThread): Parsing macros/etc/get_custom_schema.sql
2021-06-05 15:41:32.111154 (MainThread): Parsing macros/etc/get_custom_database.sql
2021-06-05 15:41:32.113425 (MainThread): Parsing macros/adapters/common.sql
2021-06-05 15:41:32.171253 (MainThread): Parsing macros/schema_tests/relationships.sql
2021-06-05 15:41:32.175584 (MainThread): Parsing macros/schema_tests/not_null.sql
2021-06-05 15:41:32.178029 (MainThread): Parsing macros/schema_tests/unique.sql
2021-06-05 15:41:32.180747 (MainThread): Parsing macros/schema_tests/accepted_values.sql
2021-06-05 15:41:32.191196 (MainThread): Partial parsing not enabled
2021-06-05 15:41:32.225301 (MainThread): Acquiring new bigquery connection "model.werkspot_technical_challenge.dim_service".
2021-06-05 15:41:32.227976 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fba3e7b4ed0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fba3ea9cfd0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fba3eaaf750>]}
2021-06-05 15:41:32.228237 (MainThread): Flushing usage events
2021-06-05 15:41:33.189207 (MainThread): Connection 'model.werkspot_technical_challenge.dim_service' was properly closed.
2021-06-05 15:41:33.189472 (MainThread): Encountered an error:
2021-06-05 15:41:33.189683 (MainThread): Compilation Error in model dim_service (models/Dimensions/dim_service.sql)
  expected token ':', got 'Column'
    line 4
      partition_by ={ -- defining Column on which data would be partitioned with in dimension table
2021-06-05 15:41:33.193620 (MainThread): Traceback (most recent call last):
  File "/opt/anaconda3/lib/python3.7/site-packages/dbt/clients/jinja.py", line 501, in catch_jinja
    yield
  File "/opt/anaconda3/lib/python3.7/site-packages/dbt/clients/jinja.py", line 528, in get_template
    return env.from_string(template_source, globals=ctx)
  File "/opt/anaconda3/lib/python3.7/site-packages/jinja2/environment.py", line 941, in from_string
    return cls.from_code(self, self.compile(source), globals, None)
  File "/opt/anaconda3/lib/python3.7/site-packages/jinja2/environment.py", line 638, in compile
    self.handle_exception(source=source_hint)
  File "/opt/anaconda3/lib/python3.7/site-packages/jinja2/environment.py", line 832, in handle_exception
    reraise(*rewrite_traceback_stack(source=source))
  File "/opt/anaconda3/lib/python3.7/site-packages/jinja2/_compat.py", line 28, in reraise
    raise value.with_traceback(tb)
  File "<unknown>", line 4, in template
jinja2.exceptions.TemplateSyntaxError: expected token ':', got 'Column'
  line 4
    partition_by ={ -- defining Column on which data would be partitioned with in dimension table

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/opt/anaconda3/lib/python3.7/site-packages/dbt/main.py", line 125, in main
    results, succeeded = handle_and_check(args)
  File "/opt/anaconda3/lib/python3.7/site-packages/dbt/main.py", line 203, in handle_and_check
    task, res = run_from_args(parsed)
  File "/opt/anaconda3/lib/python3.7/site-packages/dbt/main.py", line 256, in run_from_args
    results = task.run()
  File "/opt/anaconda3/lib/python3.7/site-packages/dbt/task/runnable.py", line 406, in run
    self._runtime_initialize()
  File "/opt/anaconda3/lib/python3.7/site-packages/dbt/task/runnable.py", line 122, in _runtime_initialize
    super()._runtime_initialize()
  File "/opt/anaconda3/lib/python3.7/site-packages/dbt/task/runnable.py", line 79, in _runtime_initialize
    self.load_manifest()
  File "/opt/anaconda3/lib/python3.7/site-packages/dbt/task/runnable.py", line 66, in load_manifest
    self.manifest = get_full_manifest(self.config)
  File "/opt/anaconda3/lib/python3.7/site-packages/dbt/perf_utils.py", line 31, in get_full_manifest
    adapter.connections.set_query_header,
  File "/opt/anaconda3/lib/python3.7/site-packages/dbt/parser/manifest.py", line 862, in load_manifest
    return ManifestLoader.load_all(config, macro_manifest, macro_hook)
  File "/opt/anaconda3/lib/python3.7/site-packages/dbt/parser/manifest.py", line 442, in load_all
    loader.load(macro_manifest=macro_manifest)
  File "/opt/anaconda3/lib/python3.7/site-packages/dbt/parser/manifest.py", line 290, in load
    self.parse_project(project, macro_manifest, old_results)
  File "/opt/anaconda3/lib/python3.7/site-packages/dbt/parser/manifest.py", line 237, in parse_project
    self.parse_with_cache(path, parser, old_results)
  File "/opt/anaconda3/lib/python3.7/site-packages/dbt/parser/manifest.py", line 188, in parse_with_cache
    parser.parse_file(block)
  File "/opt/anaconda3/lib/python3.7/site-packages/dbt/parser/base.py", line 432, in parse_file
    self.parse_node(file_block)
  File "/opt/anaconda3/lib/python3.7/site-packages/dbt/parser/base.py", line 405, in parse_node
    self.render_update(node, config)
  File "/opt/anaconda3/lib/python3.7/site-packages/dbt/parser/base.py", line 380, in render_update
    self.render_with_context(node, config)
  File "/opt/anaconda3/lib/python3.7/site-packages/dbt/parser/base.py", line 294, in render_with_context
    parsed_node.raw_sql, context, parsed_node, capture_macros=True
  File "/opt/anaconda3/lib/python3.7/site-packages/dbt/clients/jinja.py", line 580, in get_rendered
    native=native,
  File "/opt/anaconda3/lib/python3.7/site-packages/dbt/clients/jinja.py", line 528, in get_template
    return env.from_string(template_source, globals=ctx)
  File "/opt/anaconda3/lib/python3.7/contextlib.py", line 130, in __exit__
    self.gen.throw(type, value, traceback)
  File "/opt/anaconda3/lib/python3.7/site-packages/dbt/clients/jinja.py", line 504, in catch_jinja
    raise CompilationException(str(e), node) from e
dbt.exceptions.CompilationException: Compilation Error in model dim_service (models/Dimensions/dim_service.sql)
  expected token ':', got 'Column'
    line 4
      partition_by ={ -- defining Column on which data would be partitioned with in dimension table

2021-06-05 17:12:44.388672 (MainThread): Running with dbt=0.19.1
2021-06-05 17:12:45.524919 (MainThread): running dbt with arguments Namespace(cls=<class 'dbt.task.run.RunTask'>, debug=False, defer=None, exclude=None, fail_fast=False, full_refresh=False, log_cache_events=False, log_format='default', models=['dim_professional'], partial_parse=None, profile=None, profiles_dir='/Users/mac/.dbt', project_dir=None, record_timing_info=None, rpc_method='run', selector_name=None, single_threaded=False, state=None, strict=False, target=None, test_new_parser=False, threads=None, use_cache=True, use_colors=None, vars='{}', version_check=True, warn_error=False, which='run', write_json=True)
2021-06-05 17:12:45.526762 (MainThread): Tracking: tracking
2021-06-05 17:12:45.540345 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f8e1b91c290>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f8e1b91c510>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f8e1b91c150>]}
2021-06-05 17:12:45.557002 (MainThread): Partial parsing not enabled
2021-06-05 17:12:45.559146 (MainThread): Parsing macros/etc.sql
2021-06-05 17:12:45.564584 (MainThread): Parsing macros/catalog.sql
2021-06-05 17:12:45.574009 (MainThread): Parsing macros/adapters.sql
2021-06-05 17:12:45.603576 (MainThread): Parsing macros/materializations/seed.sql
2021-06-05 17:12:45.608675 (MainThread): Parsing macros/materializations/view.sql
2021-06-05 17:12:45.613170 (MainThread): Parsing macros/materializations/table.sql
2021-06-05 17:12:45.627165 (MainThread): Parsing macros/materializations/copy.sql
2021-06-05 17:12:45.634075 (MainThread): Parsing macros/materializations/incremental.sql
2021-06-05 17:12:45.653724 (MainThread): Parsing macros/materializations/snapshot.sql
2021-06-05 17:12:45.658587 (MainThread): Parsing macros/core.sql
2021-06-05 17:12:45.664694 (MainThread): Parsing macros/materializations/helpers.sql
2021-06-05 17:12:45.678458 (MainThread): Parsing macros/materializations/snapshot/snapshot_merge.sql
2021-06-05 17:12:45.681564 (MainThread): Parsing macros/materializations/snapshot/strategies.sql
2021-06-05 17:12:45.706400 (MainThread): Parsing macros/materializations/snapshot/snapshot.sql
2021-06-05 17:12:45.754015 (MainThread): Parsing macros/materializations/seed/seed.sql
2021-06-05 17:12:45.782878 (MainThread): Parsing macros/materializations/incremental/helpers.sql
2021-06-05 17:12:45.785674 (MainThread): Parsing macros/materializations/incremental/incremental.sql
2021-06-05 17:12:45.794589 (MainThread): Parsing macros/materializations/common/merge.sql
2021-06-05 17:12:45.813420 (MainThread): Parsing macros/materializations/table/table.sql
2021-06-05 17:12:45.823392 (MainThread): Parsing macros/materializations/view/view.sql
2021-06-05 17:12:45.832256 (MainThread): Parsing macros/materializations/view/create_or_replace_view.sql
2021-06-05 17:12:45.839295 (MainThread): Parsing macros/etc/get_custom_alias.sql
2021-06-05 17:12:45.841023 (MainThread): Parsing macros/etc/query.sql
2021-06-05 17:12:45.842751 (MainThread): Parsing macros/etc/is_incremental.sql
2021-06-05 17:12:45.845204 (MainThread): Parsing macros/etc/datetime.sql
2021-06-05 17:12:45.857540 (MainThread): Parsing macros/etc/get_custom_schema.sql
2021-06-05 17:12:45.861373 (MainThread): Parsing macros/etc/get_custom_database.sql
2021-06-05 17:12:45.864862 (MainThread): Parsing macros/adapters/common.sql
2021-06-05 17:12:45.924551 (MainThread): Parsing macros/schema_tests/relationships.sql
2021-06-05 17:12:45.927270 (MainThread): Parsing macros/schema_tests/not_null.sql
2021-06-05 17:12:45.929681 (MainThread): Parsing macros/schema_tests/unique.sql
2021-06-05 17:12:45.932578 (MainThread): Parsing macros/schema_tests/accepted_values.sql
2021-06-05 17:12:45.943206 (MainThread): Partial parsing not enabled
2021-06-05 17:12:45.979551 (MainThread): Acquiring new bigquery connection "model.werkspot_technical_challenge.dim_service".
2021-06-05 17:12:45.983104 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f8e1b9a99d0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f8e1baaf310>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f8e1baa0990>]}
2021-06-05 17:12:45.983564 (MainThread): Flushing usage events
2021-06-05 17:12:47.022352 (MainThread): Connection 'model.werkspot_technical_challenge.dim_service' was properly closed.
2021-06-05 17:12:47.022632 (MainThread): Encountered an error:
2021-06-05 17:12:47.022855 (MainThread): Compilation Error in model dim_service (models/Dimensions/dim_service.sql)
  expected token ':', got 'Column'
    line 4
      partition_by ={ -- defining Column on which data would be partitioned with in dimension table
2021-06-05 17:12:47.030485 (MainThread): Traceback (most recent call last):
  File "/opt/anaconda3/lib/python3.7/site-packages/dbt/clients/jinja.py", line 501, in catch_jinja
    yield
  File "/opt/anaconda3/lib/python3.7/site-packages/dbt/clients/jinja.py", line 528, in get_template
    return env.from_string(template_source, globals=ctx)
  File "/opt/anaconda3/lib/python3.7/site-packages/jinja2/environment.py", line 941, in from_string
    return cls.from_code(self, self.compile(source), globals, None)
  File "/opt/anaconda3/lib/python3.7/site-packages/jinja2/environment.py", line 638, in compile
    self.handle_exception(source=source_hint)
  File "/opt/anaconda3/lib/python3.7/site-packages/jinja2/environment.py", line 832, in handle_exception
    reraise(*rewrite_traceback_stack(source=source))
  File "/opt/anaconda3/lib/python3.7/site-packages/jinja2/_compat.py", line 28, in reraise
    raise value.with_traceback(tb)
  File "<unknown>", line 4, in template
jinja2.exceptions.TemplateSyntaxError: expected token ':', got 'Column'
  line 4
    partition_by ={ -- defining Column on which data would be partitioned with in dimension table

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/opt/anaconda3/lib/python3.7/site-packages/dbt/main.py", line 125, in main
    results, succeeded = handle_and_check(args)
  File "/opt/anaconda3/lib/python3.7/site-packages/dbt/main.py", line 203, in handle_and_check
    task, res = run_from_args(parsed)
  File "/opt/anaconda3/lib/python3.7/site-packages/dbt/main.py", line 256, in run_from_args
    results = task.run()
  File "/opt/anaconda3/lib/python3.7/site-packages/dbt/task/runnable.py", line 406, in run
    self._runtime_initialize()
  File "/opt/anaconda3/lib/python3.7/site-packages/dbt/task/runnable.py", line 122, in _runtime_initialize
    super()._runtime_initialize()
  File "/opt/anaconda3/lib/python3.7/site-packages/dbt/task/runnable.py", line 79, in _runtime_initialize
    self.load_manifest()
  File "/opt/anaconda3/lib/python3.7/site-packages/dbt/task/runnable.py", line 66, in load_manifest
    self.manifest = get_full_manifest(self.config)
  File "/opt/anaconda3/lib/python3.7/site-packages/dbt/perf_utils.py", line 31, in get_full_manifest
    adapter.connections.set_query_header,
  File "/opt/anaconda3/lib/python3.7/site-packages/dbt/parser/manifest.py", line 862, in load_manifest
    return ManifestLoader.load_all(config, macro_manifest, macro_hook)
  File "/opt/anaconda3/lib/python3.7/site-packages/dbt/parser/manifest.py", line 442, in load_all
    loader.load(macro_manifest=macro_manifest)
  File "/opt/anaconda3/lib/python3.7/site-packages/dbt/parser/manifest.py", line 290, in load
    self.parse_project(project, macro_manifest, old_results)
  File "/opt/anaconda3/lib/python3.7/site-packages/dbt/parser/manifest.py", line 237, in parse_project
    self.parse_with_cache(path, parser, old_results)
  File "/opt/anaconda3/lib/python3.7/site-packages/dbt/parser/manifest.py", line 188, in parse_with_cache
    parser.parse_file(block)
  File "/opt/anaconda3/lib/python3.7/site-packages/dbt/parser/base.py", line 432, in parse_file
    self.parse_node(file_block)
  File "/opt/anaconda3/lib/python3.7/site-packages/dbt/parser/base.py", line 405, in parse_node
    self.render_update(node, config)
  File "/opt/anaconda3/lib/python3.7/site-packages/dbt/parser/base.py", line 380, in render_update
    self.render_with_context(node, config)
  File "/opt/anaconda3/lib/python3.7/site-packages/dbt/parser/base.py", line 294, in render_with_context
    parsed_node.raw_sql, context, parsed_node, capture_macros=True
  File "/opt/anaconda3/lib/python3.7/site-packages/dbt/clients/jinja.py", line 580, in get_rendered
    native=native,
  File "/opt/anaconda3/lib/python3.7/site-packages/dbt/clients/jinja.py", line 528, in get_template
    return env.from_string(template_source, globals=ctx)
  File "/opt/anaconda3/lib/python3.7/contextlib.py", line 130, in __exit__
    self.gen.throw(type, value, traceback)
  File "/opt/anaconda3/lib/python3.7/site-packages/dbt/clients/jinja.py", line 504, in catch_jinja
    raise CompilationException(str(e), node) from e
dbt.exceptions.CompilationException: Compilation Error in model dim_service (models/Dimensions/dim_service.sql)
  expected token ':', got 'Column'
    line 4
      partition_by ={ -- defining Column on which data would be partitioned with in dimension table

2021-06-05 17:13:10.071221 (MainThread): Running with dbt=0.19.1
2021-06-05 17:13:10.811861 (MainThread): running dbt with arguments Namespace(cls=<class 'dbt.task.run.RunTask'>, debug=False, defer=None, exclude=None, fail_fast=False, full_refresh=False, log_cache_events=False, log_format='default', models=['dim_professional'], partial_parse=None, profile=None, profiles_dir='/Users/mac/.dbt', project_dir=None, record_timing_info=None, rpc_method='run', selector_name=None, single_threaded=False, state=None, strict=False, target=None, test_new_parser=False, threads=None, use_cache=True, use_colors=None, vars='{}', version_check=True, warn_error=False, which='run', write_json=True)
2021-06-05 17:13:10.813263 (MainThread): Tracking: tracking
2021-06-05 17:13:10.823713 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fd68800cfd0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fd68800cdd0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fd68800cd50>]}
2021-06-05 17:13:10.838404 (MainThread): Partial parsing not enabled
2021-06-05 17:13:10.840227 (MainThread): Parsing macros/etc.sql
2021-06-05 17:13:10.844403 (MainThread): Parsing macros/catalog.sql
2021-06-05 17:13:10.853696 (MainThread): Parsing macros/adapters.sql
2021-06-05 17:13:10.882516 (MainThread): Parsing macros/materializations/seed.sql
2021-06-05 17:13:10.886150 (MainThread): Parsing macros/materializations/view.sql
2021-06-05 17:13:10.889956 (MainThread): Parsing macros/materializations/table.sql
2021-06-05 17:13:10.903820 (MainThread): Parsing macros/materializations/copy.sql
2021-06-05 17:13:10.910136 (MainThread): Parsing macros/materializations/incremental.sql
2021-06-05 17:13:10.928063 (MainThread): Parsing macros/materializations/snapshot.sql
2021-06-05 17:13:10.932555 (MainThread): Parsing macros/core.sql
2021-06-05 17:13:10.938124 (MainThread): Parsing macros/materializations/helpers.sql
2021-06-05 17:13:10.951481 (MainThread): Parsing macros/materializations/snapshot/snapshot_merge.sql
2021-06-05 17:13:10.954078 (MainThread): Parsing macros/materializations/snapshot/strategies.sql
2021-06-05 17:13:10.978476 (MainThread): Parsing macros/materializations/snapshot/snapshot.sql
2021-06-05 17:13:11.022793 (MainThread): Parsing macros/materializations/seed/seed.sql
2021-06-05 17:13:11.051082 (MainThread): Parsing macros/materializations/incremental/helpers.sql
2021-06-05 17:13:11.053561 (MainThread): Parsing macros/materializations/incremental/incremental.sql
2021-06-05 17:13:11.062067 (MainThread): Parsing macros/materializations/common/merge.sql
2021-06-05 17:13:11.080807 (MainThread): Parsing macros/materializations/table/table.sql
2021-06-05 17:13:11.090026 (MainThread): Parsing macros/materializations/view/view.sql
2021-06-05 17:13:11.098776 (MainThread): Parsing macros/materializations/view/create_or_replace_view.sql
2021-06-05 17:13:11.105763 (MainThread): Parsing macros/etc/get_custom_alias.sql
2021-06-05 17:13:11.107201 (MainThread): Parsing macros/etc/query.sql
2021-06-05 17:13:11.108663 (MainThread): Parsing macros/etc/is_incremental.sql
2021-06-05 17:13:11.110821 (MainThread): Parsing macros/etc/datetime.sql
2021-06-05 17:13:11.122800 (MainThread): Parsing macros/etc/get_custom_schema.sql
2021-06-05 17:13:11.125395 (MainThread): Parsing macros/etc/get_custom_database.sql
2021-06-05 17:13:11.127806 (MainThread): Parsing macros/adapters/common.sql
2021-06-05 17:13:11.186468 (MainThread): Parsing macros/schema_tests/relationships.sql
2021-06-05 17:13:11.189025 (MainThread): Parsing macros/schema_tests/not_null.sql
2021-06-05 17:13:11.191073 (MainThread): Parsing macros/schema_tests/unique.sql
2021-06-05 17:13:11.193379 (MainThread): Parsing macros/schema_tests/accepted_values.sql
2021-06-05 17:13:11.203889 (MainThread): Partial parsing not enabled
2021-06-05 17:13:11.238917 (MainThread): Acquiring new bigquery connection "model.werkspot_technical_challenge.dim_service".
2021-06-05 17:13:11.241924 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fd68802dad0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fd6881a0a10>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fd6881a08d0>]}
2021-06-05 17:13:11.242224 (MainThread): Flushing usage events
2021-06-05 17:13:12.094811 (MainThread): Connection 'model.werkspot_technical_challenge.dim_service' was properly closed.
2021-06-05 17:13:12.095089 (MainThread): Encountered an error:
2021-06-05 17:13:12.095314 (MainThread): Compilation Error in model dim_service (models/Dimensions/dim_service.sql)
  expected token ':', got 'Column'
    line 5
      partition_by ={ -- defining Column on which data would be partitioned with in dimension table
2021-06-05 17:13:12.098236 (MainThread): Traceback (most recent call last):
  File "/opt/anaconda3/lib/python3.7/site-packages/dbt/clients/jinja.py", line 501, in catch_jinja
    yield
  File "/opt/anaconda3/lib/python3.7/site-packages/dbt/clients/jinja.py", line 528, in get_template
    return env.from_string(template_source, globals=ctx)
  File "/opt/anaconda3/lib/python3.7/site-packages/jinja2/environment.py", line 941, in from_string
    return cls.from_code(self, self.compile(source), globals, None)
  File "/opt/anaconda3/lib/python3.7/site-packages/jinja2/environment.py", line 638, in compile
    self.handle_exception(source=source_hint)
  File "/opt/anaconda3/lib/python3.7/site-packages/jinja2/environment.py", line 832, in handle_exception
    reraise(*rewrite_traceback_stack(source=source))
  File "/opt/anaconda3/lib/python3.7/site-packages/jinja2/_compat.py", line 28, in reraise
    raise value.with_traceback(tb)
  File "<unknown>", line 5, in template
jinja2.exceptions.TemplateSyntaxError: expected token ':', got 'Column'
  line 5
    partition_by ={ -- defining Column on which data would be partitioned with in dimension table

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/opt/anaconda3/lib/python3.7/site-packages/dbt/main.py", line 125, in main
    results, succeeded = handle_and_check(args)
  File "/opt/anaconda3/lib/python3.7/site-packages/dbt/main.py", line 203, in handle_and_check
    task, res = run_from_args(parsed)
  File "/opt/anaconda3/lib/python3.7/site-packages/dbt/main.py", line 256, in run_from_args
    results = task.run()
  File "/opt/anaconda3/lib/python3.7/site-packages/dbt/task/runnable.py", line 406, in run
    self._runtime_initialize()
  File "/opt/anaconda3/lib/python3.7/site-packages/dbt/task/runnable.py", line 122, in _runtime_initialize
    super()._runtime_initialize()
  File "/opt/anaconda3/lib/python3.7/site-packages/dbt/task/runnable.py", line 79, in _runtime_initialize
    self.load_manifest()
  File "/opt/anaconda3/lib/python3.7/site-packages/dbt/task/runnable.py", line 66, in load_manifest
    self.manifest = get_full_manifest(self.config)
  File "/opt/anaconda3/lib/python3.7/site-packages/dbt/perf_utils.py", line 31, in get_full_manifest
    adapter.connections.set_query_header,
  File "/opt/anaconda3/lib/python3.7/site-packages/dbt/parser/manifest.py", line 862, in load_manifest
    return ManifestLoader.load_all(config, macro_manifest, macro_hook)
  File "/opt/anaconda3/lib/python3.7/site-packages/dbt/parser/manifest.py", line 442, in load_all
    loader.load(macro_manifest=macro_manifest)
  File "/opt/anaconda3/lib/python3.7/site-packages/dbt/parser/manifest.py", line 290, in load
    self.parse_project(project, macro_manifest, old_results)
  File "/opt/anaconda3/lib/python3.7/site-packages/dbt/parser/manifest.py", line 237, in parse_project
    self.parse_with_cache(path, parser, old_results)
  File "/opt/anaconda3/lib/python3.7/site-packages/dbt/parser/manifest.py", line 188, in parse_with_cache
    parser.parse_file(block)
  File "/opt/anaconda3/lib/python3.7/site-packages/dbt/parser/base.py", line 432, in parse_file
    self.parse_node(file_block)
  File "/opt/anaconda3/lib/python3.7/site-packages/dbt/parser/base.py", line 405, in parse_node
    self.render_update(node, config)
  File "/opt/anaconda3/lib/python3.7/site-packages/dbt/parser/base.py", line 380, in render_update
    self.render_with_context(node, config)
  File "/opt/anaconda3/lib/python3.7/site-packages/dbt/parser/base.py", line 294, in render_with_context
    parsed_node.raw_sql, context, parsed_node, capture_macros=True
  File "/opt/anaconda3/lib/python3.7/site-packages/dbt/clients/jinja.py", line 580, in get_rendered
    native=native,
  File "/opt/anaconda3/lib/python3.7/site-packages/dbt/clients/jinja.py", line 528, in get_template
    return env.from_string(template_source, globals=ctx)
  File "/opt/anaconda3/lib/python3.7/contextlib.py", line 130, in __exit__
    self.gen.throw(type, value, traceback)
  File "/opt/anaconda3/lib/python3.7/site-packages/dbt/clients/jinja.py", line 504, in catch_jinja
    raise CompilationException(str(e), node) from e
dbt.exceptions.CompilationException: Compilation Error in model dim_service (models/Dimensions/dim_service.sql)
  expected token ':', got 'Column'
    line 5
      partition_by ={ -- defining Column on which data would be partitioned with in dimension table

2021-06-05 17:15:21.164619 (MainThread): Running with dbt=0.19.1
2021-06-05 17:15:21.969058 (MainThread): running dbt with arguments Namespace(cls=<class 'dbt.task.run.RunTask'>, debug=False, defer=None, exclude=None, fail_fast=False, full_refresh=False, log_cache_events=False, log_format='default', models=['dim_professional'], partial_parse=None, profile=None, profiles_dir='/Users/mac/.dbt', project_dir=None, record_timing_info=None, rpc_method='run', selector_name=None, single_threaded=False, state=None, strict=False, target=None, test_new_parser=False, threads=None, use_cache=True, use_colors=None, vars='{}', version_check=True, warn_error=False, which='run', write_json=True)
2021-06-05 17:15:21.970475 (MainThread): Tracking: tracking
2021-06-05 17:15:21.981441 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fc09901c3d0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fc09901c510>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fc09901c190>]}
2021-06-05 17:15:21.995994 (MainThread): Partial parsing not enabled
2021-06-05 17:15:21.997568 (MainThread): Parsing macros/etc.sql
2021-06-05 17:15:22.002013 (MainThread): Parsing macros/catalog.sql
2021-06-05 17:15:22.011102 (MainThread): Parsing macros/adapters.sql
2021-06-05 17:15:22.040347 (MainThread): Parsing macros/materializations/seed.sql
2021-06-05 17:15:22.044069 (MainThread): Parsing macros/materializations/view.sql
2021-06-05 17:15:22.047762 (MainThread): Parsing macros/materializations/table.sql
2021-06-05 17:15:22.061320 (MainThread): Parsing macros/materializations/copy.sql
2021-06-05 17:15:22.067133 (MainThread): Parsing macros/materializations/incremental.sql
2021-06-05 17:15:22.086980 (MainThread): Parsing macros/materializations/snapshot.sql
2021-06-05 17:15:22.090848 (MainThread): Parsing macros/core.sql
2021-06-05 17:15:22.096241 (MainThread): Parsing macros/materializations/helpers.sql
2021-06-05 17:15:22.108758 (MainThread): Parsing macros/materializations/snapshot/snapshot_merge.sql
2021-06-05 17:15:22.111190 (MainThread): Parsing macros/materializations/snapshot/strategies.sql
2021-06-05 17:15:22.135480 (MainThread): Parsing macros/materializations/snapshot/snapshot.sql
2021-06-05 17:15:22.180351 (MainThread): Parsing macros/materializations/seed/seed.sql
2021-06-05 17:15:22.208810 (MainThread): Parsing macros/materializations/incremental/helpers.sql
2021-06-05 17:15:22.211435 (MainThread): Parsing macros/materializations/incremental/incremental.sql
2021-06-05 17:15:22.219850 (MainThread): Parsing macros/materializations/common/merge.sql
2021-06-05 17:15:22.238923 (MainThread): Parsing macros/materializations/table/table.sql
2021-06-05 17:15:22.248366 (MainThread): Parsing macros/materializations/view/view.sql
2021-06-05 17:15:22.256867 (MainThread): Parsing macros/materializations/view/create_or_replace_view.sql
2021-06-05 17:15:22.263672 (MainThread): Parsing macros/etc/get_custom_alias.sql
2021-06-05 17:15:22.264972 (MainThread): Parsing macros/etc/query.sql
2021-06-05 17:15:22.266383 (MainThread): Parsing macros/etc/is_incremental.sql
2021-06-05 17:15:22.268539 (MainThread): Parsing macros/etc/datetime.sql
2021-06-05 17:15:22.280434 (MainThread): Parsing macros/etc/get_custom_schema.sql
2021-06-05 17:15:22.283177 (MainThread): Parsing macros/etc/get_custom_database.sql
2021-06-05 17:15:22.285405 (MainThread): Parsing macros/adapters/common.sql
2021-06-05 17:15:22.344277 (MainThread): Parsing macros/schema_tests/relationships.sql
2021-06-05 17:15:22.346866 (MainThread): Parsing macros/schema_tests/not_null.sql
2021-06-05 17:15:22.348898 (MainThread): Parsing macros/schema_tests/unique.sql
2021-06-05 17:15:22.351135 (MainThread): Parsing macros/schema_tests/accepted_values.sql
2021-06-05 17:15:22.361540 (MainThread): Partial parsing not enabled
2021-06-05 17:15:22.396864 (MainThread): Acquiring new bigquery connection "model.werkspot_technical_challenge.dim_service".
2021-06-05 17:15:22.399711 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fc0987b1890>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fc09919de50>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fc0991af210>]}
2021-06-05 17:15:22.399978 (MainThread): Flushing usage events
2021-06-05 17:15:23.240261 (MainThread): Connection 'model.werkspot_technical_challenge.dim_service' was properly closed.
2021-06-05 17:15:23.240520 (MainThread): Encountered an error:
2021-06-05 17:15:23.240713 (MainThread): Compilation Error in model dim_service (models/Dimensions/dim_service.sql)
  expected token ':', got 'Column'
    line 6
      partition_by ={ -- defining Column on which data would be partitioned with in dimension table
2021-06-05 17:15:23.243558 (MainThread): Traceback (most recent call last):
  File "/opt/anaconda3/lib/python3.7/site-packages/dbt/clients/jinja.py", line 501, in catch_jinja
    yield
  File "/opt/anaconda3/lib/python3.7/site-packages/dbt/clients/jinja.py", line 528, in get_template
    return env.from_string(template_source, globals=ctx)
  File "/opt/anaconda3/lib/python3.7/site-packages/jinja2/environment.py", line 941, in from_string
    return cls.from_code(self, self.compile(source), globals, None)
  File "/opt/anaconda3/lib/python3.7/site-packages/jinja2/environment.py", line 638, in compile
    self.handle_exception(source=source_hint)
  File "/opt/anaconda3/lib/python3.7/site-packages/jinja2/environment.py", line 832, in handle_exception
    reraise(*rewrite_traceback_stack(source=source))
  File "/opt/anaconda3/lib/python3.7/site-packages/jinja2/_compat.py", line 28, in reraise
    raise value.with_traceback(tb)
  File "<unknown>", line 6, in template
jinja2.exceptions.TemplateSyntaxError: expected token ':', got 'Column'
  line 6
    partition_by ={ -- defining Column on which data would be partitioned with in dimension table

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/opt/anaconda3/lib/python3.7/site-packages/dbt/main.py", line 125, in main
    results, succeeded = handle_and_check(args)
  File "/opt/anaconda3/lib/python3.7/site-packages/dbt/main.py", line 203, in handle_and_check
    task, res = run_from_args(parsed)
  File "/opt/anaconda3/lib/python3.7/site-packages/dbt/main.py", line 256, in run_from_args
    results = task.run()
  File "/opt/anaconda3/lib/python3.7/site-packages/dbt/task/runnable.py", line 406, in run
    self._runtime_initialize()
  File "/opt/anaconda3/lib/python3.7/site-packages/dbt/task/runnable.py", line 122, in _runtime_initialize
    super()._runtime_initialize()
  File "/opt/anaconda3/lib/python3.7/site-packages/dbt/task/runnable.py", line 79, in _runtime_initialize
    self.load_manifest()
  File "/opt/anaconda3/lib/python3.7/site-packages/dbt/task/runnable.py", line 66, in load_manifest
    self.manifest = get_full_manifest(self.config)
  File "/opt/anaconda3/lib/python3.7/site-packages/dbt/perf_utils.py", line 31, in get_full_manifest
    adapter.connections.set_query_header,
  File "/opt/anaconda3/lib/python3.7/site-packages/dbt/parser/manifest.py", line 862, in load_manifest
    return ManifestLoader.load_all(config, macro_manifest, macro_hook)
  File "/opt/anaconda3/lib/python3.7/site-packages/dbt/parser/manifest.py", line 442, in load_all
    loader.load(macro_manifest=macro_manifest)
  File "/opt/anaconda3/lib/python3.7/site-packages/dbt/parser/manifest.py", line 290, in load
    self.parse_project(project, macro_manifest, old_results)
  File "/opt/anaconda3/lib/python3.7/site-packages/dbt/parser/manifest.py", line 237, in parse_project
    self.parse_with_cache(path, parser, old_results)
  File "/opt/anaconda3/lib/python3.7/site-packages/dbt/parser/manifest.py", line 188, in parse_with_cache
    parser.parse_file(block)
  File "/opt/anaconda3/lib/python3.7/site-packages/dbt/parser/base.py", line 432, in parse_file
    self.parse_node(file_block)
  File "/opt/anaconda3/lib/python3.7/site-packages/dbt/parser/base.py", line 405, in parse_node
    self.render_update(node, config)
  File "/opt/anaconda3/lib/python3.7/site-packages/dbt/parser/base.py", line 380, in render_update
    self.render_with_context(node, config)
  File "/opt/anaconda3/lib/python3.7/site-packages/dbt/parser/base.py", line 294, in render_with_context
    parsed_node.raw_sql, context, parsed_node, capture_macros=True
  File "/opt/anaconda3/lib/python3.7/site-packages/dbt/clients/jinja.py", line 580, in get_rendered
    native=native,
  File "/opt/anaconda3/lib/python3.7/site-packages/dbt/clients/jinja.py", line 528, in get_template
    return env.from_string(template_source, globals=ctx)
  File "/opt/anaconda3/lib/python3.7/contextlib.py", line 130, in __exit__
    self.gen.throw(type, value, traceback)
  File "/opt/anaconda3/lib/python3.7/site-packages/dbt/clients/jinja.py", line 504, in catch_jinja
    raise CompilationException(str(e), node) from e
dbt.exceptions.CompilationException: Compilation Error in model dim_service (models/Dimensions/dim_service.sql)
  expected token ':', got 'Column'
    line 6
      partition_by ={ -- defining Column on which data would be partitioned with in dimension table

2021-06-05 17:15:49.459434 (MainThread): Running with dbt=0.19.1
2021-06-05 17:15:50.344895 (MainThread): running dbt with arguments Namespace(cls=<class 'dbt.task.run.RunTask'>, debug=False, defer=None, exclude=None, fail_fast=False, full_refresh=False, log_cache_events=False, log_format='default', models=['dim_professional'], partial_parse=None, profile=None, profiles_dir='/Users/mac/.dbt', project_dir=None, record_timing_info=None, rpc_method='run', selector_name=None, single_threaded=False, state=None, strict=False, target=None, test_new_parser=False, threads=None, use_cache=True, use_colors=None, vars='{}', version_check=True, warn_error=False, which='run', write_json=True)
2021-06-05 17:15:50.346131 (MainThread): Tracking: tracking
2021-06-05 17:15:50.357744 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fa9a77e7450>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fa9a77e76d0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fa9a77e72d0>]}
2021-06-05 17:15:50.372562 (MainThread): Partial parsing not enabled
2021-06-05 17:15:50.374262 (MainThread): Parsing macros/etc.sql
2021-06-05 17:15:50.379031 (MainThread): Parsing macros/catalog.sql
2021-06-05 17:15:50.388108 (MainThread): Parsing macros/adapters.sql
2021-06-05 17:15:50.417613 (MainThread): Parsing macros/materializations/seed.sql
2021-06-05 17:15:50.421275 (MainThread): Parsing macros/materializations/view.sql
2021-06-05 17:15:50.425013 (MainThread): Parsing macros/materializations/table.sql
2021-06-05 17:15:50.438421 (MainThread): Parsing macros/materializations/copy.sql
2021-06-05 17:15:50.444860 (MainThread): Parsing macros/materializations/incremental.sql
2021-06-05 17:15:50.464943 (MainThread): Parsing macros/materializations/snapshot.sql
2021-06-05 17:15:50.468741 (MainThread): Parsing macros/core.sql
2021-06-05 17:15:50.474005 (MainThread): Parsing macros/materializations/helpers.sql
2021-06-05 17:15:50.486271 (MainThread): Parsing macros/materializations/snapshot/snapshot_merge.sql
2021-06-05 17:15:50.488654 (MainThread): Parsing macros/materializations/snapshot/strategies.sql
2021-06-05 17:15:50.513532 (MainThread): Parsing macros/materializations/snapshot/snapshot.sql
2021-06-05 17:15:50.558194 (MainThread): Parsing macros/materializations/seed/seed.sql
2021-06-05 17:15:50.586899 (MainThread): Parsing macros/materializations/incremental/helpers.sql
2021-06-05 17:15:50.589422 (MainThread): Parsing macros/materializations/incremental/incremental.sql
2021-06-05 17:15:50.598072 (MainThread): Parsing macros/materializations/common/merge.sql
2021-06-05 17:15:50.617222 (MainThread): Parsing macros/materializations/table/table.sql
2021-06-05 17:15:50.626716 (MainThread): Parsing macros/materializations/view/view.sql
2021-06-05 17:15:50.635204 (MainThread): Parsing macros/materializations/view/create_or_replace_view.sql
2021-06-05 17:15:50.642181 (MainThread): Parsing macros/etc/get_custom_alias.sql
2021-06-05 17:15:50.643528 (MainThread): Parsing macros/etc/query.sql
2021-06-05 17:15:50.644978 (MainThread): Parsing macros/etc/is_incremental.sql
2021-06-05 17:15:50.647174 (MainThread): Parsing macros/etc/datetime.sql
2021-06-05 17:15:50.659056 (MainThread): Parsing macros/etc/get_custom_schema.sql
2021-06-05 17:15:50.661838 (MainThread): Parsing macros/etc/get_custom_database.sql
2021-06-05 17:15:50.664158 (MainThread): Parsing macros/adapters/common.sql
2021-06-05 17:15:50.722583 (MainThread): Parsing macros/schema_tests/relationships.sql
2021-06-05 17:15:50.725143 (MainThread): Parsing macros/schema_tests/not_null.sql
2021-06-05 17:15:50.727187 (MainThread): Parsing macros/schema_tests/unique.sql
2021-06-05 17:15:50.729460 (MainThread): Parsing macros/schema_tests/accepted_values.sql
2021-06-05 17:15:50.739855 (MainThread): Partial parsing not enabled
2021-06-05 17:15:50.775012 (MainThread): Acquiring new bigquery connection "model.werkspot_technical_challenge.dim_service".
2021-06-05 17:15:50.778468 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fa9a78101d0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fa9a77e7490>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fa9a7968ad0>]}
2021-06-05 17:15:50.778934 (MainThread): Flushing usage events
2021-06-05 17:15:51.669069 (MainThread): Connection 'model.werkspot_technical_challenge.dim_service' was properly closed.
2021-06-05 17:15:51.669337 (MainThread): Encountered an error:
2021-06-05 17:15:51.669550 (MainThread): Compilation Error in model dim_service (models/Dimensions/dim_service.sql)
  expected token ':', got 'Column'
    line 6
      partition_by ={ -- defining Column on which data would be partitioned with in dimension table
2021-06-05 17:15:51.672379 (MainThread): Traceback (most recent call last):
  File "/opt/anaconda3/lib/python3.7/site-packages/dbt/clients/jinja.py", line 501, in catch_jinja
    yield
  File "/opt/anaconda3/lib/python3.7/site-packages/dbt/clients/jinja.py", line 528, in get_template
    return env.from_string(template_source, globals=ctx)
  File "/opt/anaconda3/lib/python3.7/site-packages/jinja2/environment.py", line 941, in from_string
    return cls.from_code(self, self.compile(source), globals, None)
  File "/opt/anaconda3/lib/python3.7/site-packages/jinja2/environment.py", line 638, in compile
    self.handle_exception(source=source_hint)
  File "/opt/anaconda3/lib/python3.7/site-packages/jinja2/environment.py", line 832, in handle_exception
    reraise(*rewrite_traceback_stack(source=source))
  File "/opt/anaconda3/lib/python3.7/site-packages/jinja2/_compat.py", line 28, in reraise
    raise value.with_traceback(tb)
  File "<unknown>", line 6, in template
jinja2.exceptions.TemplateSyntaxError: expected token ':', got 'Column'
  line 6
    partition_by ={ -- defining Column on which data would be partitioned with in dimension table

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/opt/anaconda3/lib/python3.7/site-packages/dbt/main.py", line 125, in main
    results, succeeded = handle_and_check(args)
  File "/opt/anaconda3/lib/python3.7/site-packages/dbt/main.py", line 203, in handle_and_check
    task, res = run_from_args(parsed)
  File "/opt/anaconda3/lib/python3.7/site-packages/dbt/main.py", line 256, in run_from_args
    results = task.run()
  File "/opt/anaconda3/lib/python3.7/site-packages/dbt/task/runnable.py", line 406, in run
    self._runtime_initialize()
  File "/opt/anaconda3/lib/python3.7/site-packages/dbt/task/runnable.py", line 122, in _runtime_initialize
    super()._runtime_initialize()
  File "/opt/anaconda3/lib/python3.7/site-packages/dbt/task/runnable.py", line 79, in _runtime_initialize
    self.load_manifest()
  File "/opt/anaconda3/lib/python3.7/site-packages/dbt/task/runnable.py", line 66, in load_manifest
    self.manifest = get_full_manifest(self.config)
  File "/opt/anaconda3/lib/python3.7/site-packages/dbt/perf_utils.py", line 31, in get_full_manifest
    adapter.connections.set_query_header,
  File "/opt/anaconda3/lib/python3.7/site-packages/dbt/parser/manifest.py", line 862, in load_manifest
    return ManifestLoader.load_all(config, macro_manifest, macro_hook)
  File "/opt/anaconda3/lib/python3.7/site-packages/dbt/parser/manifest.py", line 442, in load_all
    loader.load(macro_manifest=macro_manifest)
  File "/opt/anaconda3/lib/python3.7/site-packages/dbt/parser/manifest.py", line 290, in load
    self.parse_project(project, macro_manifest, old_results)
  File "/opt/anaconda3/lib/python3.7/site-packages/dbt/parser/manifest.py", line 237, in parse_project
    self.parse_with_cache(path, parser, old_results)
  File "/opt/anaconda3/lib/python3.7/site-packages/dbt/parser/manifest.py", line 188, in parse_with_cache
    parser.parse_file(block)
  File "/opt/anaconda3/lib/python3.7/site-packages/dbt/parser/base.py", line 432, in parse_file
    self.parse_node(file_block)
  File "/opt/anaconda3/lib/python3.7/site-packages/dbt/parser/base.py", line 405, in parse_node
    self.render_update(node, config)
  File "/opt/anaconda3/lib/python3.7/site-packages/dbt/parser/base.py", line 380, in render_update
    self.render_with_context(node, config)
  File "/opt/anaconda3/lib/python3.7/site-packages/dbt/parser/base.py", line 294, in render_with_context
    parsed_node.raw_sql, context, parsed_node, capture_macros=True
  File "/opt/anaconda3/lib/python3.7/site-packages/dbt/clients/jinja.py", line 580, in get_rendered
    native=native,
  File "/opt/anaconda3/lib/python3.7/site-packages/dbt/clients/jinja.py", line 528, in get_template
    return env.from_string(template_source, globals=ctx)
  File "/opt/anaconda3/lib/python3.7/contextlib.py", line 130, in __exit__
    self.gen.throw(type, value, traceback)
  File "/opt/anaconda3/lib/python3.7/site-packages/dbt/clients/jinja.py", line 504, in catch_jinja
    raise CompilationException(str(e), node) from e
dbt.exceptions.CompilationException: Compilation Error in model dim_service (models/Dimensions/dim_service.sql)
  expected token ':', got 'Column'
    line 6
      partition_by ={ -- defining Column on which data would be partitioned with in dimension table

2021-06-05 17:16:58.065931 (MainThread): Running with dbt=0.19.1
2021-06-05 17:16:59.167054 (MainThread): running dbt with arguments Namespace(cls=<class 'dbt.task.run.RunTask'>, debug=False, defer=None, exclude=None, fail_fast=False, full_refresh=False, log_cache_events=False, log_format='default', models=['dim_professional'], partial_parse=None, profile=None, profiles_dir='/Users/mac/.dbt', project_dir=None, record_timing_info=None, rpc_method='run', selector_name=None, single_threaded=False, state=None, strict=False, target=None, test_new_parser=False, threads=None, use_cache=True, use_colors=None, vars='{}', version_check=True, warn_error=False, which='run', write_json=True)
2021-06-05 17:16:59.168494 (MainThread): Tracking: tracking
2021-06-05 17:16:59.185726 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fc23610c990>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fc23611b450>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fc23611b050>]}
2021-06-05 17:16:59.200781 (MainThread): Partial parsing not enabled
2021-06-05 17:16:59.202379 (MainThread): Parsing macros/etc.sql
2021-06-05 17:16:59.207579 (MainThread): Parsing macros/catalog.sql
2021-06-05 17:16:59.217032 (MainThread): Parsing macros/adapters.sql
2021-06-05 17:16:59.246726 (MainThread): Parsing macros/materializations/seed.sql
2021-06-05 17:16:59.252892 (MainThread): Parsing macros/materializations/view.sql
2021-06-05 17:16:59.257889 (MainThread): Parsing macros/materializations/table.sql
2021-06-05 17:16:59.275034 (MainThread): Parsing macros/materializations/copy.sql
2021-06-05 17:16:59.282236 (MainThread): Parsing macros/materializations/incremental.sql
2021-06-05 17:16:59.302494 (MainThread): Parsing macros/materializations/snapshot.sql
2021-06-05 17:16:59.307162 (MainThread): Parsing macros/core.sql
2021-06-05 17:16:59.313035 (MainThread): Parsing macros/materializations/helpers.sql
2021-06-05 17:16:59.325874 (MainThread): Parsing macros/materializations/snapshot/snapshot_merge.sql
2021-06-05 17:16:59.328557 (MainThread): Parsing macros/materializations/snapshot/strategies.sql
2021-06-05 17:16:59.353100 (MainThread): Parsing macros/materializations/snapshot/snapshot.sql
2021-06-05 17:16:59.399116 (MainThread): Parsing macros/materializations/seed/seed.sql
2021-06-05 17:16:59.431252 (MainThread): Parsing macros/materializations/incremental/helpers.sql
2021-06-05 17:16:59.433996 (MainThread): Parsing macros/materializations/incremental/incremental.sql
2021-06-05 17:16:59.443085 (MainThread): Parsing macros/materializations/common/merge.sql
2021-06-05 17:16:59.463029 (MainThread): Parsing macros/materializations/table/table.sql
2021-06-05 17:16:59.473603 (MainThread): Parsing macros/materializations/view/view.sql
2021-06-05 17:16:59.483653 (MainThread): Parsing macros/materializations/view/create_or_replace_view.sql
2021-06-05 17:16:59.490549 (MainThread): Parsing macros/etc/get_custom_alias.sql
2021-06-05 17:16:59.491973 (MainThread): Parsing macros/etc/query.sql
2021-06-05 17:16:59.493661 (MainThread): Parsing macros/etc/is_incremental.sql
2021-06-05 17:16:59.496108 (MainThread): Parsing macros/etc/datetime.sql
2021-06-05 17:16:59.508239 (MainThread): Parsing macros/etc/get_custom_schema.sql
2021-06-05 17:16:59.511011 (MainThread): Parsing macros/etc/get_custom_database.sql
2021-06-05 17:16:59.513387 (MainThread): Parsing macros/adapters/common.sql
2021-06-05 17:16:59.572799 (MainThread): Parsing macros/schema_tests/relationships.sql
2021-06-05 17:16:59.576026 (MainThread): Parsing macros/schema_tests/not_null.sql
2021-06-05 17:16:59.578539 (MainThread): Parsing macros/schema_tests/unique.sql
2021-06-05 17:16:59.581933 (MainThread): Parsing macros/schema_tests/accepted_values.sql
2021-06-05 17:16:59.593479 (MainThread): Partial parsing not enabled
2021-06-05 17:16:59.629581 (MainThread): Acquiring new bigquery connection "model.werkspot_technical_challenge.dim_service".
2021-06-05 17:16:59.651571 (MainThread): Acquiring new bigquery connection "model.werkspot_technical_challenge.dim_professional".
2021-06-05 17:16:59.654988 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fc236176410>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fc23629cf90>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fc2362af690>]}
2021-06-05 17:16:59.655361 (MainThread): Flushing usage events
2021-06-05 17:17:00.505258 (MainThread): Connection 'model.werkspot_technical_challenge.dim_professional' was properly closed.
2021-06-05 17:17:00.505531 (MainThread): Encountered an error:
2021-06-05 17:17:00.505753 (MainThread): Compilation Error in model dim_professional (models/Dimensions/dim_professional.sql)
  invalid syntax for function call expression
    line 2
      config(
2021-06-05 17:17:00.513559 (MainThread): Traceback (most recent call last):
  File "/opt/anaconda3/lib/python3.7/site-packages/dbt/clients/jinja.py", line 501, in catch_jinja
    yield
  File "/opt/anaconda3/lib/python3.7/site-packages/dbt/clients/jinja.py", line 528, in get_template
    return env.from_string(template_source, globals=ctx)
  File "/opt/anaconda3/lib/python3.7/site-packages/jinja2/environment.py", line 941, in from_string
    return cls.from_code(self, self.compile(source), globals, None)
  File "/opt/anaconda3/lib/python3.7/site-packages/jinja2/environment.py", line 638, in compile
    self.handle_exception(source=source_hint)
  File "/opt/anaconda3/lib/python3.7/site-packages/jinja2/environment.py", line 832, in handle_exception
    reraise(*rewrite_traceback_stack(source=source))
  File "/opt/anaconda3/lib/python3.7/site-packages/jinja2/_compat.py", line 28, in reraise
    raise value.with_traceback(tb)
  File "<unknown>", line 2, in template
jinja2.exceptions.TemplateSyntaxError: invalid syntax for function call expression
  line 2
    config(

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/opt/anaconda3/lib/python3.7/site-packages/dbt/main.py", line 125, in main
    results, succeeded = handle_and_check(args)
  File "/opt/anaconda3/lib/python3.7/site-packages/dbt/main.py", line 203, in handle_and_check
    task, res = run_from_args(parsed)
  File "/opt/anaconda3/lib/python3.7/site-packages/dbt/main.py", line 256, in run_from_args
    results = task.run()
  File "/opt/anaconda3/lib/python3.7/site-packages/dbt/task/runnable.py", line 406, in run
    self._runtime_initialize()
  File "/opt/anaconda3/lib/python3.7/site-packages/dbt/task/runnable.py", line 122, in _runtime_initialize
    super()._runtime_initialize()
  File "/opt/anaconda3/lib/python3.7/site-packages/dbt/task/runnable.py", line 79, in _runtime_initialize
    self.load_manifest()
  File "/opt/anaconda3/lib/python3.7/site-packages/dbt/task/runnable.py", line 66, in load_manifest
    self.manifest = get_full_manifest(self.config)
  File "/opt/anaconda3/lib/python3.7/site-packages/dbt/perf_utils.py", line 31, in get_full_manifest
    adapter.connections.set_query_header,
  File "/opt/anaconda3/lib/python3.7/site-packages/dbt/parser/manifest.py", line 862, in load_manifest
    return ManifestLoader.load_all(config, macro_manifest, macro_hook)
  File "/opt/anaconda3/lib/python3.7/site-packages/dbt/parser/manifest.py", line 442, in load_all
    loader.load(macro_manifest=macro_manifest)
  File "/opt/anaconda3/lib/python3.7/site-packages/dbt/parser/manifest.py", line 290, in load
    self.parse_project(project, macro_manifest, old_results)
  File "/opt/anaconda3/lib/python3.7/site-packages/dbt/parser/manifest.py", line 237, in parse_project
    self.parse_with_cache(path, parser, old_results)
  File "/opt/anaconda3/lib/python3.7/site-packages/dbt/parser/manifest.py", line 188, in parse_with_cache
    parser.parse_file(block)
  File "/opt/anaconda3/lib/python3.7/site-packages/dbt/parser/base.py", line 432, in parse_file
    self.parse_node(file_block)
  File "/opt/anaconda3/lib/python3.7/site-packages/dbt/parser/base.py", line 405, in parse_node
    self.render_update(node, config)
  File "/opt/anaconda3/lib/python3.7/site-packages/dbt/parser/base.py", line 380, in render_update
    self.render_with_context(node, config)
  File "/opt/anaconda3/lib/python3.7/site-packages/dbt/parser/base.py", line 294, in render_with_context
    parsed_node.raw_sql, context, parsed_node, capture_macros=True
  File "/opt/anaconda3/lib/python3.7/site-packages/dbt/clients/jinja.py", line 580, in get_rendered
    native=native,
  File "/opt/anaconda3/lib/python3.7/site-packages/dbt/clients/jinja.py", line 528, in get_template
    return env.from_string(template_source, globals=ctx)
  File "/opt/anaconda3/lib/python3.7/contextlib.py", line 130, in __exit__
    self.gen.throw(type, value, traceback)
  File "/opt/anaconda3/lib/python3.7/site-packages/dbt/clients/jinja.py", line 504, in catch_jinja
    raise CompilationException(str(e), node) from e
dbt.exceptions.CompilationException: Compilation Error in model dim_professional (models/Dimensions/dim_professional.sql)
  invalid syntax for function call expression
    line 2
      config(

2021-06-05 17:17:19.673854 (MainThread): Running with dbt=0.19.1
2021-06-05 17:17:20.424965 (MainThread): running dbt with arguments Namespace(cls=<class 'dbt.task.run.RunTask'>, debug=False, defer=None, exclude=None, fail_fast=False, full_refresh=False, log_cache_events=False, log_format='default', models=['dim_professional'], partial_parse=None, profile=None, profiles_dir='/Users/mac/.dbt', project_dir=None, record_timing_info=None, rpc_method='run', selector_name=None, single_threaded=False, state=None, strict=False, target=None, test_new_parser=False, threads=None, use_cache=True, use_colors=None, vars='{}', version_check=True, warn_error=False, which='run', write_json=True)
2021-06-05 17:17:20.427286 (MainThread): Tracking: tracking
2021-06-05 17:17:20.442858 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fb9e8fdb150>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fb9e8fdb550>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fb9e8fdb3d0>]}
2021-06-05 17:17:20.457064 (MainThread): Partial parsing not enabled
2021-06-05 17:17:20.458550 (MainThread): Parsing macros/etc.sql
2021-06-05 17:17:20.462940 (MainThread): Parsing macros/catalog.sql
2021-06-05 17:17:20.473102 (MainThread): Parsing macros/adapters.sql
2021-06-05 17:17:20.501229 (MainThread): Parsing macros/materializations/seed.sql
2021-06-05 17:17:20.504897 (MainThread): Parsing macros/materializations/view.sql
2021-06-05 17:17:20.508612 (MainThread): Parsing macros/materializations/table.sql
2021-06-05 17:17:20.522073 (MainThread): Parsing macros/materializations/copy.sql
2021-06-05 17:17:20.527923 (MainThread): Parsing macros/materializations/incremental.sql
2021-06-05 17:17:20.544742 (MainThread): Parsing macros/materializations/snapshot.sql
2021-06-05 17:17:20.549126 (MainThread): Parsing macros/core.sql
2021-06-05 17:17:20.554927 (MainThread): Parsing macros/materializations/helpers.sql
2021-06-05 17:17:20.567254 (MainThread): Parsing macros/materializations/snapshot/snapshot_merge.sql
2021-06-05 17:17:20.569642 (MainThread): Parsing macros/materializations/snapshot/strategies.sql
2021-06-05 17:17:20.594381 (MainThread): Parsing macros/materializations/snapshot/snapshot.sql
2021-06-05 17:17:20.639191 (MainThread): Parsing macros/materializations/seed/seed.sql
2021-06-05 17:17:20.667653 (MainThread): Parsing macros/materializations/incremental/helpers.sql
2021-06-05 17:17:20.670128 (MainThread): Parsing macros/materializations/incremental/incremental.sql
2021-06-05 17:17:20.678576 (MainThread): Parsing macros/materializations/common/merge.sql
2021-06-05 17:17:20.697919 (MainThread): Parsing macros/materializations/table/table.sql
2021-06-05 17:17:20.707029 (MainThread): Parsing macros/materializations/view/view.sql
2021-06-05 17:17:20.716089 (MainThread): Parsing macros/materializations/view/create_or_replace_view.sql
2021-06-05 17:17:20.723037 (MainThread): Parsing macros/etc/get_custom_alias.sql
2021-06-05 17:17:20.724362 (MainThread): Parsing macros/etc/query.sql
2021-06-05 17:17:20.725801 (MainThread): Parsing macros/etc/is_incremental.sql
2021-06-05 17:17:20.727969 (MainThread): Parsing macros/etc/datetime.sql
2021-06-05 17:17:20.739867 (MainThread): Parsing macros/etc/get_custom_schema.sql
2021-06-05 17:17:20.742722 (MainThread): Parsing macros/etc/get_custom_database.sql
2021-06-05 17:17:20.745189 (MainThread): Parsing macros/adapters/common.sql
2021-06-05 17:17:20.804983 (MainThread): Parsing macros/schema_tests/relationships.sql
2021-06-05 17:17:20.807567 (MainThread): Parsing macros/schema_tests/not_null.sql
2021-06-05 17:17:20.809618 (MainThread): Parsing macros/schema_tests/unique.sql
2021-06-05 17:17:20.812490 (MainThread): Parsing macros/schema_tests/accepted_values.sql
2021-06-05 17:17:20.823043 (MainThread): Partial parsing not enabled
2021-06-05 17:17:20.856071 (MainThread): Acquiring new bigquery connection "model.werkspot_technical_challenge.dim_service".
2021-06-05 17:17:20.876612 (MainThread): Acquiring new bigquery connection "model.werkspot_technical_challenge.dim_professional".
2021-06-05 17:17:20.879256 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fb9e902ab50>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fb9e9183190>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fb9e9053210>]}
2021-06-05 17:17:20.879509 (MainThread): Flushing usage events
2021-06-05 17:17:21.899741 (MainThread): Connection 'model.werkspot_technical_challenge.dim_professional' was properly closed.
2021-06-05 17:17:21.900012 (MainThread): Encountered an error:
2021-06-05 17:17:21.900297 (MainThread): Compilation Error in model dim_professional (models/Dimensions/dim_professional.sql)
  invalid syntax for function call expression
    line 2
      config(
2021-06-05 17:17:21.903537 (MainThread): Traceback (most recent call last):
  File "/opt/anaconda3/lib/python3.7/site-packages/dbt/clients/jinja.py", line 501, in catch_jinja
    yield
  File "/opt/anaconda3/lib/python3.7/site-packages/dbt/clients/jinja.py", line 528, in get_template
    return env.from_string(template_source, globals=ctx)
  File "/opt/anaconda3/lib/python3.7/site-packages/jinja2/environment.py", line 941, in from_string
    return cls.from_code(self, self.compile(source), globals, None)
  File "/opt/anaconda3/lib/python3.7/site-packages/jinja2/environment.py", line 638, in compile
    self.handle_exception(source=source_hint)
  File "/opt/anaconda3/lib/python3.7/site-packages/jinja2/environment.py", line 832, in handle_exception
    reraise(*rewrite_traceback_stack(source=source))
  File "/opt/anaconda3/lib/python3.7/site-packages/jinja2/_compat.py", line 28, in reraise
    raise value.with_traceback(tb)
  File "<unknown>", line 2, in template
jinja2.exceptions.TemplateSyntaxError: invalid syntax for function call expression
  line 2
    config(

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/opt/anaconda3/lib/python3.7/site-packages/dbt/main.py", line 125, in main
    results, succeeded = handle_and_check(args)
  File "/opt/anaconda3/lib/python3.7/site-packages/dbt/main.py", line 203, in handle_and_check
    task, res = run_from_args(parsed)
  File "/opt/anaconda3/lib/python3.7/site-packages/dbt/main.py", line 256, in run_from_args
    results = task.run()
  File "/opt/anaconda3/lib/python3.7/site-packages/dbt/task/runnable.py", line 406, in run
    self._runtime_initialize()
  File "/opt/anaconda3/lib/python3.7/site-packages/dbt/task/runnable.py", line 122, in _runtime_initialize
    super()._runtime_initialize()
  File "/opt/anaconda3/lib/python3.7/site-packages/dbt/task/runnable.py", line 79, in _runtime_initialize
    self.load_manifest()
  File "/opt/anaconda3/lib/python3.7/site-packages/dbt/task/runnable.py", line 66, in load_manifest
    self.manifest = get_full_manifest(self.config)
  File "/opt/anaconda3/lib/python3.7/site-packages/dbt/perf_utils.py", line 31, in get_full_manifest
    adapter.connections.set_query_header,
  File "/opt/anaconda3/lib/python3.7/site-packages/dbt/parser/manifest.py", line 862, in load_manifest
    return ManifestLoader.load_all(config, macro_manifest, macro_hook)
  File "/opt/anaconda3/lib/python3.7/site-packages/dbt/parser/manifest.py", line 442, in load_all
    loader.load(macro_manifest=macro_manifest)
  File "/opt/anaconda3/lib/python3.7/site-packages/dbt/parser/manifest.py", line 290, in load
    self.parse_project(project, macro_manifest, old_results)
  File "/opt/anaconda3/lib/python3.7/site-packages/dbt/parser/manifest.py", line 237, in parse_project
    self.parse_with_cache(path, parser, old_results)
  File "/opt/anaconda3/lib/python3.7/site-packages/dbt/parser/manifest.py", line 188, in parse_with_cache
    parser.parse_file(block)
  File "/opt/anaconda3/lib/python3.7/site-packages/dbt/parser/base.py", line 432, in parse_file
    self.parse_node(file_block)
  File "/opt/anaconda3/lib/python3.7/site-packages/dbt/parser/base.py", line 405, in parse_node
    self.render_update(node, config)
  File "/opt/anaconda3/lib/python3.7/site-packages/dbt/parser/base.py", line 380, in render_update
    self.render_with_context(node, config)
  File "/opt/anaconda3/lib/python3.7/site-packages/dbt/parser/base.py", line 294, in render_with_context
    parsed_node.raw_sql, context, parsed_node, capture_macros=True
  File "/opt/anaconda3/lib/python3.7/site-packages/dbt/clients/jinja.py", line 580, in get_rendered
    native=native,
  File "/opt/anaconda3/lib/python3.7/site-packages/dbt/clients/jinja.py", line 528, in get_template
    return env.from_string(template_source, globals=ctx)
  File "/opt/anaconda3/lib/python3.7/contextlib.py", line 130, in __exit__
    self.gen.throw(type, value, traceback)
  File "/opt/anaconda3/lib/python3.7/site-packages/dbt/clients/jinja.py", line 504, in catch_jinja
    raise CompilationException(str(e), node) from e
dbt.exceptions.CompilationException: Compilation Error in model dim_professional (models/Dimensions/dim_professional.sql)
  invalid syntax for function call expression
    line 2
      config(

2021-06-05 17:17:52.510012 (MainThread): Running with dbt=0.19.1
2021-06-05 17:17:53.252650 (MainThread): running dbt with arguments Namespace(cls=<class 'dbt.task.run.RunTask'>, debug=False, defer=None, exclude=None, fail_fast=False, full_refresh=False, log_cache_events=False, log_format='default', models=['dim_professional'], partial_parse=None, profile=None, profiles_dir='/Users/mac/.dbt', project_dir=None, record_timing_info=None, rpc_method='run', selector_name=None, single_threaded=False, state=None, strict=False, target=None, test_new_parser=False, threads=None, use_cache=True, use_colors=None, vars='{}', version_check=True, warn_error=False, which='run', write_json=True)
2021-06-05 17:17:53.284592 (MainThread): Tracking: tracking
2021-06-05 17:17:53.294120 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ff0b1767290>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ff0b17674d0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ff0b1767150>]}
2021-06-05 17:17:53.309060 (MainThread): Partial parsing not enabled
2021-06-05 17:17:53.310526 (MainThread): Parsing macros/etc.sql
2021-06-05 17:17:53.314878 (MainThread): Parsing macros/catalog.sql
2021-06-05 17:17:53.323981 (MainThread): Parsing macros/adapters.sql
2021-06-05 17:17:53.350544 (MainThread): Parsing macros/materializations/seed.sql
2021-06-05 17:17:53.354178 (MainThread): Parsing macros/materializations/view.sql
2021-06-05 17:17:53.357890 (MainThread): Parsing macros/materializations/table.sql
2021-06-05 17:17:53.371291 (MainThread): Parsing macros/materializations/copy.sql
2021-06-05 17:17:53.377154 (MainThread): Parsing macros/materializations/incremental.sql
2021-06-05 17:17:53.393711 (MainThread): Parsing macros/materializations/snapshot.sql
2021-06-05 17:17:53.397398 (MainThread): Parsing macros/core.sql
2021-06-05 17:17:53.402523 (MainThread): Parsing macros/materializations/helpers.sql
2021-06-05 17:17:53.414561 (MainThread): Parsing macros/materializations/snapshot/snapshot_merge.sql
2021-06-05 17:17:53.416973 (MainThread): Parsing macros/materializations/snapshot/strategies.sql
2021-06-05 17:17:53.440740 (MainThread): Parsing macros/materializations/snapshot/snapshot.sql
2021-06-05 17:17:53.484920 (MainThread): Parsing macros/materializations/seed/seed.sql
2021-06-05 17:17:53.513081 (MainThread): Parsing macros/materializations/incremental/helpers.sql
2021-06-05 17:17:53.515586 (MainThread): Parsing macros/materializations/incremental/incremental.sql
2021-06-05 17:17:53.523893 (MainThread): Parsing macros/materializations/common/merge.sql
2021-06-05 17:17:53.543121 (MainThread): Parsing macros/materializations/table/table.sql
2021-06-05 17:17:53.552203 (MainThread): Parsing macros/materializations/view/view.sql
2021-06-05 17:17:53.561368 (MainThread): Parsing macros/materializations/view/create_or_replace_view.sql
2021-06-05 17:17:53.568030 (MainThread): Parsing macros/etc/get_custom_alias.sql
2021-06-05 17:17:53.569312 (MainThread): Parsing macros/etc/query.sql
2021-06-05 17:17:53.570717 (MainThread): Parsing macros/etc/is_incremental.sql
2021-06-05 17:17:53.572893 (MainThread): Parsing macros/etc/datetime.sql
2021-06-05 17:17:53.585349 (MainThread): Parsing macros/etc/get_custom_schema.sql
2021-06-05 17:17:53.588052 (MainThread): Parsing macros/etc/get_custom_database.sql
2021-06-05 17:17:53.590337 (MainThread): Parsing macros/adapters/common.sql
2021-06-05 17:17:53.648980 (MainThread): Parsing macros/schema_tests/relationships.sql
2021-06-05 17:17:53.651537 (MainThread): Parsing macros/schema_tests/not_null.sql
2021-06-05 17:17:53.653580 (MainThread): Parsing macros/schema_tests/unique.sql
2021-06-05 17:17:53.655821 (MainThread): Parsing macros/schema_tests/accepted_values.sql
2021-06-05 17:17:53.666565 (MainThread): Partial parsing not enabled
2021-06-05 17:17:53.700119 (MainThread): Acquiring new bigquery connection "model.werkspot_technical_challenge.dim_service".
2021-06-05 17:17:53.721051 (MainThread): Acquiring new bigquery connection "model.werkspot_technical_challenge.dim_professional".
2021-06-05 17:17:53.729584 (MainThread): Acquiring new bigquery connection "model.werkspot_technical_challenge.fct_fee".
2021-06-05 17:17:53.732467 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ff0b2212510>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ff0b224a490>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ff0b224abd0>]}
2021-06-05 17:17:53.732776 (MainThread): Flushing usage events
2021-06-05 17:17:55.530429 (MainThread): Connection 'model.werkspot_technical_challenge.fct_fee' was properly closed.
2021-06-05 17:17:55.530699 (MainThread): Encountered an error:
2021-06-05 17:17:55.530921 (MainThread): Compilation Error in model fct_fee (models/Facts/fct_fee.sql)
  invalid syntax for function call expression
    line 2
      config(
2021-06-05 17:17:55.533804 (MainThread): Traceback (most recent call last):
  File "/opt/anaconda3/lib/python3.7/site-packages/dbt/clients/jinja.py", line 501, in catch_jinja
    yield
  File "/opt/anaconda3/lib/python3.7/site-packages/dbt/clients/jinja.py", line 528, in get_template
    return env.from_string(template_source, globals=ctx)
  File "/opt/anaconda3/lib/python3.7/site-packages/jinja2/environment.py", line 941, in from_string
    return cls.from_code(self, self.compile(source), globals, None)
  File "/opt/anaconda3/lib/python3.7/site-packages/jinja2/environment.py", line 638, in compile
    self.handle_exception(source=source_hint)
  File "/opt/anaconda3/lib/python3.7/site-packages/jinja2/environment.py", line 832, in handle_exception
    reraise(*rewrite_traceback_stack(source=source))
  File "/opt/anaconda3/lib/python3.7/site-packages/jinja2/_compat.py", line 28, in reraise
    raise value.with_traceback(tb)
  File "<unknown>", line 2, in template
jinja2.exceptions.TemplateSyntaxError: invalid syntax for function call expression
  line 2
    config(

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/opt/anaconda3/lib/python3.7/site-packages/dbt/main.py", line 125, in main
    results, succeeded = handle_and_check(args)
  File "/opt/anaconda3/lib/python3.7/site-packages/dbt/main.py", line 203, in handle_and_check
    task, res = run_from_args(parsed)
  File "/opt/anaconda3/lib/python3.7/site-packages/dbt/main.py", line 256, in run_from_args
    results = task.run()
  File "/opt/anaconda3/lib/python3.7/site-packages/dbt/task/runnable.py", line 406, in run
    self._runtime_initialize()
  File "/opt/anaconda3/lib/python3.7/site-packages/dbt/task/runnable.py", line 122, in _runtime_initialize
    super()._runtime_initialize()
  File "/opt/anaconda3/lib/python3.7/site-packages/dbt/task/runnable.py", line 79, in _runtime_initialize
    self.load_manifest()
  File "/opt/anaconda3/lib/python3.7/site-packages/dbt/task/runnable.py", line 66, in load_manifest
    self.manifest = get_full_manifest(self.config)
  File "/opt/anaconda3/lib/python3.7/site-packages/dbt/perf_utils.py", line 31, in get_full_manifest
    adapter.connections.set_query_header,
  File "/opt/anaconda3/lib/python3.7/site-packages/dbt/parser/manifest.py", line 862, in load_manifest
    return ManifestLoader.load_all(config, macro_manifest, macro_hook)
  File "/opt/anaconda3/lib/python3.7/site-packages/dbt/parser/manifest.py", line 442, in load_all
    loader.load(macro_manifest=macro_manifest)
  File "/opt/anaconda3/lib/python3.7/site-packages/dbt/parser/manifest.py", line 290, in load
    self.parse_project(project, macro_manifest, old_results)
  File "/opt/anaconda3/lib/python3.7/site-packages/dbt/parser/manifest.py", line 237, in parse_project
    self.parse_with_cache(path, parser, old_results)
  File "/opt/anaconda3/lib/python3.7/site-packages/dbt/parser/manifest.py", line 188, in parse_with_cache
    parser.parse_file(block)
  File "/opt/anaconda3/lib/python3.7/site-packages/dbt/parser/base.py", line 432, in parse_file
    self.parse_node(file_block)
  File "/opt/anaconda3/lib/python3.7/site-packages/dbt/parser/base.py", line 405, in parse_node
    self.render_update(node, config)
  File "/opt/anaconda3/lib/python3.7/site-packages/dbt/parser/base.py", line 380, in render_update
    self.render_with_context(node, config)
  File "/opt/anaconda3/lib/python3.7/site-packages/dbt/parser/base.py", line 294, in render_with_context
    parsed_node.raw_sql, context, parsed_node, capture_macros=True
  File "/opt/anaconda3/lib/python3.7/site-packages/dbt/clients/jinja.py", line 580, in get_rendered
    native=native,
  File "/opt/anaconda3/lib/python3.7/site-packages/dbt/clients/jinja.py", line 528, in get_template
    return env.from_string(template_source, globals=ctx)
  File "/opt/anaconda3/lib/python3.7/contextlib.py", line 130, in __exit__
    self.gen.throw(type, value, traceback)
  File "/opt/anaconda3/lib/python3.7/site-packages/dbt/clients/jinja.py", line 504, in catch_jinja
    raise CompilationException(str(e), node) from e
dbt.exceptions.CompilationException: Compilation Error in model fct_fee (models/Facts/fct_fee.sql)
  invalid syntax for function call expression
    line 2
      config(

2021-06-05 17:18:16.950548 (MainThread): Running with dbt=0.19.1
2021-06-05 17:18:17.681789 (MainThread): running dbt with arguments Namespace(cls=<class 'dbt.task.run.RunTask'>, debug=False, defer=None, exclude=None, fail_fast=False, full_refresh=False, log_cache_events=False, log_format='default', models=['dim_professional'], partial_parse=None, profile=None, profiles_dir='/Users/mac/.dbt', project_dir=None, record_timing_info=None, rpc_method='run', selector_name=None, single_threaded=False, state=None, strict=False, target=None, test_new_parser=False, threads=None, use_cache=True, use_colors=None, vars='{}', version_check=True, warn_error=False, which='run', write_json=True)
2021-06-05 17:18:17.682993 (MainThread): Tracking: tracking
2021-06-05 17:18:17.698370 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7feb6391b290>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7feb6273dfd0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7feb6391b190>]}
2021-06-05 17:18:17.714136 (MainThread): Partial parsing not enabled
2021-06-05 17:18:17.715689 (MainThread): Parsing macros/etc.sql
2021-06-05 17:18:17.719824 (MainThread): Parsing macros/catalog.sql
2021-06-05 17:18:17.729366 (MainThread): Parsing macros/adapters.sql
2021-06-05 17:18:17.757521 (MainThread): Parsing macros/materializations/seed.sql
2021-06-05 17:18:17.761187 (MainThread): Parsing macros/materializations/view.sql
2021-06-05 17:18:17.764906 (MainThread): Parsing macros/materializations/table.sql
2021-06-05 17:18:17.778220 (MainThread): Parsing macros/materializations/copy.sql
2021-06-05 17:18:17.784042 (MainThread): Parsing macros/materializations/incremental.sql
2021-06-05 17:18:17.800873 (MainThread): Parsing macros/materializations/snapshot.sql
2021-06-05 17:18:17.804584 (MainThread): Parsing macros/core.sql
2021-06-05 17:18:17.810013 (MainThread): Parsing macros/materializations/helpers.sql
2021-06-05 17:18:17.822147 (MainThread): Parsing macros/materializations/snapshot/snapshot_merge.sql
2021-06-05 17:18:17.824518 (MainThread): Parsing macros/materializations/snapshot/strategies.sql
2021-06-05 17:18:17.848512 (MainThread): Parsing macros/materializations/snapshot/snapshot.sql
2021-06-05 17:18:17.893312 (MainThread): Parsing macros/materializations/seed/seed.sql
2021-06-05 17:18:17.921258 (MainThread): Parsing macros/materializations/incremental/helpers.sql
2021-06-05 17:18:17.923792 (MainThread): Parsing macros/materializations/incremental/incremental.sql
2021-06-05 17:18:17.931936 (MainThread): Parsing macros/materializations/common/merge.sql
2021-06-05 17:18:17.951115 (MainThread): Parsing macros/materializations/table/table.sql
2021-06-05 17:18:17.960510 (MainThread): Parsing macros/materializations/view/view.sql
2021-06-05 17:18:17.969055 (MainThread): Parsing macros/materializations/view/create_or_replace_view.sql
2021-06-05 17:18:17.975620 (MainThread): Parsing macros/etc/get_custom_alias.sql
2021-06-05 17:18:17.976886 (MainThread): Parsing macros/etc/query.sql
2021-06-05 17:18:17.978368 (MainThread): Parsing macros/etc/is_incremental.sql
2021-06-05 17:18:17.980526 (MainThread): Parsing macros/etc/datetime.sql
2021-06-05 17:18:17.992587 (MainThread): Parsing macros/etc/get_custom_schema.sql
2021-06-05 17:18:17.995184 (MainThread): Parsing macros/etc/get_custom_database.sql
2021-06-05 17:18:17.997400 (MainThread): Parsing macros/adapters/common.sql
2021-06-05 17:18:18.056662 (MainThread): Parsing macros/schema_tests/relationships.sql
2021-06-05 17:18:18.059376 (MainThread): Parsing macros/schema_tests/not_null.sql
2021-06-05 17:18:18.061438 (MainThread): Parsing macros/schema_tests/unique.sql
2021-06-05 17:18:18.063686 (MainThread): Parsing macros/schema_tests/accepted_values.sql
2021-06-05 17:18:18.073851 (MainThread): Partial parsing not enabled
2021-06-05 17:18:18.106711 (MainThread): Acquiring new bigquery connection "model.werkspot_technical_challenge.dim_service".
2021-06-05 17:18:18.126166 (MainThread): Acquiring new bigquery connection "model.werkspot_technical_challenge.dim_professional".
2021-06-05 17:18:18.134065 (MainThread): Acquiring new bigquery connection "model.werkspot_technical_challenge.fct_fee".
2021-06-05 17:18:18.137129 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7feb63a923d0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7feb63aa7b90>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7feb63a9c890>]}
2021-06-05 17:18:18.137426 (MainThread): Flushing usage events
2021-06-05 17:18:18.974252 (MainThread): Connection 'model.werkspot_technical_challenge.fct_fee' was properly closed.
2021-06-05 17:18:18.974516 (MainThread): Encountered an error:
2021-06-05 17:18:18.974723 (MainThread): Compilation Error in model fct_fee (models/Facts/fct_fee.sql)
  expected token ',', got 'partition_by'
    line 5
      partition_by={
2021-06-05 17:18:18.977525 (MainThread): Traceback (most recent call last):
  File "/opt/anaconda3/lib/python3.7/site-packages/dbt/clients/jinja.py", line 501, in catch_jinja
    yield
  File "/opt/anaconda3/lib/python3.7/site-packages/dbt/clients/jinja.py", line 528, in get_template
    return env.from_string(template_source, globals=ctx)
  File "/opt/anaconda3/lib/python3.7/site-packages/jinja2/environment.py", line 941, in from_string
    return cls.from_code(self, self.compile(source), globals, None)
  File "/opt/anaconda3/lib/python3.7/site-packages/jinja2/environment.py", line 638, in compile
    self.handle_exception(source=source_hint)
  File "/opt/anaconda3/lib/python3.7/site-packages/jinja2/environment.py", line 832, in handle_exception
    reraise(*rewrite_traceback_stack(source=source))
  File "/opt/anaconda3/lib/python3.7/site-packages/jinja2/_compat.py", line 28, in reraise
    raise value.with_traceback(tb)
  File "<unknown>", line 5, in template
jinja2.exceptions.TemplateSyntaxError: expected token ',', got 'partition_by'
  line 5
    partition_by={

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/opt/anaconda3/lib/python3.7/site-packages/dbt/main.py", line 125, in main
    results, succeeded = handle_and_check(args)
  File "/opt/anaconda3/lib/python3.7/site-packages/dbt/main.py", line 203, in handle_and_check
    task, res = run_from_args(parsed)
  File "/opt/anaconda3/lib/python3.7/site-packages/dbt/main.py", line 256, in run_from_args
    results = task.run()
  File "/opt/anaconda3/lib/python3.7/site-packages/dbt/task/runnable.py", line 406, in run
    self._runtime_initialize()
  File "/opt/anaconda3/lib/python3.7/site-packages/dbt/task/runnable.py", line 122, in _runtime_initialize
    super()._runtime_initialize()
  File "/opt/anaconda3/lib/python3.7/site-packages/dbt/task/runnable.py", line 79, in _runtime_initialize
    self.load_manifest()
  File "/opt/anaconda3/lib/python3.7/site-packages/dbt/task/runnable.py", line 66, in load_manifest
    self.manifest = get_full_manifest(self.config)
  File "/opt/anaconda3/lib/python3.7/site-packages/dbt/perf_utils.py", line 31, in get_full_manifest
    adapter.connections.set_query_header,
  File "/opt/anaconda3/lib/python3.7/site-packages/dbt/parser/manifest.py", line 862, in load_manifest
    return ManifestLoader.load_all(config, macro_manifest, macro_hook)
  File "/opt/anaconda3/lib/python3.7/site-packages/dbt/parser/manifest.py", line 442, in load_all
    loader.load(macro_manifest=macro_manifest)
  File "/opt/anaconda3/lib/python3.7/site-packages/dbt/parser/manifest.py", line 290, in load
    self.parse_project(project, macro_manifest, old_results)
  File "/opt/anaconda3/lib/python3.7/site-packages/dbt/parser/manifest.py", line 237, in parse_project
    self.parse_with_cache(path, parser, old_results)
  File "/opt/anaconda3/lib/python3.7/site-packages/dbt/parser/manifest.py", line 188, in parse_with_cache
    parser.parse_file(block)
  File "/opt/anaconda3/lib/python3.7/site-packages/dbt/parser/base.py", line 432, in parse_file
    self.parse_node(file_block)
  File "/opt/anaconda3/lib/python3.7/site-packages/dbt/parser/base.py", line 405, in parse_node
    self.render_update(node, config)
  File "/opt/anaconda3/lib/python3.7/site-packages/dbt/parser/base.py", line 380, in render_update
    self.render_with_context(node, config)
  File "/opt/anaconda3/lib/python3.7/site-packages/dbt/parser/base.py", line 294, in render_with_context
    parsed_node.raw_sql, context, parsed_node, capture_macros=True
  File "/opt/anaconda3/lib/python3.7/site-packages/dbt/clients/jinja.py", line 580, in get_rendered
    native=native,
  File "/opt/anaconda3/lib/python3.7/site-packages/dbt/clients/jinja.py", line 528, in get_template
    return env.from_string(template_source, globals=ctx)
  File "/opt/anaconda3/lib/python3.7/contextlib.py", line 130, in __exit__
    self.gen.throw(type, value, traceback)
  File "/opt/anaconda3/lib/python3.7/site-packages/dbt/clients/jinja.py", line 504, in catch_jinja
    raise CompilationException(str(e), node) from e
dbt.exceptions.CompilationException: Compilation Error in model fct_fee (models/Facts/fct_fee.sql)
  expected token ',', got 'partition_by'
    line 5
      partition_by={

2021-06-05 17:19:01.456490 (MainThread): Running with dbt=0.19.1
2021-06-05 17:19:02.223786 (MainThread): running dbt with arguments Namespace(cls=<class 'dbt.task.run.RunTask'>, debug=False, defer=None, exclude=None, fail_fast=False, full_refresh=False, log_cache_events=False, log_format='default', models=['dim_professional'], partial_parse=None, profile=None, profiles_dir='/Users/mac/.dbt', project_dir=None, record_timing_info=None, rpc_method='run', selector_name=None, single_threaded=False, state=None, strict=False, target=None, test_new_parser=False, threads=None, use_cache=True, use_colors=None, vars='{}', version_check=True, warn_error=False, which='run', write_json=True)
2021-06-05 17:19:02.225489 (MainThread): Tracking: tracking
2021-06-05 17:19:02.235215 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fb8c50ccdd0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fb8c50db490>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fb8c50db2d0>]}
2021-06-05 17:19:02.248636 (MainThread): Partial parsing not enabled
2021-06-05 17:19:02.250241 (MainThread): Parsing macros/etc.sql
2021-06-05 17:19:02.254230 (MainThread): Parsing macros/catalog.sql
2021-06-05 17:19:02.262817 (MainThread): Parsing macros/adapters.sql
2021-06-05 17:19:02.290967 (MainThread): Parsing macros/materializations/seed.sql
2021-06-05 17:19:02.294714 (MainThread): Parsing macros/materializations/view.sql
2021-06-05 17:19:02.298626 (MainThread): Parsing macros/materializations/table.sql
2021-06-05 17:19:02.311860 (MainThread): Parsing macros/materializations/copy.sql
2021-06-05 17:19:02.317969 (MainThread): Parsing macros/materializations/incremental.sql
2021-06-05 17:19:02.336283 (MainThread): Parsing macros/materializations/snapshot.sql
2021-06-05 17:19:02.341759 (MainThread): Parsing macros/core.sql
2021-06-05 17:19:02.347639 (MainThread): Parsing macros/materializations/helpers.sql
2021-06-05 17:19:02.359493 (MainThread): Parsing macros/materializations/snapshot/snapshot_merge.sql
2021-06-05 17:19:02.362052 (MainThread): Parsing macros/materializations/snapshot/strategies.sql
2021-06-05 17:19:02.386787 (MainThread): Parsing macros/materializations/snapshot/snapshot.sql
2021-06-05 17:19:02.431851 (MainThread): Parsing macros/materializations/seed/seed.sql
2021-06-05 17:19:02.460342 (MainThread): Parsing macros/materializations/incremental/helpers.sql
2021-06-05 17:19:02.462788 (MainThread): Parsing macros/materializations/incremental/incremental.sql
2021-06-05 17:19:02.471084 (MainThread): Parsing macros/materializations/common/merge.sql
2021-06-05 17:19:02.490141 (MainThread): Parsing macros/materializations/table/table.sql
2021-06-05 17:19:02.499846 (MainThread): Parsing macros/materializations/view/view.sql
2021-06-05 17:19:02.508784 (MainThread): Parsing macros/materializations/view/create_or_replace_view.sql
2021-06-05 17:19:02.515516 (MainThread): Parsing macros/etc/get_custom_alias.sql
2021-06-05 17:19:02.516823 (MainThread): Parsing macros/etc/query.sql
2021-06-05 17:19:02.518567 (MainThread): Parsing macros/etc/is_incremental.sql
2021-06-05 17:19:02.520841 (MainThread): Parsing macros/etc/datetime.sql
2021-06-05 17:19:02.533217 (MainThread): Parsing macros/etc/get_custom_schema.sql
2021-06-05 17:19:02.535926 (MainThread): Parsing macros/etc/get_custom_database.sql
2021-06-05 17:19:02.538610 (MainThread): Parsing macros/adapters/common.sql
2021-06-05 17:19:02.602104 (MainThread): Parsing macros/schema_tests/relationships.sql
2021-06-05 17:19:02.607284 (MainThread): Parsing macros/schema_tests/not_null.sql
2021-06-05 17:19:02.609982 (MainThread): Parsing macros/schema_tests/unique.sql
2021-06-05 17:19:02.613157 (MainThread): Parsing macros/schema_tests/accepted_values.sql
2021-06-05 17:19:02.623650 (MainThread): Partial parsing not enabled
2021-06-05 17:19:02.658283 (MainThread): Acquiring new bigquery connection "model.werkspot_technical_challenge.dim_service".
2021-06-05 17:19:02.680176 (MainThread): Acquiring new bigquery connection "model.werkspot_technical_challenge.dim_professional".
2021-06-05 17:19:02.688606 (MainThread): Acquiring new bigquery connection "model.werkspot_technical_challenge.fct_fee".
2021-06-05 17:19:02.761171 (MainThread): [WARNING]: Configuration paths exist in your dbt_project.yml file which do not apply to any resources.
There are 1 unused configuration paths:
- models.werkspot_technical_challenge.example

2021-06-05 17:19:02.761899 (MainThread): Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'fa2bfa03-118e-443f-b577-395ff53c7289', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fb8c529ffd0>]}
2021-06-05 17:19:02.778007 (MainThread): Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'fa2bfa03-118e-443f-b577-395ff53c7289', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fb8c50eea10>]}
2021-06-05 17:19:02.778535 (MainThread): Found 3 models, 0 tests, 0 snapshots, 0 analyses, 156 macros, 0 operations, 0 seed files, 0 sources, 0 exposures
2021-06-05 17:19:02.779660 (MainThread): 
2021-06-05 17:19:02.780199 (MainThread): Acquiring new bigquery connection "master".
2021-06-05 17:19:02.781254 (ThreadPoolExecutor-0_0): Acquiring new bigquery connection "list_poetic-genius-315513".
2021-06-05 17:19:02.781564 (ThreadPoolExecutor-0_0): Opening a new connection, currently in state init
2021-06-05 17:19:06.898232 (ThreadPoolExecutor-1_0): Acquiring new bigquery connection "list_poetic-genius-315513_events_information".
2021-06-05 17:19:06.898602 (ThreadPoolExecutor-1_0): Opening a new connection, currently in state closed
2021-06-05 17:19:06.898917 (ThreadPoolExecutor-1_0): Client.dataset is deprecated and will be removed in a future version. Use a string like 'my_project.my_dataset' or a cloud.google.bigquery.DatasetReference object, instead.
2021-06-05 17:19:08.123391 (MainThread): 22:19:08 | Concurrency: 1 threads (target='dev')
2021-06-05 17:19:08.123770 (MainThread): 22:19:08 | 
2021-06-05 17:19:08.126585 (Thread-1): Began running node model.werkspot_technical_challenge.dim_professional
2021-06-05 17:19:08.127014 (Thread-1): 22:19:08 | 1 of 1 START incremental model events_information.dim_professional... [RUN]
2021-06-05 17:19:08.127492 (Thread-1): Acquiring new bigquery connection "model.werkspot_technical_challenge.dim_professional".
2021-06-05 17:19:08.127776 (Thread-1): Compiling model.werkspot_technical_challenge.dim_professional
2021-06-05 17:19:08.128559 (Thread-1): unclosed <socket.socket fd=13, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('192.168.0.104', 55950), raddr=('142.250.185.42', 443)>
2021-06-05 17:19:08.134383 (Thread-1): Writing injected SQL for node "model.werkspot_technical_challenge.dim_professional"
2021-06-05 17:19:08.135056 (Thread-1): finished collecting timing info
2021-06-05 17:19:08.136578 (Thread-1): unclosed <socket.socket fd=12, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('192.168.0.104', 55949), raddr=('142.250.185.42', 443)>
2021-06-05 17:19:08.136864 (Thread-1): unclosed <socket.socket fd=11, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('192.168.0.104', 55948), raddr=('172.217.169.234', 443)>
2021-06-05 17:19:08.209396 (Thread-1): Writing runtime SQL for node "model.werkspot_technical_challenge.dim_professional"
2021-06-05 17:19:08.210049 (Thread-1): Opening a new connection, currently in state closed
2021-06-05 17:19:08.210229 (Thread-1): On model.werkspot_technical_challenge.dim_professional: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "werkspot_technical_challenge", "target_name": "dev", "node_id": "model.werkspot_technical_challenge.dim_professional"} */


  create or replace table `poetic-genius-315513`.`events_information`.`dim_professional`
  partition by datetime_trunc(AuditCreatedDateTime, day)
  
  OPTIONS()
  as (
    


SELECT
  DISTINCT 
    CAST(ParsedEventLog[OFFSET(2)] AS STRING) AS PK_ProfessionalID,
    CURRENT_DATETIME() as AuditCreatedDateTime,  -- Audit column
    CURRENT_DATETIME() as AuditModifiedDateTime  -- Audit column
FROM 
(

  SELECT 
    SPLIT(EventLogEntry,';') as ParsedEventLog
  FROM 
   `poetic-genius-315513.events_information_staging.events_log_data_stg`
      
      -- this will only be applied on an incremental run & will filter data early
      -- `poetic-genius-315513`.`events_information`.`dim_professional` will give last run date which can then be used to pick CDC records daily
      

)
  );
  
2021-06-05 17:19:12.161950 (Thread-1): finished collecting timing info
2021-06-05 17:19:12.162543 (Thread-1): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'fa2bfa03-118e-443f-b577-395ff53c7289', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fb8c570b510>]}
2021-06-05 17:19:12.163047 (Thread-1): 22:19:12 | 1 of 1 OK created incremental model events_information.dim_professional [CREATE TABLE (1.5k rows, 1.6 MB processed) in 4.04s]
2021-06-05 17:19:12.163247 (Thread-1): Finished running node model.werkspot_technical_challenge.dim_professional
2021-06-05 17:19:12.231003 (MainThread): Acquiring new bigquery connection "master".
2021-06-05 17:19:12.231446 (MainThread): 22:19:12 | 
2021-06-05 17:19:12.231618 (MainThread): 22:19:12 | Finished running 1 incremental model in 9.45s.
2021-06-05 17:19:12.231776 (MainThread): Connection 'master' was properly closed.
2021-06-05 17:19:12.231901 (MainThread): Connection 'model.werkspot_technical_challenge.dim_professional' was properly closed.
2021-06-05 17:19:12.248868 (MainThread): 
2021-06-05 17:19:12.249127 (MainThread): Completed successfully
2021-06-05 17:19:12.249391 (MainThread): 
Done. PASS=1 WARN=0 ERROR=0 SKIP=0 TOTAL=1
2021-06-05 17:19:12.249755 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fb8c529bb10>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fb8c54f7f10>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fb8c52975d0>]}
2021-06-05 17:19:12.250043 (MainThread): Flushing usage events
2021-06-05 17:20:34.172689 (MainThread): Running with dbt=0.19.1
2021-06-05 17:20:35.146126 (MainThread): running dbt with arguments Namespace(cls=<class 'dbt.task.run.RunTask'>, debug=False, defer=None, exclude=None, fail_fast=False, full_refresh=False, log_cache_events=False, log_format='default', models=['dim_service'], partial_parse=None, profile=None, profiles_dir='/Users/mac/.dbt', project_dir=None, record_timing_info=None, rpc_method='run', selector_name=None, single_threaded=False, state=None, strict=False, target=None, test_new_parser=False, threads=None, use_cache=True, use_colors=None, vars='{}', version_check=True, warn_error=False, which='run', write_json=True)
2021-06-05 17:20:35.147426 (MainThread): Tracking: tracking
2021-06-05 17:20:35.160849 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fc7c690a910>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fc7c1e62710>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fc7c68d8910>]}
2021-06-05 17:20:35.177389 (MainThread): Partial parsing not enabled
2021-06-05 17:20:35.179435 (MainThread): Parsing macros/etc.sql
2021-06-05 17:20:35.184328 (MainThread): Parsing macros/catalog.sql
2021-06-05 17:20:35.194923 (MainThread): Parsing macros/adapters.sql
2021-06-05 17:20:35.225854 (MainThread): Parsing macros/materializations/seed.sql
2021-06-05 17:20:35.230644 (MainThread): Parsing macros/materializations/view.sql
2021-06-05 17:20:35.234676 (MainThread): Parsing macros/materializations/table.sql
2021-06-05 17:20:35.249438 (MainThread): Parsing macros/materializations/copy.sql
2021-06-05 17:20:35.255711 (MainThread): Parsing macros/materializations/incremental.sql
2021-06-05 17:20:35.275011 (MainThread): Parsing macros/materializations/snapshot.sql
2021-06-05 17:20:35.279193 (MainThread): Parsing macros/core.sql
2021-06-05 17:20:35.284919 (MainThread): Parsing macros/materializations/helpers.sql
2021-06-05 17:20:35.298251 (MainThread): Parsing macros/materializations/snapshot/snapshot_merge.sql
2021-06-05 17:20:35.301549 (MainThread): Parsing macros/materializations/snapshot/strategies.sql
2021-06-05 17:20:35.326359 (MainThread): Parsing macros/materializations/snapshot/snapshot.sql
2021-06-05 17:20:35.371171 (MainThread): Parsing macros/materializations/seed/seed.sql
2021-06-05 17:20:35.400306 (MainThread): Parsing macros/materializations/incremental/helpers.sql
2021-06-05 17:20:35.403023 (MainThread): Parsing macros/materializations/incremental/incremental.sql
2021-06-05 17:20:35.411414 (MainThread): Parsing macros/materializations/common/merge.sql
2021-06-05 17:20:35.430576 (MainThread): Parsing macros/materializations/table/table.sql
2021-06-05 17:20:35.440799 (MainThread): Parsing macros/materializations/view/view.sql
2021-06-05 17:20:35.449901 (MainThread): Parsing macros/materializations/view/create_or_replace_view.sql
2021-06-05 17:20:35.461301 (MainThread): Parsing macros/etc/get_custom_alias.sql
2021-06-05 17:20:35.463228 (MainThread): Parsing macros/etc/query.sql
2021-06-05 17:20:35.464977 (MainThread): Parsing macros/etc/is_incremental.sql
2021-06-05 17:20:35.467711 (MainThread): Parsing macros/etc/datetime.sql
2021-06-05 17:20:35.479763 (MainThread): Parsing macros/etc/get_custom_schema.sql
2021-06-05 17:20:35.482469 (MainThread): Parsing macros/etc/get_custom_database.sql
2021-06-05 17:20:35.484801 (MainThread): Parsing macros/adapters/common.sql
2021-06-05 17:20:35.543888 (MainThread): Parsing macros/schema_tests/relationships.sql
2021-06-05 17:20:35.546863 (MainThread): Parsing macros/schema_tests/not_null.sql
2021-06-05 17:20:35.549228 (MainThread): Parsing macros/schema_tests/unique.sql
2021-06-05 17:20:35.551594 (MainThread): Parsing macros/schema_tests/accepted_values.sql
2021-06-05 17:20:35.562198 (MainThread): Partial parsing not enabled
2021-06-05 17:20:35.603822 (MainThread): Acquiring new bigquery connection "model.werkspot_technical_challenge.dim_service".
2021-06-05 17:20:35.624117 (MainThread): Acquiring new bigquery connection "model.werkspot_technical_challenge.dim_professional".
2021-06-05 17:20:35.631233 (MainThread): Acquiring new bigquery connection "model.werkspot_technical_challenge.fct_fee".
2021-06-05 17:20:35.697974 (MainThread): [WARNING]: Configuration paths exist in your dbt_project.yml file which do not apply to any resources.
There are 1 unused configuration paths:
- models.werkspot_technical_challenge.example

2021-06-05 17:20:35.698660 (MainThread): Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'f852548c-e6ab-410b-a5dc-75b380f3f47d', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fc7c6ae2190>]}
2021-06-05 17:20:35.714361 (MainThread): Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'f852548c-e6ab-410b-a5dc-75b380f3f47d', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fc7c6acc190>]}
2021-06-05 17:20:35.714885 (MainThread): Found 3 models, 0 tests, 0 snapshots, 0 analyses, 156 macros, 0 operations, 0 seed files, 0 sources, 0 exposures
2021-06-05 17:20:35.716151 (MainThread): 
2021-06-05 17:20:35.716672 (MainThread): Acquiring new bigquery connection "master".
2021-06-05 17:20:35.717743 (ThreadPoolExecutor-0_0): Acquiring new bigquery connection "list_poetic-genius-315513".
2021-06-05 17:20:35.718068 (ThreadPoolExecutor-0_0): Opening a new connection, currently in state init
2021-06-05 17:20:38.332177 (ThreadPoolExecutor-1_0): Acquiring new bigquery connection "list_poetic-genius-315513_events_information".
2021-06-05 17:20:38.332549 (ThreadPoolExecutor-1_0): Opening a new connection, currently in state closed
2021-06-05 17:20:38.332868 (ThreadPoolExecutor-1_0): Client.dataset is deprecated and will be removed in a future version. Use a string like 'my_project.my_dataset' or a cloud.google.bigquery.DatasetReference object, instead.
2021-06-05 17:20:39.566160 (MainThread): 22:20:39 | Concurrency: 1 threads (target='dev')
2021-06-05 17:20:39.566533 (MainThread): 22:20:39 | 
2021-06-05 17:20:39.568965 (Thread-1): Began running node model.werkspot_technical_challenge.dim_service
2021-06-05 17:20:39.569385 (Thread-1): 22:20:39 | 1 of 1 START incremental model events_information.dim_service........ [RUN]
2021-06-05 17:20:39.569872 (Thread-1): Acquiring new bigquery connection "model.werkspot_technical_challenge.dim_service".
2021-06-05 17:20:39.570085 (Thread-1): Compiling model.werkspot_technical_challenge.dim_service
2021-06-05 17:20:39.570855 (Thread-1): unclosed <socket.socket fd=13, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('192.168.0.104', 56017), raddr=('142.250.185.42', 443)>
2021-06-05 17:20:39.576580 (Thread-1): Writing injected SQL for node "model.werkspot_technical_challenge.dim_service"
2021-06-05 17:20:39.577216 (Thread-1): finished collecting timing info
2021-06-05 17:20:39.578688 (Thread-1): unclosed <socket.socket fd=12, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('192.168.0.104', 56016), raddr=('142.250.185.42', 443)>
2021-06-05 17:20:39.578935 (Thread-1): unclosed <socket.socket fd=11, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('192.168.0.104', 56015), raddr=('172.217.169.234', 443)>
2021-06-05 17:20:39.656497 (Thread-1): Writing runtime SQL for node "model.werkspot_technical_challenge.dim_service"
2021-06-05 17:20:39.657078 (Thread-1): Opening a new connection, currently in state closed
2021-06-05 17:20:39.657256 (Thread-1): On model.werkspot_technical_challenge.dim_service: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "werkspot_technical_challenge", "target_name": "dev", "node_id": "model.werkspot_technical_challenge.dim_service"} */


  create or replace table `poetic-genius-315513`.`events_information`.`dim_service`
  partition by datetime_trunc(AuditCreatedDateTime, day)
  
  OPTIONS()
  as (
    

SELECT  -- ADDING one extra select so that results could be sorted based on PK_ServiceID
  *
FROM 
(
  SELECT
    DISTINCT 
      CAST(ParsedMetdata[OFFSET(0)] AS STRING) AS PK_ServiceID,
      ParsedMetdata[OFFSET(1)] AS ServiceNameDutch,
      ParsedMetdata[OFFSET(2)] AS ServiceNameEnglish,

      CURRENT_DATETIME() as AuditCreatedDateTime, -- Audit column
      CURRENT_DATETIME() as AuditModifiedDateTime  -- Audit column
  FROM 
  (
    SELECT 
      -- Splitting metadata field further on underscore to get information about service and fees
      SPLIT(ParsedEventLog,'_') AS ParsedMetdata
    FROM 
    (
      SELECT 
        -- since we know that the position of metadata field is 4th (assuming 0 based index)
        SPLIT(EventLogEntry,';')[OFFSET(4)] as ParsedEventLog
      FROM 
       `poetic-genius-315513.events_information_staging.events_log_data_stg`

        -- this will only be applied on an incremental run & will filter data early
        -- `poetic-genius-315513`.`events_information`.`dim_service` will give last run date which can then be used to pick CDC records daily
        
    )
    -- Discarding those rows where metadata is empty to reduce processing
    WHERE ParsedEventLog!=''
  )
)
  );
  
2021-06-05 17:20:43.174578 (Thread-1): finished collecting timing info
2021-06-05 17:20:43.175142 (Thread-1): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'f852548c-e6ab-410b-a5dc-75b380f3f47d', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fc7c6aded10>]}
2021-06-05 17:20:43.175597 (Thread-1): 22:20:43 | 1 of 1 OK created incremental model events_information.dim_service... [CREATE TABLE (171.0 rows, 1.6 MB processed) in 3.61s]
2021-06-05 17:20:43.175833 (Thread-1): Finished running node model.werkspot_technical_challenge.dim_service
2021-06-05 17:20:43.176869 (MainThread): Acquiring new bigquery connection "master".
2021-06-05 17:20:43.177270 (MainThread): 22:20:43 | 
2021-06-05 17:20:43.177444 (MainThread): 22:20:43 | Finished running 1 incremental model in 7.46s.
2021-06-05 17:20:43.177616 (MainThread): Connection 'master' was properly closed.
2021-06-05 17:20:43.177751 (MainThread): Connection 'model.werkspot_technical_challenge.dim_service' was properly closed.
2021-06-05 17:20:43.187901 (MainThread): 
2021-06-05 17:20:43.188170 (MainThread): Completed successfully
2021-06-05 17:20:43.188470 (MainThread): 
Done. PASS=1 WARN=0 ERROR=0 SKIP=0 TOTAL=1
2021-06-05 17:20:43.188841 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fc7c6cebcd0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fc7c6c180d0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fc7c6aaf590>]}
2021-06-05 17:20:43.189122 (MainThread): Flushing usage events
2021-06-05 17:21:51.892126 (MainThread): Running with dbt=0.19.1
2021-06-05 17:21:53.031447 (MainThread): running dbt with arguments Namespace(cls=<class 'dbt.task.run.RunTask'>, debug=False, defer=None, exclude=None, fail_fast=False, full_refresh=False, log_cache_events=False, log_format='default', models=['fct_fee'], partial_parse=None, profile=None, profiles_dir='/Users/mac/.dbt', project_dir=None, record_timing_info=None, rpc_method='run', selector_name=None, single_threaded=False, state=None, strict=False, target=None, test_new_parser=False, threads=None, use_cache=True, use_colors=None, vars='{}', version_check=True, warn_error=False, which='run', write_json=True)
2021-06-05 17:21:53.032965 (MainThread): Tracking: tracking
2021-06-05 17:21:53.046318 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ff1e2ffe310>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ff1e2ffe590>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ff1e2ffe1d0>]}
2021-06-05 17:21:53.071446 (MainThread): Partial parsing not enabled
2021-06-05 17:21:53.073770 (MainThread): Parsing macros/etc.sql
2021-06-05 17:21:53.081092 (MainThread): Parsing macros/catalog.sql
2021-06-05 17:21:53.096891 (MainThread): Parsing macros/adapters.sql
2021-06-05 17:21:53.133624 (MainThread): Parsing macros/materializations/seed.sql
2021-06-05 17:21:53.141714 (MainThread): Parsing macros/materializations/view.sql
2021-06-05 17:21:53.149741 (MainThread): Parsing macros/materializations/table.sql
2021-06-05 17:21:53.164414 (MainThread): Parsing macros/materializations/copy.sql
2021-06-05 17:21:53.171370 (MainThread): Parsing macros/materializations/incremental.sql
2021-06-05 17:21:53.188381 (MainThread): Parsing macros/materializations/snapshot.sql
2021-06-05 17:21:53.192818 (MainThread): Parsing macros/core.sql
2021-06-05 17:21:53.198498 (MainThread): Parsing macros/materializations/helpers.sql
2021-06-05 17:21:53.211110 (MainThread): Parsing macros/materializations/snapshot/snapshot_merge.sql
2021-06-05 17:21:53.214166 (MainThread): Parsing macros/materializations/snapshot/strategies.sql
2021-06-05 17:21:53.238797 (MainThread): Parsing macros/materializations/snapshot/snapshot.sql
2021-06-05 17:21:53.284592 (MainThread): Parsing macros/materializations/seed/seed.sql
2021-06-05 17:21:53.312863 (MainThread): Parsing macros/materializations/incremental/helpers.sql
2021-06-05 17:21:53.315574 (MainThread): Parsing macros/materializations/incremental/incremental.sql
2021-06-05 17:21:53.323837 (MainThread): Parsing macros/materializations/common/merge.sql
2021-06-05 17:21:53.344223 (MainThread): Parsing macros/materializations/table/table.sql
2021-06-05 17:21:53.356131 (MainThread): Parsing macros/materializations/view/view.sql
2021-06-05 17:21:53.364865 (MainThread): Parsing macros/materializations/view/create_or_replace_view.sql
2021-06-05 17:21:53.371494 (MainThread): Parsing macros/etc/get_custom_alias.sql
2021-06-05 17:21:53.373099 (MainThread): Parsing macros/etc/query.sql
2021-06-05 17:21:53.374675 (MainThread): Parsing macros/etc/is_incremental.sql
2021-06-05 17:21:53.376951 (MainThread): Parsing macros/etc/datetime.sql
2021-06-05 17:21:53.389348 (MainThread): Parsing macros/etc/get_custom_schema.sql
2021-06-05 17:21:53.392353 (MainThread): Parsing macros/etc/get_custom_database.sql
2021-06-05 17:21:53.394718 (MainThread): Parsing macros/adapters/common.sql
2021-06-05 17:21:53.454205 (MainThread): Parsing macros/schema_tests/relationships.sql
2021-06-05 17:21:53.458553 (MainThread): Parsing macros/schema_tests/not_null.sql
2021-06-05 17:21:53.461055 (MainThread): Parsing macros/schema_tests/unique.sql
2021-06-05 17:21:53.463835 (MainThread): Parsing macros/schema_tests/accepted_values.sql
2021-06-05 17:21:53.474783 (MainThread): Partial parsing not enabled
2021-06-05 17:21:53.510181 (MainThread): Acquiring new bigquery connection "model.werkspot_technical_challenge.dim_service".
2021-06-05 17:21:53.530495 (MainThread): Acquiring new bigquery connection "model.werkspot_technical_challenge.dim_professional".
2021-06-05 17:21:53.537745 (MainThread): Acquiring new bigquery connection "model.werkspot_technical_challenge.fct_fee".
2021-06-05 17:21:53.607321 (MainThread): [WARNING]: Configuration paths exist in your dbt_project.yml file which do not apply to any resources.
There are 1 unused configuration paths:
- models.werkspot_technical_challenge.example

2021-06-05 17:21:53.608111 (MainThread): Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '865278fd-1cd5-49b9-b31e-a7a8a1f07bb4', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ff1e31a2090>]}
2021-06-05 17:21:53.629588 (MainThread): Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '865278fd-1cd5-49b9-b31e-a7a8a1f07bb4', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ff1e317fbd0>]}
2021-06-05 17:21:53.629979 (MainThread): Found 3 models, 0 tests, 0 snapshots, 0 analyses, 156 macros, 0 operations, 0 seed files, 0 sources, 0 exposures
2021-06-05 17:21:53.630910 (MainThread): 
2021-06-05 17:21:53.631400 (MainThread): Acquiring new bigquery connection "master".
2021-06-05 17:21:53.632401 (ThreadPoolExecutor-0_0): Acquiring new bigquery connection "list_poetic-genius-315513".
2021-06-05 17:21:53.632739 (ThreadPoolExecutor-0_0): Opening a new connection, currently in state init
2021-06-05 17:22:09.322127 (MainThread): Running with dbt=0.19.1
2021-06-05 17:22:10.264819 (MainThread): running dbt with arguments Namespace(cls=<class 'dbt.task.run.RunTask'>, debug=False, defer=None, exclude=None, fail_fast=False, full_refresh=False, log_cache_events=False, log_format='default', models=['fct_fee'], partial_parse=None, profile=None, profiles_dir='/Users/mac/.dbt', project_dir=None, record_timing_info=None, rpc_method='run', selector_name=None, single_threaded=False, state=None, strict=False, target=None, test_new_parser=False, threads=None, use_cache=True, use_colors=None, vars='{}', version_check=True, warn_error=False, which='run', write_json=True)
2021-06-05 17:22:10.266414 (MainThread): Tracking: tracking
2021-06-05 17:22:10.278602 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fc65980ee90>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fc6597dca10>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fc6597dc9d0>]}
2021-06-05 17:22:10.293525 (MainThread): Partial parsing not enabled
2021-06-05 17:22:10.295127 (MainThread): Parsing macros/etc.sql
2021-06-05 17:22:10.299722 (MainThread): Parsing macros/catalog.sql
2021-06-05 17:22:10.309193 (MainThread): Parsing macros/adapters.sql
2021-06-05 17:22:10.338137 (MainThread): Parsing macros/materializations/seed.sql
2021-06-05 17:22:10.342060 (MainThread): Parsing macros/materializations/view.sql
2021-06-05 17:22:10.346022 (MainThread): Parsing macros/materializations/table.sql
2021-06-05 17:22:10.360167 (MainThread): Parsing macros/materializations/copy.sql
2021-06-05 17:22:10.369306 (MainThread): Parsing macros/materializations/incremental.sql
2021-06-05 17:22:10.389996 (MainThread): Parsing macros/materializations/snapshot.sql
2021-06-05 17:22:10.394629 (MainThread): Parsing macros/core.sql
2021-06-05 17:22:10.400208 (MainThread): Parsing macros/materializations/helpers.sql
2021-06-05 17:22:10.413106 (MainThread): Parsing macros/materializations/snapshot/snapshot_merge.sql
2021-06-05 17:22:10.416180 (MainThread): Parsing macros/materializations/snapshot/strategies.sql
2021-06-05 17:22:10.440904 (MainThread): Parsing macros/materializations/snapshot/snapshot.sql
2021-06-05 17:22:10.485904 (MainThread): Parsing macros/materializations/seed/seed.sql
2021-06-05 17:22:10.516187 (MainThread): Parsing macros/materializations/incremental/helpers.sql
2021-06-05 17:22:10.520619 (MainThread): Parsing macros/materializations/incremental/incremental.sql
2021-06-05 17:22:10.531068 (MainThread): Parsing macros/materializations/common/merge.sql
2021-06-05 17:22:10.550428 (MainThread): Parsing macros/materializations/table/table.sql
2021-06-05 17:22:10.560075 (MainThread): Parsing macros/materializations/view/view.sql
2021-06-05 17:22:10.568686 (MainThread): Parsing macros/materializations/view/create_or_replace_view.sql
2021-06-05 17:22:10.575695 (MainThread): Parsing macros/etc/get_custom_alias.sql
2021-06-05 17:22:10.577226 (MainThread): Parsing macros/etc/query.sql
2021-06-05 17:22:10.579002 (MainThread): Parsing macros/etc/is_incremental.sql
2021-06-05 17:22:10.581440 (MainThread): Parsing macros/etc/datetime.sql
2021-06-05 17:22:10.593694 (MainThread): Parsing macros/etc/get_custom_schema.sql
2021-06-05 17:22:10.596924 (MainThread): Parsing macros/etc/get_custom_database.sql
2021-06-05 17:22:10.599939 (MainThread): Parsing macros/adapters/common.sql
2021-06-05 17:22:10.659264 (MainThread): Parsing macros/schema_tests/relationships.sql
2021-06-05 17:22:10.662153 (MainThread): Parsing macros/schema_tests/not_null.sql
2021-06-05 17:22:10.664669 (MainThread): Parsing macros/schema_tests/unique.sql
2021-06-05 17:22:10.667451 (MainThread): Parsing macros/schema_tests/accepted_values.sql
2021-06-05 17:22:10.678175 (MainThread): Partial parsing not enabled
2021-06-05 17:22:10.712382 (MainThread): Acquiring new bigquery connection "model.werkspot_technical_challenge.dim_service".
2021-06-05 17:22:10.737068 (MainThread): Acquiring new bigquery connection "model.werkspot_technical_challenge.dim_professional".
2021-06-05 17:22:10.744703 (MainThread): Acquiring new bigquery connection "model.werkspot_technical_challenge.fct_fee".
2021-06-05 17:22:10.813814 (MainThread): [WARNING]: Configuration paths exist in your dbt_project.yml file which do not apply to any resources.
There are 1 unused configuration paths:
- models.werkspot_technical_challenge.example

2021-06-05 17:22:10.815205 (MainThread): Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '01335f18-a429-4eb7-a259-2b1935a7a028', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fc6598a9250>]}
2021-06-05 17:22:10.830811 (MainThread): Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '01335f18-a429-4eb7-a259-2b1935a7a028', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fc6599d6890>]}
2021-06-05 17:22:10.831221 (MainThread): Found 3 models, 0 tests, 0 snapshots, 0 analyses, 156 macros, 0 operations, 0 seed files, 0 sources, 0 exposures
2021-06-05 17:22:10.832115 (MainThread): 
2021-06-05 17:22:10.832646 (MainThread): Acquiring new bigquery connection "master".
2021-06-05 17:22:10.833691 (ThreadPoolExecutor-0_0): Acquiring new bigquery connection "list_poetic-genius-315513".
2021-06-05 17:22:10.833997 (ThreadPoolExecutor-0_0): Opening a new connection, currently in state init
2021-06-05 17:22:13.364810 (ThreadPoolExecutor-1_0): Acquiring new bigquery connection "list_poetic-genius-315513_events_information".
2021-06-05 17:22:13.365170 (ThreadPoolExecutor-1_0): Opening a new connection, currently in state closed
2021-06-05 17:22:13.365619 (ThreadPoolExecutor-1_0): Client.dataset is deprecated and will be removed in a future version. Use a string like 'my_project.my_dataset' or a cloud.google.bigquery.DatasetReference object, instead.
2021-06-05 17:22:14.502430 (MainThread): 22:22:14 | Concurrency: 1 threads (target='dev')
2021-06-05 17:22:14.502715 (MainThread): 22:22:14 | 
2021-06-05 17:22:14.505220 (Thread-1): Began running node model.werkspot_technical_challenge.fct_fee
2021-06-05 17:22:14.505630 (Thread-1): 22:22:14 | 1 of 1 START incremental model events_information.fct_fee............ [RUN]
2021-06-05 17:22:14.506114 (Thread-1): Acquiring new bigquery connection "model.werkspot_technical_challenge.fct_fee".
2021-06-05 17:22:14.506323 (Thread-1): Compiling model.werkspot_technical_challenge.fct_fee
2021-06-05 17:22:14.507089 (Thread-1): unclosed <socket.socket fd=13, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('192.168.0.104', 56055), raddr=('142.250.185.42', 443)>
2021-06-05 17:22:14.512661 (Thread-1): Writing injected SQL for node "model.werkspot_technical_challenge.fct_fee"
2021-06-05 17:22:14.513304 (Thread-1): finished collecting timing info
2021-06-05 17:22:14.514696 (Thread-1): unclosed <socket.socket fd=12, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('192.168.0.104', 56054), raddr=('142.250.185.42', 443)>
2021-06-05 17:22:14.514933 (Thread-1): unclosed <socket.socket fd=11, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('192.168.0.104', 56053), raddr=('216.58.209.138', 443)>
2021-06-05 17:22:14.589036 (Thread-1): Writing runtime SQL for node "model.werkspot_technical_challenge.fct_fee"
2021-06-05 17:22:14.589776 (Thread-1): Opening a new connection, currently in state closed
2021-06-05 17:22:14.589993 (Thread-1): On model.werkspot_technical_challenge.fct_fee: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "werkspot_technical_challenge", "target_name": "dev", "node_id": "model.werkspot_technical_challenge.fct_fee"} */


  create or replace table `poetic-genius-315513`.`events_information`.`fct_fee`
  partition by datetime_trunc(AuditCreatedDateTime, day)
  
  OPTIONS()
  as (
    




SELECT 
  
  (CASE 
    WHEN SPLIT(ParsedEventLog[OFFSET(4)],'_')[OFFSET(0)]='' 
      THEN 'Not provided' 
      ELSE  SPLIT(ParsedEventLog[OFFSET(4)],'_')[OFFSET(0)] 
    END) AS FK_ServiceID, -- ServiceID referenced as foreign key
  
  CAST(ParsedEventLog[OFFSET(2)] AS INT64) AS FK_ProfessionalID, -- ProfessionalID referenced as foreign key
  
  ParsedEventLog[OFFSET(0)] AS EventID, -- EventID is always at 1st index (assuming 0 based indexing)
  ParsedEventLog[OFFSET(1)] AS EventName, -- EventName is always at 2nd index (assuming 0 based indexing)
  CAST(ParsedEventLog[OFFSET(3)] AS DATETIME) AS CreatedAt, -- CreatedAt is always at 3rd index (assuming 0 based indexing)
  
  (CASE 
    WHEN ParsedEventLog[OFFSET(4)]!='' 
      THEN CAST(SPLIT(ParsedEventLog[OFFSET(4)],'_')[OFFSET(3)] AS FLOAT64) 
      ELSE 0.0 
   END) as LeadFee,
  
  CURRENT_DATETIME() as AuditCreatedDateTime, -- Audit column
  CURRENT_DATETIME() as AuditModifiedDateTime  -- Audit column
FROM
(
  SELECT 
      SPLIT(EventLogEntry,';') as ParsedEventLog
    FROM 
     `poetic-genius-315513.events_information_staging.events_log_data_stg`

      -- this will only be applied on an incremental run & will filter data early
      -- `poetic-genius-315513`.`events_information`.`fct_fee` will give last run date which can then be used to pick CDC records daily
      
)
  );
  
2021-06-05 17:22:19.381091 (Thread-1): finished collecting timing info
2021-06-05 17:22:19.381684 (Thread-1): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '01335f18-a429-4eb7-a259-2b1935a7a028', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fc659bead90>]}
2021-06-05 17:22:19.382195 (Thread-1): 22:22:19 | 1 of 1 OK created incremental model events_information.fct_fee....... [CREATE TABLE (19.0k rows, 1.6 MB processed) in 4.88s]
2021-06-05 17:22:19.382402 (Thread-1): Finished running node model.werkspot_technical_challenge.fct_fee
2021-06-05 17:22:19.462427 (MainThread): Acquiring new bigquery connection "master".
2021-06-05 17:22:19.463026 (MainThread): 22:22:19 | 
2021-06-05 17:22:19.463281 (MainThread): 22:22:19 | Finished running 1 incremental model in 8.63s.
2021-06-05 17:22:19.463528 (MainThread): Connection 'master' was properly closed.
2021-06-05 17:22:19.463726 (MainThread): Connection 'model.werkspot_technical_challenge.fct_fee' was properly closed.
2021-06-05 17:22:19.474917 (MainThread): 
2021-06-05 17:22:19.475177 (MainThread): Completed successfully
2021-06-05 17:22:19.475479 (MainThread): 
Done. PASS=1 WARN=0 ERROR=0 SKIP=0 TOTAL=1
2021-06-05 17:22:19.475840 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fc6599dafd0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fc659bee910>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fc659beac50>]}
2021-06-05 17:22:19.476118 (MainThread): Flushing usage events
2021-06-05 17:23:42.204501 (MainThread): Running with dbt=0.19.1
2021-06-05 17:23:42.943000 (MainThread): running dbt with arguments Namespace(cls=<class 'dbt.task.run.RunTask'>, debug=False, defer=None, exclude=None, fail_fast=False, full_refresh=False, log_cache_events=False, log_format='default', models=['fct_fee'], partial_parse=None, profile=None, profiles_dir='/Users/mac/.dbt', project_dir=None, record_timing_info=None, rpc_method='run', selector_name=None, single_threaded=False, state=None, strict=False, target=None, test_new_parser=False, threads=None, use_cache=True, use_colors=None, vars='{}', version_check=True, warn_error=False, which='run', write_json=True)
2021-06-05 17:23:42.945569 (MainThread): Tracking: tracking
2021-06-05 17:23:42.958256 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f9a6211b390>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f9a6211b5d0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f9a6211b210>]}
2021-06-05 17:23:42.982453 (MainThread): Partial parsing not enabled
2021-06-05 17:23:42.983956 (MainThread): Parsing macros/etc.sql
2021-06-05 17:23:42.989650 (MainThread): Parsing macros/catalog.sql
2021-06-05 17:23:43.001754 (MainThread): Parsing macros/adapters.sql
2021-06-05 17:23:43.035534 (MainThread): Parsing macros/materializations/seed.sql
2021-06-05 17:23:43.039412 (MainThread): Parsing macros/materializations/view.sql
2021-06-05 17:23:43.044241 (MainThread): Parsing macros/materializations/table.sql
2021-06-05 17:23:43.062103 (MainThread): Parsing macros/materializations/copy.sql
2021-06-05 17:23:43.071325 (MainThread): Parsing macros/materializations/incremental.sql
2021-06-05 17:23:43.091493 (MainThread): Parsing macros/materializations/snapshot.sql
2021-06-05 17:23:43.095599 (MainThread): Parsing macros/core.sql
2021-06-05 17:23:43.102203 (MainThread): Parsing macros/materializations/helpers.sql
2021-06-05 17:23:43.116177 (MainThread): Parsing macros/materializations/snapshot/snapshot_merge.sql
2021-06-05 17:23:43.118708 (MainThread): Parsing macros/materializations/snapshot/strategies.sql
2021-06-05 17:23:43.151904 (MainThread): Parsing macros/materializations/snapshot/snapshot.sql
2021-06-05 17:23:43.197299 (MainThread): Parsing macros/materializations/seed/seed.sql
2021-06-05 17:23:43.225138 (MainThread): Parsing macros/materializations/incremental/helpers.sql
2021-06-05 17:23:43.227646 (MainThread): Parsing macros/materializations/incremental/incremental.sql
2021-06-05 17:23:43.235966 (MainThread): Parsing macros/materializations/common/merge.sql
2021-06-05 17:23:43.254674 (MainThread): Parsing macros/materializations/table/table.sql
2021-06-05 17:23:43.263721 (MainThread): Parsing macros/materializations/view/view.sql
2021-06-05 17:23:43.272065 (MainThread): Parsing macros/materializations/view/create_or_replace_view.sql
2021-06-05 17:23:43.278731 (MainThread): Parsing macros/etc/get_custom_alias.sql
2021-06-05 17:23:43.280119 (MainThread): Parsing macros/etc/query.sql
2021-06-05 17:23:43.281520 (MainThread): Parsing macros/etc/is_incremental.sql
2021-06-05 17:23:43.283681 (MainThread): Parsing macros/etc/datetime.sql
2021-06-05 17:23:43.295975 (MainThread): Parsing macros/etc/get_custom_schema.sql
2021-06-05 17:23:43.298691 (MainThread): Parsing macros/etc/get_custom_database.sql
2021-06-05 17:23:43.301040 (MainThread): Parsing macros/adapters/common.sql
2021-06-05 17:23:43.365688 (MainThread): Parsing macros/schema_tests/relationships.sql
2021-06-05 17:23:43.368301 (MainThread): Parsing macros/schema_tests/not_null.sql
2021-06-05 17:23:43.370434 (MainThread): Parsing macros/schema_tests/unique.sql
2021-06-05 17:23:43.374429 (MainThread): Parsing macros/schema_tests/accepted_values.sql
2021-06-05 17:23:43.385746 (MainThread): Partial parsing not enabled
2021-06-05 17:23:43.424382 (MainThread): Acquiring new bigquery connection "model.werkspot_technical_challenge.dim_service".
2021-06-05 17:23:43.447884 (MainThread): Acquiring new bigquery connection "model.werkspot_technical_challenge.dim_professional".
2021-06-05 17:23:43.456789 (MainThread): Acquiring new bigquery connection "model.werkspot_technical_challenge.fct_fee".
2021-06-05 17:23:43.531261 (MainThread): [WARNING]: Configuration paths exist in your dbt_project.yml file which do not apply to any resources.
There are 1 unused configuration paths:
- models.werkspot_technical_challenge.example

2021-06-05 17:23:43.532077 (MainThread): Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'd028fab7-a03c-481d-8051-a6c655d2ff9b', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f9a622e1110>]}
2021-06-05 17:23:43.552852 (MainThread): Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'd028fab7-a03c-481d-8051-a6c655d2ff9b', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f9a622c3950>]}
2021-06-05 17:23:43.553377 (MainThread): Found 3 models, 0 tests, 0 snapshots, 0 analyses, 156 macros, 0 operations, 0 seed files, 0 sources, 0 exposures
2021-06-05 17:23:43.554585 (MainThread): 
2021-06-05 17:23:43.555223 (MainThread): Acquiring new bigquery connection "master".
2021-06-05 17:23:43.556691 (ThreadPoolExecutor-0_0): Acquiring new bigquery connection "list_poetic-genius-315513".
2021-06-05 17:23:43.557132 (ThreadPoolExecutor-0_0): Opening a new connection, currently in state init
2021-06-05 17:23:46.248048 (ThreadPoolExecutor-1_0): Acquiring new bigquery connection "list_poetic-genius-315513_events_information".
2021-06-05 17:23:46.250330 (ThreadPoolExecutor-1_0): Opening a new connection, currently in state closed
2021-06-05 17:23:46.251133 (ThreadPoolExecutor-1_0): Client.dataset is deprecated and will be removed in a future version. Use a string like 'my_project.my_dataset' or a cloud.google.bigquery.DatasetReference object, instead.
2021-06-05 17:23:47.473089 (MainThread): 22:23:47 | Concurrency: 1 threads (target='dev')
2021-06-05 17:23:47.473464 (MainThread): 22:23:47 | 
2021-06-05 17:23:47.476021 (Thread-1): Began running node model.werkspot_technical_challenge.fct_fee
2021-06-05 17:23:47.476449 (Thread-1): 22:23:47 | 1 of 1 START incremental model events_information.fct_fee............ [RUN]
2021-06-05 17:23:47.476926 (Thread-1): Acquiring new bigquery connection "model.werkspot_technical_challenge.fct_fee".
2021-06-05 17:23:47.477131 (Thread-1): Compiling model.werkspot_technical_challenge.fct_fee
2021-06-05 17:23:47.477882 (Thread-1): unclosed <socket.socket fd=13, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('192.168.0.104', 56078), raddr=('142.250.185.42', 443)>
2021-06-05 17:23:47.483747 (Thread-1): Writing injected SQL for node "model.werkspot_technical_challenge.fct_fee"
2021-06-05 17:23:47.484613 (Thread-1): finished collecting timing info
2021-06-05 17:23:47.486037 (Thread-1): unclosed <socket.socket fd=12, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('192.168.0.104', 56077), raddr=('142.250.185.42', 443)>
2021-06-05 17:23:47.486273 (Thread-1): unclosed <socket.socket fd=11, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('192.168.0.104', 56076), raddr=('216.58.209.138', 443)>
2021-06-05 17:23:47.564710 (Thread-1): Writing runtime SQL for node "model.werkspot_technical_challenge.fct_fee"
2021-06-05 17:23:47.565393 (Thread-1): Opening a new connection, currently in state closed
2021-06-05 17:23:47.565595 (Thread-1): On model.werkspot_technical_challenge.fct_fee: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "werkspot_technical_challenge", "target_name": "dev", "node_id": "model.werkspot_technical_challenge.fct_fee"} */


  create or replace table `poetic-genius-315513`.`events_information`.`fct_fee`
  partition by datetime_trunc(AuditCreatedDateTime, day)
  
  OPTIONS()
  as (
    




SELECT 

  CAST(ParsedEventLog[OFFSET(2)] AS INT64) AS FK_ProfessionalID, -- ProfessionalID referenced as foreign key
  
  (CASE 
    WHEN SPLIT(ParsedEventLog[OFFSET(4)],'_')[OFFSET(0)]='' 
      THEN 'Not provided' 
      ELSE  SPLIT(ParsedEventLog[OFFSET(4)],'_')[OFFSET(0)] 
    END) AS FK_ServiceID, -- ServiceID referenced as foreign key
  
  ParsedEventLog[OFFSET(0)] AS EventID, -- EventID is always at 1st index (assuming 0 based indexing)
  ParsedEventLog[OFFSET(1)] AS EventName, -- EventName is always at 2nd index (assuming 0 based indexing)
  CAST(ParsedEventLog[OFFSET(3)] AS DATETIME) AS CreatedAt, -- CreatedAt is always at 3rd index (assuming 0 based indexing)
  
  (CASE 
    WHEN ParsedEventLog[OFFSET(4)]!='' 
      THEN CAST(SPLIT(ParsedEventLog[OFFSET(4)],'_')[OFFSET(3)] AS FLOAT64) 
      ELSE 0.0 
   END) as LeadFee,
  
  CURRENT_DATETIME() as AuditCreatedDateTime, -- Audit column
  CURRENT_DATETIME() as AuditModifiedDateTime  -- Audit column
FROM
(
  SELECT 
      SPLIT(EventLogEntry,';') as ParsedEventLog
    FROM 
     `poetic-genius-315513.events_information_staging.events_log_data_stg`

      -- this will only be applied on an incremental run & will filter data early
      -- `poetic-genius-315513`.`events_information`.`fct_fee` will give last run date which can then be used to pick CDC records daily
      
)
  );
  
2021-06-05 17:23:51.281875 (Thread-1): finished collecting timing info
2021-06-05 17:23:51.282497 (Thread-1): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'd028fab7-a03c-481d-8051-a6c655d2ff9b', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f9a62739e50>]}
2021-06-05 17:23:51.283640 (Thread-1): 22:23:51 | 1 of 1 OK created incremental model events_information.fct_fee....... [CREATE TABLE (19.0k rows, 1.6 MB processed) in 3.81s]
2021-06-05 17:23:51.283926 (Thread-1): Finished running node model.werkspot_technical_challenge.fct_fee
2021-06-05 17:23:51.385996 (MainThread): Acquiring new bigquery connection "master".
2021-06-05 17:23:51.386692 (MainThread): 22:23:51 | 
2021-06-05 17:23:51.386922 (MainThread): 22:23:51 | Finished running 1 incremental model in 7.83s.
2021-06-05 17:23:51.387295 (MainThread): Connection 'master' was properly closed.
2021-06-05 17:23:51.387543 (MainThread): Connection 'model.werkspot_technical_challenge.fct_fee' was properly closed.
2021-06-05 17:23:51.413831 (MainThread): 
2021-06-05 17:23:51.414159 (MainThread): Completed successfully
2021-06-05 17:23:51.414570 (MainThread): 
Done. PASS=1 WARN=0 ERROR=0 SKIP=0 TOTAL=1
2021-06-05 17:23:51.415374 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f9a6242f650>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f9a6211b6d0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f9a6271a190>]}
2021-06-05 17:23:51.416414 (MainThread): Flushing usage events
2021-06-05 17:25:18.875561 (MainThread): Running with dbt=0.19.1
2021-06-05 17:25:19.814028 (MainThread): running dbt with arguments Namespace(cls=<class 'dbt.task.run.RunTask'>, debug=False, defer=None, exclude=None, fail_fast=False, full_refresh=False, log_cache_events=False, log_format='default', models=['fct_fee'], partial_parse=None, profile=None, profiles_dir='/Users/mac/.dbt', project_dir=None, record_timing_info=None, rpc_method='run', selector_name=None, single_threaded=False, state=None, strict=False, target=None, test_new_parser=False, threads=None, use_cache=True, use_colors=None, vars='{}', version_check=True, warn_error=False, which='run', write_json=True)
2021-06-05 17:25:19.815643 (MainThread): Tracking: tracking
2021-06-05 17:25:19.827643 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ffc927e1c90>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ffc927bc850>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ffc9245fc50>]}
2021-06-05 17:25:19.842840 (MainThread): Partial parsing not enabled
2021-06-05 17:25:19.844654 (MainThread): Parsing macros/etc.sql
2021-06-05 17:25:19.849224 (MainThread): Parsing macros/catalog.sql
2021-06-05 17:25:19.859059 (MainThread): Parsing macros/adapters.sql
2021-06-05 17:25:19.889148 (MainThread): Parsing macros/materializations/seed.sql
2021-06-05 17:25:19.894382 (MainThread): Parsing macros/materializations/view.sql
2021-06-05 17:25:19.899215 (MainThread): Parsing macros/materializations/table.sql
2021-06-05 17:25:19.913939 (MainThread): Parsing macros/materializations/copy.sql
2021-06-05 17:25:19.921854 (MainThread): Parsing macros/materializations/incremental.sql
2021-06-05 17:25:19.941826 (MainThread): Parsing macros/materializations/snapshot.sql
2021-06-05 17:25:19.945825 (MainThread): Parsing macros/core.sql
2021-06-05 17:25:19.951262 (MainThread): Parsing macros/materializations/helpers.sql
2021-06-05 17:25:19.964346 (MainThread): Parsing macros/materializations/snapshot/snapshot_merge.sql
2021-06-05 17:25:19.967734 (MainThread): Parsing macros/materializations/snapshot/strategies.sql
2021-06-05 17:25:19.993555 (MainThread): Parsing macros/materializations/snapshot/snapshot.sql
2021-06-05 17:25:20.038737 (MainThread): Parsing macros/materializations/seed/seed.sql
2021-06-05 17:25:20.067801 (MainThread): Parsing macros/materializations/incremental/helpers.sql
2021-06-05 17:25:20.070511 (MainThread): Parsing macros/materializations/incremental/incremental.sql
2021-06-05 17:25:20.079714 (MainThread): Parsing macros/materializations/common/merge.sql
2021-06-05 17:25:20.098780 (MainThread): Parsing macros/materializations/table/table.sql
2021-06-05 17:25:20.109556 (MainThread): Parsing macros/materializations/view/view.sql
2021-06-05 17:25:20.118263 (MainThread): Parsing macros/materializations/view/create_or_replace_view.sql
2021-06-05 17:25:20.125380 (MainThread): Parsing macros/etc/get_custom_alias.sql
2021-06-05 17:25:20.127747 (MainThread): Parsing macros/etc/query.sql
2021-06-05 17:25:20.129723 (MainThread): Parsing macros/etc/is_incremental.sql
2021-06-05 17:25:20.132436 (MainThread): Parsing macros/etc/datetime.sql
2021-06-05 17:25:20.145403 (MainThread): Parsing macros/etc/get_custom_schema.sql
2021-06-05 17:25:20.148184 (MainThread): Parsing macros/etc/get_custom_database.sql
2021-06-05 17:25:20.150682 (MainThread): Parsing macros/adapters/common.sql
2021-06-05 17:25:20.208929 (MainThread): Parsing macros/schema_tests/relationships.sql
2021-06-05 17:25:20.212299 (MainThread): Parsing macros/schema_tests/not_null.sql
2021-06-05 17:25:20.215589 (MainThread): Parsing macros/schema_tests/unique.sql
2021-06-05 17:25:20.219334 (MainThread): Parsing macros/schema_tests/accepted_values.sql
2021-06-05 17:25:20.231985 (MainThread): Partial parsing not enabled
2021-06-05 17:25:20.271875 (MainThread): Acquiring new bigquery connection "model.werkspot_technical_challenge.dim_service".
2021-06-05 17:25:20.298384 (MainThread): Acquiring new bigquery connection "model.werkspot_technical_challenge.dim_professional".
2021-06-05 17:25:20.306873 (MainThread): Acquiring new bigquery connection "model.werkspot_technical_challenge.fct_fee".
2021-06-05 17:25:20.406754 (MainThread): Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'fbc1209d-5bf9-4612-8cd0-c8458b6918ca', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ffc92992e10>]}
2021-06-05 17:25:20.422662 (MainThread): Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'fbc1209d-5bf9-4612-8cd0-c8458b6918ca', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ffc929aa090>]}
2021-06-05 17:25:20.423031 (MainThread): Found 3 models, 0 tests, 0 snapshots, 0 analyses, 156 macros, 0 operations, 0 seed files, 0 sources, 0 exposures
2021-06-05 17:25:20.423867 (MainThread): 
2021-06-05 17:25:20.424391 (MainThread): Acquiring new bigquery connection "master".
2021-06-05 17:25:20.425399 (ThreadPoolExecutor-0_0): Acquiring new bigquery connection "list_poetic-genius-315513".
2021-06-05 17:25:20.425696 (ThreadPoolExecutor-0_0): Opening a new connection, currently in state init
2021-06-05 17:25:23.160670 (ThreadPoolExecutor-1_0): Acquiring new bigquery connection "list_poetic-genius-315513_events_information".
2021-06-05 17:25:23.161077 (ThreadPoolExecutor-1_0): Opening a new connection, currently in state closed
2021-06-05 17:25:23.161421 (ThreadPoolExecutor-1_0): Client.dataset is deprecated and will be removed in a future version. Use a string like 'my_project.my_dataset' or a cloud.google.bigquery.DatasetReference object, instead.
2021-06-05 17:25:24.444563 (MainThread): 22:25:24 | Concurrency: 1 threads (target='dev')
2021-06-05 17:25:24.444942 (MainThread): 22:25:24 | 
2021-06-05 17:25:24.447397 (Thread-1): Began running node model.werkspot_technical_challenge.fct_fee
2021-06-05 17:25:24.447823 (Thread-1): 22:25:24 | 1 of 1 START incremental model events_information.fct_fee............ [RUN]
2021-06-05 17:25:24.448319 (Thread-1): Acquiring new bigquery connection "model.werkspot_technical_challenge.fct_fee".
2021-06-05 17:25:24.448535 (Thread-1): Compiling model.werkspot_technical_challenge.fct_fee
2021-06-05 17:25:24.449255 (Thread-1): unclosed <socket.socket fd=13, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('192.168.0.104', 56111), raddr=('142.250.185.42', 443)>
2021-06-05 17:25:24.454981 (Thread-1): Writing injected SQL for node "model.werkspot_technical_challenge.fct_fee"
2021-06-05 17:25:24.482133 (Thread-1): finished collecting timing info
2021-06-05 17:25:24.483805 (Thread-1): unclosed <socket.socket fd=12, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('192.168.0.104', 56110), raddr=('142.250.185.42', 443)>
2021-06-05 17:25:24.484147 (Thread-1): unclosed <socket.socket fd=11, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('192.168.0.104', 56109), raddr=('216.58.209.138', 443)>
2021-06-05 17:25:24.553827 (Thread-1): Writing runtime SQL for node "model.werkspot_technical_challenge.fct_fee"
2021-06-05 17:25:24.554508 (Thread-1): Opening a new connection, currently in state closed
2021-06-05 17:25:24.554719 (Thread-1): On model.werkspot_technical_challenge.fct_fee: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "werkspot_technical_challenge", "target_name": "dev", "node_id": "model.werkspot_technical_challenge.fct_fee"} */


  create or replace table `poetic-genius-315513`.`events_information`.`fct_fee`
  partition by datetime_trunc(AuditCreatedDateTime, day)
  
  OPTIONS()
  as (
    




SELECT 

  CAST(ParsedEventLog[OFFSET(2)] AS INT64) AS FK_ProfessionalID, -- ProfessionalID referenced as foreign key
  
  (CASE 
    WHEN SPLIT(ParsedEventLog[OFFSET(4)],'_')[OFFSET(0)]='' 
      THEN 'Not provided' 
      ELSE  SPLIT(ParsedEventLog[OFFSET(4)],'_')[OFFSET(0)] 
    END) AS FK_ServiceID, -- ServiceID referenced as foreign key
  
  ParsedEventLog[OFFSET(0)] AS EventID, -- EventID is always at 1st index (assuming 0 based indexing)
  ParsedEventLog[OFFSET(1)] AS EventName, -- EventName is always at 2nd index (assuming 0 based indexing)
  CAST(ParsedEventLog[OFFSET(3)] AS DATETIME) AS CreatedAt, -- CreatedAt is always at 3rd index (assuming 0 based indexing)
  
  (CASE 
    WHEN ParsedEventLog[OFFSET(4)]!='' 
      THEN CAST(SPLIT(ParsedEventLog[OFFSET(4)],'_')[OFFSET(3)] AS FLOAT64) 
      ELSE 0.0 
   END) as LeadFee,
  
  CURRENT_DATETIME() as AuditCreatedDateTime, -- Audit column
  CURRENT_DATETIME() as AuditModifiedDateTime  -- Audit column
FROM
(
  SELECT 
      SPLIT(EventLogEntry,';') as ParsedEventLog
    FROM 
     `poetic-genius-315513.events_information_staging.events_log_data_stg`

      -- this will only be applied on an incremental run & will filter data early
      -- `poetic-genius-315513`.`events_information`.`fct_fee` will give last run date which can then be used to pick CDC records daily
      
)
  );
  
2021-06-05 17:25:28.235477 (Thread-1): finished collecting timing info
2021-06-05 17:25:28.236115 (Thread-1): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'fbc1209d-5bf9-4612-8cd0-c8458b6918ca', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ffc92e58d90>]}
2021-06-05 17:25:28.236704 (Thread-1): 22:25:28 | 1 of 1 OK created incremental model events_information.fct_fee....... [CREATE TABLE (19.0k rows, 1.6 MB processed) in 3.79s]
2021-06-05 17:25:28.236931 (Thread-1): Finished running node model.werkspot_technical_challenge.fct_fee
2021-06-05 17:25:28.338777 (MainThread): Acquiring new bigquery connection "master".
2021-06-05 17:25:28.339224 (MainThread): 22:25:28 | 
2021-06-05 17:25:28.339416 (MainThread): 22:25:28 | Finished running 1 incremental model in 7.92s.
2021-06-05 17:25:28.339659 (MainThread): Connection 'master' was properly closed.
2021-06-05 17:25:28.339815 (MainThread): Connection 'model.werkspot_technical_challenge.fct_fee' was properly closed.
2021-06-05 17:25:28.350639 (MainThread): 
2021-06-05 17:25:28.350908 (MainThread): Completed successfully
2021-06-05 17:25:28.351144 (MainThread): 
Done. PASS=1 WARN=0 ERROR=0 SKIP=0 TOTAL=1
2021-06-05 17:25:28.351493 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ffc92bc2d50>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ffc929a33d0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ffc927ed4d0>]}
2021-06-05 17:25:28.351780 (MainThread): Flushing usage events
2021-06-05 17:28:53.361444 (MainThread): Running with dbt=0.19.1
2021-06-05 17:28:54.303048 (MainThread): running dbt with arguments Namespace(cls=<class 'dbt.task.run.RunTask'>, debug=False, defer=None, exclude=None, fail_fast=False, full_refresh=False, log_cache_events=False, log_format='default', models=['fct_fee'], partial_parse=None, profile=None, profiles_dir='/Users/mac/.dbt', project_dir=None, record_timing_info=None, rpc_method='run', selector_name=None, single_threaded=False, state=None, strict=False, target=None, test_new_parser=False, threads=None, use_cache=True, use_colors=None, vars='{}', version_check=True, warn_error=False, which='run', write_json=True)
2021-06-05 17:28:54.304315 (MainThread): Tracking: tracking
2021-06-05 17:28:54.315559 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fa12e90b090>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fa12e90bed0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fa12e90b250>]}
2021-06-05 17:28:54.330003 (MainThread): Partial parsing not enabled
2021-06-05 17:28:54.331664 (MainThread): Parsing macros/etc.sql
2021-06-05 17:28:54.336741 (MainThread): Parsing macros/catalog.sql
2021-06-05 17:28:54.345862 (MainThread): Parsing macros/adapters.sql
2021-06-05 17:28:54.374139 (MainThread): Parsing macros/materializations/seed.sql
2021-06-05 17:28:54.379915 (MainThread): Parsing macros/materializations/view.sql
2021-06-05 17:28:54.384445 (MainThread): Parsing macros/materializations/table.sql
2021-06-05 17:28:54.398250 (MainThread): Parsing macros/materializations/copy.sql
2021-06-05 17:28:54.404653 (MainThread): Parsing macros/materializations/incremental.sql
2021-06-05 17:28:54.422635 (MainThread): Parsing macros/materializations/snapshot.sql
2021-06-05 17:28:54.429764 (MainThread): Parsing macros/core.sql
2021-06-05 17:28:54.436727 (MainThread): Parsing macros/materializations/helpers.sql
2021-06-05 17:28:54.449698 (MainThread): Parsing macros/materializations/snapshot/snapshot_merge.sql
2021-06-05 17:28:54.452670 (MainThread): Parsing macros/materializations/snapshot/strategies.sql
2021-06-05 17:28:54.477029 (MainThread): Parsing macros/materializations/snapshot/snapshot.sql
2021-06-05 17:28:54.522043 (MainThread): Parsing macros/materializations/seed/seed.sql
2021-06-05 17:28:54.553234 (MainThread): Parsing macros/materializations/incremental/helpers.sql
2021-06-05 17:28:54.555921 (MainThread): Parsing macros/materializations/incremental/incremental.sql
2021-06-05 17:28:54.565471 (MainThread): Parsing macros/materializations/common/merge.sql
2021-06-05 17:28:54.587652 (MainThread): Parsing macros/materializations/table/table.sql
2021-06-05 17:28:54.599959 (MainThread): Parsing macros/materializations/view/view.sql
2021-06-05 17:28:54.609325 (MainThread): Parsing macros/materializations/view/create_or_replace_view.sql
2021-06-05 17:28:54.615954 (MainThread): Parsing macros/etc/get_custom_alias.sql
2021-06-05 17:28:54.617294 (MainThread): Parsing macros/etc/query.sql
2021-06-05 17:28:54.618767 (MainThread): Parsing macros/etc/is_incremental.sql
2021-06-05 17:28:54.621012 (MainThread): Parsing macros/etc/datetime.sql
2021-06-05 17:28:54.632882 (MainThread): Parsing macros/etc/get_custom_schema.sql
2021-06-05 17:28:54.635586 (MainThread): Parsing macros/etc/get_custom_database.sql
2021-06-05 17:28:54.637934 (MainThread): Parsing macros/adapters/common.sql
2021-06-05 17:28:54.695796 (MainThread): Parsing macros/schema_tests/relationships.sql
2021-06-05 17:28:54.698614 (MainThread): Parsing macros/schema_tests/not_null.sql
2021-06-05 17:28:54.701002 (MainThread): Parsing macros/schema_tests/unique.sql
2021-06-05 17:28:54.703775 (MainThread): Parsing macros/schema_tests/accepted_values.sql
2021-06-05 17:28:54.714319 (MainThread): Partial parsing not enabled
2021-06-05 17:28:54.748905 (MainThread): Acquiring new bigquery connection "model.werkspot_technical_challenge.dim_service".
2021-06-05 17:28:54.768450 (MainThread): Acquiring new bigquery connection "model.werkspot_technical_challenge.dim_professional".
2021-06-05 17:28:54.782792 (MainThread): Acquiring new bigquery connection "model.werkspot_technical_challenge.fct_fee".
2021-06-05 17:28:54.854530 (MainThread): Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'c220574a-d4a9-4b56-b896-eacb7c0f0ae3', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fa12eacdf50>]}
2021-06-05 17:28:54.870503 (MainThread): Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'c220574a-d4a9-4b56-b896-eacb7c0f0ae3', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fa12ead8a90>]}
2021-06-05 17:28:54.871030 (MainThread): Found 3 models, 0 tests, 0 snapshots, 0 analyses, 156 macros, 0 operations, 0 seed files, 0 sources, 0 exposures
2021-06-05 17:28:54.872061 (MainThread): 
2021-06-05 17:28:54.872551 (MainThread): Acquiring new bigquery connection "master".
2021-06-05 17:28:54.873573 (ThreadPoolExecutor-0_0): Acquiring new bigquery connection "list_poetic-genius-315513".
2021-06-05 17:28:54.873875 (ThreadPoolExecutor-0_0): Opening a new connection, currently in state init
2021-06-05 17:28:57.334828 (ThreadPoolExecutor-1_0): Acquiring new bigquery connection "list_poetic-genius-315513_events_information".
2021-06-05 17:28:57.335210 (ThreadPoolExecutor-1_0): Opening a new connection, currently in state closed
2021-06-05 17:28:57.335513 (ThreadPoolExecutor-1_0): Client.dataset is deprecated and will be removed in a future version. Use a string like 'my_project.my_dataset' or a cloud.google.bigquery.DatasetReference object, instead.
2021-06-05 17:28:58.506522 (MainThread): 22:28:58 | Concurrency: 1 threads (target='dev')
2021-06-05 17:28:58.506891 (MainThread): 22:28:58 | 
2021-06-05 17:28:58.509616 (Thread-1): Began running node model.werkspot_technical_challenge.fct_fee
2021-06-05 17:28:58.510047 (Thread-1): 22:28:58 | 1 of 1 START incremental model events_information.fct_fee............ [RUN]
2021-06-05 17:28:58.510528 (Thread-1): Acquiring new bigquery connection "model.werkspot_technical_challenge.fct_fee".
2021-06-05 17:28:58.510732 (Thread-1): Compiling model.werkspot_technical_challenge.fct_fee
2021-06-05 17:28:58.511487 (Thread-1): unclosed <socket.socket fd=13, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('192.168.0.104', 56152), raddr=('142.250.185.42', 443)>
2021-06-05 17:28:58.517335 (Thread-1): Writing injected SQL for node "model.werkspot_technical_challenge.fct_fee"
2021-06-05 17:28:58.518199 (Thread-1): finished collecting timing info
2021-06-05 17:28:58.519853 (Thread-1): unclosed <socket.socket fd=12, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('192.168.0.104', 56151), raddr=('142.250.185.42', 443)>
2021-06-05 17:28:58.520116 (Thread-1): unclosed <socket.socket fd=11, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('192.168.0.104', 56150), raddr=('216.58.210.74', 443)>
2021-06-05 17:28:58.591260 (Thread-1): Writing runtime SQL for node "model.werkspot_technical_challenge.fct_fee"
2021-06-05 17:28:58.591851 (Thread-1): Opening a new connection, currently in state closed
2021-06-05 17:28:58.592062 (Thread-1): On model.werkspot_technical_challenge.fct_fee: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "werkspot_technical_challenge", "target_name": "dev", "node_id": "model.werkspot_technical_challenge.fct_fee"} */


  create or replace table `poetic-genius-315513`.`events_information`.`fct_fee`
  partition by datetime_trunc(AuditCreatedDateTime, day)
  
  OPTIONS()
  as (
    




SELECT 

  CAST(ParsedEventLog[OFFSET(2)] AS STRING) AS FK_ProfessionalID, -- ProfessionalID referenced as foreign key
  
  (CASE 
    WHEN SPLIT(ParsedEventLog[OFFSET(4)],'_')[OFFSET(0)]='' 
      THEN 'Not provided' 
      ELSE  SPLIT(ParsedEventLog[OFFSET(4)],'_')[OFFSET(0)] 
    END) AS FK_ServiceID, -- ServiceID referenced as foreign key
  
  ParsedEventLog[OFFSET(0)] AS EventID, -- EventID is always at 1st index (assuming 0 based indexing)
  ParsedEventLog[OFFSET(1)] AS EventName, -- EventName is always at 2nd index (assuming 0 based indexing)
  CAST(ParsedEventLog[OFFSET(3)] AS DATETIME) AS CreatedAt, -- CreatedAt is always at 3rd index (assuming 0 based indexing)
  
  (CASE 
    WHEN ParsedEventLog[OFFSET(4)]!='' 
      THEN CAST(SPLIT(ParsedEventLog[OFFSET(4)],'_')[OFFSET(3)] AS FLOAT64) 
      ELSE 0.0 
   END) as LeadFee,
  
  CURRENT_DATETIME() as AuditCreatedDateTime, -- Audit column
  CURRENT_DATETIME() as AuditModifiedDateTime  -- Audit column
FROM
(
  SELECT 
      SPLIT(EventLogEntry,';') as ParsedEventLog
    FROM 
     `poetic-genius-315513.events_information_staging.events_log_data_stg`

      -- this will only be applied on an incremental run & will filter data early
      -- `poetic-genius-315513`.`events_information`.`fct_fee` will give last run date which can then be used to pick CDC records daily
      
)
  );
  
2021-06-05 17:29:02.968292 (Thread-1): finished collecting timing info
2021-06-05 17:29:02.968859 (Thread-1): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'c220574a-d4a9-4b56-b896-eacb7c0f0ae3', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fa12ec6c710>]}
2021-06-05 17:29:02.969325 (Thread-1): 22:29:02 | 1 of 1 OK created incremental model events_information.fct_fee....... [CREATE TABLE (19.0k rows, 1.6 MB processed) in 4.46s]
2021-06-05 17:29:02.969550 (Thread-1): Finished running node model.werkspot_technical_challenge.fct_fee
2021-06-05 17:29:03.059990 (MainThread): Acquiring new bigquery connection "master".
2021-06-05 17:29:03.060711 (MainThread): 22:29:03 | 
2021-06-05 17:29:03.061009 (MainThread): 22:29:03 | Finished running 1 incremental model in 8.19s.
2021-06-05 17:29:03.061405 (MainThread): Connection 'master' was properly closed.
2021-06-05 17:29:03.061631 (MainThread): Connection 'model.werkspot_technical_challenge.fct_fee' was properly closed.
2021-06-05 17:29:03.072121 (MainThread): 
2021-06-05 17:29:03.072392 (MainThread): Completed successfully
2021-06-05 17:29:03.072643 (MainThread): 
Done. PASS=1 WARN=0 ERROR=0 SKIP=0 TOTAL=1
2021-06-05 17:29:03.072999 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fa12ecf0e10>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fa12ece7f50>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fa12ef31b50>]}
2021-06-05 17:29:03.073282 (MainThread): Flushing usage events
2021-06-05 20:06:58.652966 (MainThread): Running with dbt=0.19.1
2021-06-05 20:06:59.755774 (MainThread): running dbt with arguments Namespace(cls=<class 'dbt.task.run.RunTask'>, debug=False, defer=None, exclude=None, fail_fast=False, full_refresh=False, log_cache_events=False, log_format='default', models=['event_logs_stg'], partial_parse=None, profile=None, profiles_dir='/Users/mac/.dbt', project_dir=None, record_timing_info=None, rpc_method='run', selector_name=None, single_threaded=False, state=None, strict=False, target=None, test_new_parser=False, threads=None, use_cache=True, use_colors=None, vars='{}', version_check=True, warn_error=False, which='run', write_json=True)
2021-06-05 20:06:59.757249 (MainThread): Tracking: tracking
2021-06-05 20:06:59.771148 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f8a6010c910>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f8a6010c790>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f8a6010c850>]}
2021-06-05 20:06:59.786345 (MainThread): Partial parsing not enabled
2021-06-05 20:06:59.788312 (MainThread): Parsing macros/etc.sql
2021-06-05 20:06:59.792979 (MainThread): Parsing macros/catalog.sql
2021-06-05 20:06:59.802912 (MainThread): Parsing macros/adapters.sql
2021-06-05 20:06:59.833243 (MainThread): Parsing macros/materializations/seed.sql
2021-06-05 20:06:59.837626 (MainThread): Parsing macros/materializations/view.sql
2021-06-05 20:06:59.841927 (MainThread): Parsing macros/materializations/table.sql
2021-06-05 20:06:59.855488 (MainThread): Parsing macros/materializations/copy.sql
2021-06-05 20:06:59.862863 (MainThread): Parsing macros/materializations/incremental.sql
2021-06-05 20:06:59.883327 (MainThread): Parsing macros/materializations/snapshot.sql
2021-06-05 20:06:59.888361 (MainThread): Parsing macros/core.sql
2021-06-05 20:06:59.893877 (MainThread): Parsing macros/materializations/helpers.sql
2021-06-05 20:06:59.906452 (MainThread): Parsing macros/materializations/snapshot/snapshot_merge.sql
2021-06-05 20:06:59.909120 (MainThread): Parsing macros/materializations/snapshot/strategies.sql
2021-06-05 20:06:59.933477 (MainThread): Parsing macros/materializations/snapshot/snapshot.sql
2021-06-05 20:06:59.979788 (MainThread): Parsing macros/materializations/seed/seed.sql
2021-06-05 20:07:00.012480 (MainThread): Parsing macros/materializations/incremental/helpers.sql
2021-06-05 20:07:00.015900 (MainThread): Parsing macros/materializations/incremental/incremental.sql
2021-06-05 20:07:00.028905 (MainThread): Parsing macros/materializations/common/merge.sql
2021-06-05 20:07:00.049299 (MainThread): Parsing macros/materializations/table/table.sql
2021-06-05 20:07:00.059896 (MainThread): Parsing macros/materializations/view/view.sql
2021-06-05 20:07:00.071498 (MainThread): Parsing macros/materializations/view/create_or_replace_view.sql
2021-06-05 20:07:00.080370 (MainThread): Parsing macros/etc/get_custom_alias.sql
2021-06-05 20:07:00.082145 (MainThread): Parsing macros/etc/query.sql
2021-06-05 20:07:00.083932 (MainThread): Parsing macros/etc/is_incremental.sql
2021-06-05 20:07:00.086532 (MainThread): Parsing macros/etc/datetime.sql
2021-06-05 20:07:00.098989 (MainThread): Parsing macros/etc/get_custom_schema.sql
2021-06-05 20:07:00.101845 (MainThread): Parsing macros/etc/get_custom_database.sql
2021-06-05 20:07:00.104781 (MainThread): Parsing macros/adapters/common.sql
2021-06-05 20:07:00.164487 (MainThread): Parsing macros/schema_tests/relationships.sql
2021-06-05 20:07:00.168921 (MainThread): Parsing macros/schema_tests/not_null.sql
2021-06-05 20:07:00.171471 (MainThread): Parsing macros/schema_tests/unique.sql
2021-06-05 20:07:00.174313 (MainThread): Parsing macros/schema_tests/accepted_values.sql
2021-06-05 20:07:00.185574 (MainThread): Partial parsing not enabled
2021-06-05 20:07:00.220366 (MainThread): Acquiring new bigquery connection "model.werkspot_technical_challenge.dim_service".
2021-06-05 20:07:00.241619 (MainThread): Acquiring new bigquery connection "model.werkspot_technical_challenge.dim_professional".
2021-06-05 20:07:00.248750 (MainThread): Acquiring new bigquery connection "model.werkspot_technical_challenge.fct_fee".
2021-06-05 20:07:00.264342 (MainThread): Acquiring new bigquery connection "model.werkspot_technical_challenge.event_logs_stg".
2021-06-05 20:07:00.336485 (MainThread): Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '346a6143-1ebd-47ef-8521-244eef3141e5', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f8a602e2d50>]}
2021-06-05 20:07:00.353103 (MainThread): Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '346a6143-1ebd-47ef-8521-244eef3141e5', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f8a60432290>]}
2021-06-05 20:07:00.353647 (MainThread): Found 4 models, 0 tests, 0 snapshots, 0 analyses, 156 macros, 0 operations, 0 seed files, 0 sources, 0 exposures
2021-06-05 20:07:00.354824 (MainThread): 
2021-06-05 20:07:00.355341 (MainThread): Acquiring new bigquery connection "master".
2021-06-05 20:07:00.356364 (ThreadPoolExecutor-0_0): Acquiring new bigquery connection "list_poetic-genius-315513".
2021-06-05 20:07:00.356588 (ThreadPoolExecutor-0_0): Opening a new connection, currently in state init
2021-06-05 20:07:04.056673 (ThreadPoolExecutor-1_0): Acquiring new bigquery connection "list_poetic-genius-315513_events_information".
2021-06-05 20:07:04.057046 (ThreadPoolExecutor-1_0): Opening a new connection, currently in state closed
2021-06-05 20:07:04.057371 (ThreadPoolExecutor-1_0): Client.dataset is deprecated and will be removed in a future version. Use a string like 'my_project.my_dataset' or a cloud.google.bigquery.DatasetReference object, instead.
2021-06-05 20:07:06.135450 (MainThread): 01:07:06 | Concurrency: 1 threads (target='dev')
2021-06-05 20:07:06.135867 (MainThread): 01:07:06 | 
2021-06-05 20:07:06.138204 (Thread-1): Began running node model.werkspot_technical_challenge.event_logs_stg
2021-06-05 20:07:06.138618 (Thread-1): 01:07:06 | 1 of 1 START incremental model events_information.event_logs_stg..... [RUN]
2021-06-05 20:07:06.139097 (Thread-1): Acquiring new bigquery connection "model.werkspot_technical_challenge.event_logs_stg".
2021-06-05 20:07:06.140464 (Thread-1): unclosed <socket.socket fd=12, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('192.168.0.104', 61072), raddr=('142.250.185.42', 443)>
2021-06-05 20:07:06.140704 (Thread-1): unclosed <socket.socket fd=11, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('192.168.0.104', 61071), raddr=('172.217.169.234', 443)>
2021-06-05 20:07:06.140959 (Thread-1): unclosed <socket.socket fd=13, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('192.168.0.104', 61073), raddr=('142.250.185.42', 443)>
2021-06-05 20:07:06.141440 (Thread-1): Compiling model.werkspot_technical_challenge.event_logs_stg
2021-06-05 20:07:06.147106 (Thread-1): Writing injected SQL for node "model.werkspot_technical_challenge.event_logs_stg"
2021-06-05 20:07:06.148054 (Thread-1): finished collecting timing info
2021-06-05 20:07:06.216104 (Thread-1): Writing runtime SQL for node "model.werkspot_technical_challenge.event_logs_stg"
2021-06-05 20:07:06.216923 (Thread-1): Opening a new connection, currently in state closed
2021-06-05 20:07:06.217166 (Thread-1): On model.werkspot_technical_challenge.event_logs_stg: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "werkspot_technical_challenge", "target_name": "dev", "node_id": "model.werkspot_technical_challenge.event_logs_stg"} */


  create or replace table `poetic-genius-315513`.`events_information`.`event_logs_stg`
  partition by datetime_trunc(AuditCreatedDatetime, day)
  
  OPTIONS()
  as (
    


SELECT
  ParsedEventLogEntry[OFFSET(0)] AS EventID,
  ParsedEventLogEntry[OFFSET(1)] AS EventType,
  ParsedEventLogEntry[OFFSET(2)] AS ProfessionalID,
  ParsedEventLogEntry[OFFSET(3)] AS CreatedAt,
  ParsedEventLogEntry[OFFSET(4)] AS Metadata,
  CURRENT_DATETIME() AS AuditCreatedDatetime -- Audit Column, Used for Partitioning & Filtering Day in daily runs
FROM
(
  SELECT 
    
    SPLIT( EventLogEntry, ';') AS ParsedEventLogEntry -- Parsing Raw Event Log Entry on ; delimiter
  
  FROM `poetic-genius-315513.events_information.raw_event_logs`

    -- this will only be applied on an incremental run & will filter data early
    -- `poetic-genius-315513`.`events_information`.`event_logs_stg` will give last run date which can then be used to pick CDC records daily
    
)
  );
  
2021-06-05 20:07:10.508904 (Thread-1): finished collecting timing info
2021-06-05 20:07:10.509509 (Thread-1): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '346a6143-1ebd-47ef-8521-244eef3141e5', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f8a60554290>]}
2021-06-05 20:07:10.510029 (Thread-1): 01:07:10 | 1 of 1 OK created incremental model events_information.event_logs_stg [CREATE TABLE (19.0k rows, 1.6 MB processed) in 4.37s]
2021-06-05 20:07:10.510258 (Thread-1): Finished running node model.werkspot_technical_challenge.event_logs_stg
2021-06-05 20:07:10.583713 (MainThread): Acquiring new bigquery connection "master".
2021-06-05 20:07:10.584562 (MainThread): 01:07:10 | 
2021-06-05 20:07:10.584863 (MainThread): 01:07:10 | Finished running 1 incremental model in 10.23s.
2021-06-05 20:07:10.585220 (MainThread): Connection 'master' was properly closed.
2021-06-05 20:07:10.585371 (MainThread): Connection 'model.werkspot_technical_challenge.event_logs_stg' was properly closed.
2021-06-05 20:07:10.609078 (MainThread): 
2021-06-05 20:07:10.609338 (MainThread): Completed successfully
2021-06-05 20:07:10.609547 (MainThread): 
Done. PASS=1 WARN=0 ERROR=0 SKIP=0 TOTAL=1
2021-06-05 20:07:10.609865 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f8a605220d0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f8a6056b350>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f8a6056b110>]}
2021-06-05 20:07:10.610143 (MainThread): Flushing usage events
2021-06-05 20:11:29.450188 (MainThread): Running with dbt=0.19.1
2021-06-05 20:11:30.378152 (MainThread): running dbt with arguments Namespace(cls=<class 'dbt.task.run.RunTask'>, debug=False, defer=None, exclude=None, fail_fast=False, full_refresh=False, log_cache_events=False, log_format='default', models=['dim_professional'], partial_parse=None, profile=None, profiles_dir='/Users/mac/.dbt', project_dir=None, record_timing_info=None, rpc_method='run', selector_name=None, single_threaded=False, state=None, strict=False, target=None, test_new_parser=False, threads=None, use_cache=True, use_colors=None, vars='{}', version_check=True, warn_error=False, which='run', write_json=True)
2021-06-05 20:11:30.379435 (MainThread): Tracking: tracking
2021-06-05 20:11:30.394181 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fd33f7eea90>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fd33f7ee990>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fd33f7ee1d0>]}
2021-06-05 20:11:30.409169 (MainThread): Partial parsing not enabled
2021-06-05 20:11:30.410817 (MainThread): Parsing macros/etc.sql
2021-06-05 20:11:30.416996 (MainThread): Parsing macros/catalog.sql
2021-06-05 20:11:30.426567 (MainThread): Parsing macros/adapters.sql
2021-06-05 20:11:30.455062 (MainThread): Parsing macros/materializations/seed.sql
2021-06-05 20:11:30.459080 (MainThread): Parsing macros/materializations/view.sql
2021-06-05 20:11:30.463913 (MainThread): Parsing macros/materializations/table.sql
2021-06-05 20:11:30.478997 (MainThread): Parsing macros/materializations/copy.sql
2021-06-05 20:11:30.486267 (MainThread): Parsing macros/materializations/incremental.sql
2021-06-05 20:11:30.508552 (MainThread): Parsing macros/materializations/snapshot.sql
2021-06-05 20:11:30.513179 (MainThread): Parsing macros/core.sql
2021-06-05 20:11:30.519526 (MainThread): Parsing macros/materializations/helpers.sql
2021-06-05 20:11:30.534106 (MainThread): Parsing macros/materializations/snapshot/snapshot_merge.sql
2021-06-05 20:11:30.536873 (MainThread): Parsing macros/materializations/snapshot/strategies.sql
2021-06-05 20:11:30.561408 (MainThread): Parsing macros/materializations/snapshot/snapshot.sql
2021-06-05 20:11:30.606808 (MainThread): Parsing macros/materializations/seed/seed.sql
2021-06-05 20:11:30.636161 (MainThread): Parsing macros/materializations/incremental/helpers.sql
2021-06-05 20:11:30.640604 (MainThread): Parsing macros/materializations/incremental/incremental.sql
2021-06-05 20:11:30.650324 (MainThread): Parsing macros/materializations/common/merge.sql
2021-06-05 20:11:30.669740 (MainThread): Parsing macros/materializations/table/table.sql
2021-06-05 20:11:30.680163 (MainThread): Parsing macros/materializations/view/view.sql
2021-06-05 20:11:30.688728 (MainThread): Parsing macros/materializations/view/create_or_replace_view.sql
2021-06-05 20:11:30.695605 (MainThread): Parsing macros/etc/get_custom_alias.sql
2021-06-05 20:11:30.697059 (MainThread): Parsing macros/etc/query.sql
2021-06-05 20:11:30.698536 (MainThread): Parsing macros/etc/is_incremental.sql
2021-06-05 20:11:30.700907 (MainThread): Parsing macros/etc/datetime.sql
2021-06-05 20:11:30.713147 (MainThread): Parsing macros/etc/get_custom_schema.sql
2021-06-05 20:11:30.716247 (MainThread): Parsing macros/etc/get_custom_database.sql
2021-06-05 20:11:30.719024 (MainThread): Parsing macros/adapters/common.sql
2021-06-05 20:11:30.778569 (MainThread): Parsing macros/schema_tests/relationships.sql
2021-06-05 20:11:30.781627 (MainThread): Parsing macros/schema_tests/not_null.sql
2021-06-05 20:11:30.784149 (MainThread): Parsing macros/schema_tests/unique.sql
2021-06-05 20:11:30.787605 (MainThread): Parsing macros/schema_tests/accepted_values.sql
2021-06-05 20:11:30.799214 (MainThread): Partial parsing not enabled
2021-06-05 20:11:30.832597 (MainThread): Acquiring new bigquery connection "model.werkspot_technical_challenge.dim_service".
2021-06-05 20:11:30.860959 (MainThread): Acquiring new bigquery connection "model.werkspot_technical_challenge.dim_professional".
2021-06-05 20:11:30.875307 (MainThread): Acquiring new bigquery connection "model.werkspot_technical_challenge.fct_fee".
2021-06-05 20:11:30.885156 (MainThread): Acquiring new bigquery connection "model.werkspot_technical_challenge.event_logs_stg".
2021-06-05 20:11:30.964193 (MainThread): Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '0e424a98-bbf0-4df7-a20a-bb7004724a27', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fd33fb9ced0>]}
2021-06-05 20:11:30.980610 (MainThread): Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '0e424a98-bbf0-4df7-a20a-bb7004724a27', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fd33fc39f90>]}
2021-06-05 20:11:30.981109 (MainThread): Found 4 models, 0 tests, 0 snapshots, 0 analyses, 156 macros, 0 operations, 0 seed files, 0 sources, 0 exposures
2021-06-05 20:11:30.982038 (MainThread): 
2021-06-05 20:11:30.982527 (MainThread): Acquiring new bigquery connection "master".
2021-06-05 20:11:30.983563 (ThreadPoolExecutor-0_0): Acquiring new bigquery connection "list_poetic-genius-315513".
2021-06-05 20:11:30.983868 (ThreadPoolExecutor-0_0): Opening a new connection, currently in state init
2021-06-05 20:11:33.467908 (ThreadPoolExecutor-1_0): Acquiring new bigquery connection "list_poetic-genius-315513_events_information".
2021-06-05 20:11:33.468280 (ThreadPoolExecutor-1_0): Opening a new connection, currently in state closed
2021-06-05 20:11:33.468598 (ThreadPoolExecutor-1_0): Client.dataset is deprecated and will be removed in a future version. Use a string like 'my_project.my_dataset' or a cloud.google.bigquery.DatasetReference object, instead.
2021-06-05 20:11:34.823687 (MainThread): 01:11:34 | Concurrency: 1 threads (target='dev')
2021-06-05 20:11:34.823976 (MainThread): 01:11:34 | 
2021-06-05 20:11:34.826395 (Thread-1): Began running node model.werkspot_technical_challenge.dim_professional
2021-06-05 20:11:34.826806 (Thread-1): 01:11:34 | 1 of 1 START incremental model events_information.dim_professional... [RUN]
2021-06-05 20:11:34.827277 (Thread-1): Acquiring new bigquery connection "model.werkspot_technical_challenge.dim_professional".
2021-06-05 20:11:34.828627 (Thread-1): unclosed <socket.socket fd=12, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('192.168.0.104', 61139), raddr=('142.250.185.42', 443)>
2021-06-05 20:11:34.828883 (Thread-1): unclosed <socket.socket fd=11, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('192.168.0.104', 61138), raddr=('172.217.169.234', 443)>
2021-06-05 20:11:34.829088 (Thread-1): unclosed <socket.socket fd=13, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('192.168.0.104', 61144), raddr=('142.250.185.42', 443)>
2021-06-05 20:11:34.829538 (Thread-1): Compiling model.werkspot_technical_challenge.dim_professional
2021-06-05 20:11:34.835855 (Thread-1): Writing injected SQL for node "model.werkspot_technical_challenge.dim_professional"
2021-06-05 20:11:34.836976 (Thread-1): finished collecting timing info
2021-06-05 20:11:34.909442 (Thread-1): Writing runtime SQL for node "model.werkspot_technical_challenge.dim_professional"
2021-06-05 20:11:34.910163 (Thread-1): Opening a new connection, currently in state closed
2021-06-05 20:11:34.910395 (Thread-1): On model.werkspot_technical_challenge.dim_professional: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "werkspot_technical_challenge", "target_name": "dev", "node_id": "model.werkspot_technical_challenge.dim_professional"} */


  create or replace table `poetic-genius-315513`.`events_information`.`dim_professional`
  partition by datetime_trunc(AuditCreatedDateTime, day)
  
  OPTIONS()
  as (
    


SELECT
  
  DISTINCT

    ProfessionalID,
    CURRENT_DATETIME() as AuditCreatedDateTime,  -- Audit Column, Used for Partitioning & Filtering Day in daily runs

FROM 

  `poetic-genius-315513`.`events_information`.`event_logs_stg`
      
    -- this will only be applied on an incremental run & will filter data early
    -- `poetic-genius-315513`.`events_information`.`dim_professional` will give last run date which can then be used to pick CDC records daily
    
  );
  
2021-06-05 20:11:38.698507 (Thread-1): finished collecting timing info
2021-06-05 20:11:38.699103 (Thread-1): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '0e424a98-bbf0-4df7-a20a-bb7004724a27', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fd33fad5410>]}
2021-06-05 20:11:38.699574 (Thread-1): 01:11:38 | 1 of 1 OK created incremental model events_information.dim_professional [CREATE TABLE (1.5k rows, 97.0 KB processed) in 3.87s]
2021-06-05 20:11:38.699774 (Thread-1): Finished running node model.werkspot_technical_challenge.dim_professional
2021-06-05 20:11:38.728816 (MainThread): Acquiring new bigquery connection "master".
2021-06-05 20:11:38.729459 (MainThread): 01:11:38 | 
2021-06-05 20:11:38.729716 (MainThread): 01:11:38 | Finished running 1 incremental model in 7.75s.
2021-06-05 20:11:38.729970 (MainThread): Connection 'master' was properly closed.
2021-06-05 20:11:38.730180 (MainThread): Connection 'model.werkspot_technical_challenge.dim_professional' was properly closed.
2021-06-05 20:11:38.741843 (MainThread): 
2021-06-05 20:11:38.742192 (MainThread): Completed successfully
2021-06-05 20:11:38.742425 (MainThread): 
Done. PASS=1 WARN=0 ERROR=0 SKIP=0 TOTAL=1
2021-06-05 20:11:38.742787 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fd33fade250>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fd33fd512d0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fd33fad5410>]}
2021-06-05 20:11:38.743045 (MainThread): Flushing usage events
2021-06-05 20:17:40.752411 (MainThread): Running with dbt=0.19.1
2021-06-05 20:17:41.677363 (MainThread): running dbt with arguments Namespace(cls=<class 'dbt.task.compile.CompileTask'>, debug=False, defer=None, exclude=None, full_refresh=False, log_cache_events=False, log_format='default', models=None, parse_only=False, partial_parse=None, profile=None, profiles_dir='/Users/mac/.dbt', project_dir=None, record_timing_info=None, rpc_method='compile', selector_name=None, single_threaded=False, state=None, strict=False, target=None, test_new_parser=False, threads=None, use_cache=True, use_colors=None, vars='{}', version_check=True, warn_error=False, which='compile', write_json=True)
2021-06-05 20:17:41.679381 (MainThread): Tracking: tracking
2021-06-05 20:17:41.692945 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fdefaff2e50>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fdefaff2e10>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fdefaff2110>]}
2021-06-05 20:17:41.706977 (MainThread): Partial parsing not enabled
2021-06-05 20:17:41.708638 (MainThread): Parsing macros/etc.sql
2021-06-05 20:17:41.712891 (MainThread): Parsing macros/catalog.sql
2021-06-05 20:17:41.722501 (MainThread): Parsing macros/adapters.sql
2021-06-05 20:17:41.751348 (MainThread): Parsing macros/materializations/seed.sql
2021-06-05 20:17:41.755264 (MainThread): Parsing macros/materializations/view.sql
2021-06-05 20:17:41.759293 (MainThread): Parsing macros/materializations/table.sql
2021-06-05 20:17:41.775782 (MainThread): Parsing macros/materializations/copy.sql
2021-06-05 20:17:41.783180 (MainThread): Parsing macros/materializations/incremental.sql
2021-06-05 20:17:41.804263 (MainThread): Parsing macros/materializations/snapshot.sql
2021-06-05 20:17:41.808427 (MainThread): Parsing macros/core.sql
2021-06-05 20:17:41.814519 (MainThread): Parsing macros/materializations/helpers.sql
2021-06-05 20:17:41.827606 (MainThread): Parsing macros/materializations/snapshot/snapshot_merge.sql
2021-06-05 20:17:41.830230 (MainThread): Parsing macros/materializations/snapshot/strategies.sql
2021-06-05 20:17:41.854450 (MainThread): Parsing macros/materializations/snapshot/snapshot.sql
2021-06-05 20:17:41.899004 (MainThread): Parsing macros/materializations/seed/seed.sql
2021-06-05 20:17:41.927780 (MainThread): Parsing macros/materializations/incremental/helpers.sql
2021-06-05 20:17:41.930615 (MainThread): Parsing macros/materializations/incremental/incremental.sql
2021-06-05 20:17:41.939204 (MainThread): Parsing macros/materializations/common/merge.sql
2021-06-05 20:17:41.958421 (MainThread): Parsing macros/materializations/table/table.sql
2021-06-05 20:17:41.967777 (MainThread): Parsing macros/materializations/view/view.sql
2021-06-05 20:17:41.976849 (MainThread): Parsing macros/materializations/view/create_or_replace_view.sql
2021-06-05 20:17:41.984475 (MainThread): Parsing macros/etc/get_custom_alias.sql
2021-06-05 20:17:41.985958 (MainThread): Parsing macros/etc/query.sql
2021-06-05 20:17:41.987436 (MainThread): Parsing macros/etc/is_incremental.sql
2021-06-05 20:17:41.989705 (MainThread): Parsing macros/etc/datetime.sql
2021-06-05 20:17:42.001916 (MainThread): Parsing macros/etc/get_custom_schema.sql
2021-06-05 20:17:42.005190 (MainThread): Parsing macros/etc/get_custom_database.sql
2021-06-05 20:17:42.008441 (MainThread): Parsing macros/adapters/common.sql
2021-06-05 20:17:42.069619 (MainThread): Parsing macros/schema_tests/relationships.sql
2021-06-05 20:17:42.072911 (MainThread): Parsing macros/schema_tests/not_null.sql
2021-06-05 20:17:42.075431 (MainThread): Parsing macros/schema_tests/unique.sql
2021-06-05 20:17:42.078079 (MainThread): Parsing macros/schema_tests/accepted_values.sql
2021-06-05 20:17:42.088481 (MainThread): Partial parsing not enabled
2021-06-05 20:17:42.121915 (MainThread): Acquiring new bigquery connection "model.werkspot_technical_challenge.dim_service".
2021-06-05 20:17:42.142996 (MainThread): Acquiring new bigquery connection "model.werkspot_technical_challenge.dim_professional".
2021-06-05 20:17:42.150348 (MainThread): Acquiring new bigquery connection "model.werkspot_technical_challenge.fct_fee".
2021-06-05 20:17:42.158127 (MainThread): Acquiring new bigquery connection "model.werkspot_technical_challenge.event_logs_stg".
2021-06-05 20:17:42.223644 (MainThread): Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '8204412b-1488-4487-8d28-b4fcbbf6ad4e', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fdefb1cb110>]}
2021-06-05 20:17:42.239614 (MainThread): Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '8204412b-1488-4487-8d28-b4fcbbf6ad4e', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fdefb431b10>]}
2021-06-05 20:17:42.240122 (MainThread): Found 4 models, 0 tests, 0 snapshots, 0 analyses, 156 macros, 0 operations, 0 seed files, 0 sources, 0 exposures
2021-06-05 20:17:42.241535 (MainThread): 
2021-06-05 20:17:42.241963 (MainThread): Acquiring new bigquery connection "master".
2021-06-05 20:17:42.243069 (ThreadPoolExecutor-0_0): Acquiring new bigquery connection "list_poetic-genius-315513_events_information".
2021-06-05 20:17:42.243332 (ThreadPoolExecutor-0_0): Opening a new connection, currently in state init
2021-06-05 20:17:43.130745 (ThreadPoolExecutor-0_0): Client.dataset is deprecated and will be removed in a future version. Use a string like 'my_project.my_dataset' or a cloud.google.bigquery.DatasetReference object, instead.
2021-06-05 20:17:44.982306 (MainThread): 01:17:44 | Concurrency: 1 threads (target='dev')
2021-06-05 20:17:44.982635 (MainThread): 01:17:44 | 
2021-06-05 20:17:44.985102 (Thread-1): Began running node model.werkspot_technical_challenge.event_logs_stg
2021-06-05 20:17:44.985647 (Thread-1): Acquiring new bigquery connection "model.werkspot_technical_challenge.event_logs_stg".
2021-06-05 20:17:44.985873 (Thread-1): Compiling model.werkspot_technical_challenge.event_logs_stg
2021-06-05 20:17:44.988326 (Thread-1): unclosed <socket.socket fd=12, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('192.168.0.104', 61244), raddr=('142.250.185.42', 443)>
2021-06-05 20:17:44.988587 (Thread-1): unclosed <socket.socket fd=11, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('192.168.0.104', 61243), raddr=('172.217.18.138', 443)>
2021-06-05 20:17:44.996395 (Thread-1): Writing injected SQL for node "model.werkspot_technical_challenge.event_logs_stg"
2021-06-05 20:17:44.996986 (Thread-1): finished collecting timing info
2021-06-05 20:17:44.997232 (Thread-1): finished collecting timing info
2021-06-05 20:17:44.997608 (Thread-1): Finished running node model.werkspot_technical_challenge.event_logs_stg
2021-06-05 20:17:44.997784 (Thread-1): Began running node model.werkspot_technical_challenge.dim_service
2021-06-05 20:17:44.998246 (Thread-1): Acquiring new bigquery connection "model.werkspot_technical_challenge.dim_service".
2021-06-05 20:17:44.998489 (Thread-1): Compiling model.werkspot_technical_challenge.dim_service
2021-06-05 20:17:45.003052 (Thread-1): Writing injected SQL for node "model.werkspot_technical_challenge.dim_service"
2021-06-05 20:17:45.004140 (Thread-1): finished collecting timing info
2021-06-05 20:17:45.004365 (Thread-1): finished collecting timing info
2021-06-05 20:17:45.004765 (Thread-1): Finished running node model.werkspot_technical_challenge.dim_service
2021-06-05 20:17:45.004947 (Thread-1): Began running node model.werkspot_technical_challenge.fct_fee
2021-06-05 20:17:45.005374 (Thread-1): Acquiring new bigquery connection "model.werkspot_technical_challenge.fct_fee".
2021-06-05 20:17:45.005524 (Thread-1): Compiling model.werkspot_technical_challenge.fct_fee
2021-06-05 20:17:45.010651 (Thread-1): Writing injected SQL for node "model.werkspot_technical_challenge.fct_fee"
2021-06-05 20:17:45.011179 (Thread-1): finished collecting timing info
2021-06-05 20:17:45.011362 (Thread-1): finished collecting timing info
2021-06-05 20:17:45.011695 (Thread-1): Finished running node model.werkspot_technical_challenge.fct_fee
2021-06-05 20:17:45.011856 (Thread-1): Began running node model.werkspot_technical_challenge.dim_professional
2021-06-05 20:17:45.012233 (Thread-1): Acquiring new bigquery connection "model.werkspot_technical_challenge.dim_professional".
2021-06-05 20:17:45.012383 (Thread-1): Compiling model.werkspot_technical_challenge.dim_professional
2021-06-05 20:17:45.018566 (Thread-1): Writing injected SQL for node "model.werkspot_technical_challenge.dim_professional"
2021-06-05 20:17:45.019250 (Thread-1): finished collecting timing info
2021-06-05 20:17:45.019490 (Thread-1): finished collecting timing info
2021-06-05 20:17:45.019919 (Thread-1): Finished running node model.werkspot_technical_challenge.dim_professional
2021-06-05 20:17:45.086605 (MainThread): Connection 'master' was properly closed.
2021-06-05 20:17:45.086898 (MainThread): Connection 'model.werkspot_technical_challenge.dim_professional' was properly closed.
2021-06-05 20:17:45.098482 (MainThread): 01:17:45 | Done.
2021-06-05 20:17:45.098908 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fdefb1dd390>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fdefb4678d0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fdefb602650>]}
2021-06-05 20:17:45.099280 (MainThread): Flushing usage events
2021-06-05 20:18:39.722711 (MainThread): Running with dbt=0.19.1
2021-06-05 20:18:40.603197 (MainThread): running dbt with arguments Namespace(cls=<class 'dbt.task.run.RunTask'>, debug=False, defer=None, exclude=None, fail_fast=False, full_refresh=False, log_cache_events=False, log_format='default', models=['dim_service', 'dim_professional'], partial_parse=None, profile=None, profiles_dir='/Users/mac/.dbt', project_dir=None, record_timing_info=None, rpc_method='run', selector_name=None, single_threaded=False, state=None, strict=False, target=None, test_new_parser=False, threads=None, use_cache=True, use_colors=None, vars='{}', version_check=True, warn_error=False, which='run', write_json=True)
2021-06-05 20:18:40.605241 (MainThread): Tracking: tracking
2021-06-05 20:18:40.616090 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7feac47db190>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7feac47db590>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7feac47db490>]}
2021-06-05 20:18:40.633199 (MainThread): Partial parsing not enabled
2021-06-05 20:18:40.634569 (MainThread): Parsing macros/etc.sql
2021-06-05 20:18:40.638774 (MainThread): Parsing macros/catalog.sql
2021-06-05 20:18:40.647630 (MainThread): Parsing macros/adapters.sql
2021-06-05 20:18:40.676506 (MainThread): Parsing macros/materializations/seed.sql
2021-06-05 20:18:40.680470 (MainThread): Parsing macros/materializations/view.sql
2021-06-05 20:18:40.684344 (MainThread): Parsing macros/materializations/table.sql
2021-06-05 20:18:40.698501 (MainThread): Parsing macros/materializations/copy.sql
2021-06-05 20:18:40.704494 (MainThread): Parsing macros/materializations/incremental.sql
2021-06-05 20:18:40.722677 (MainThread): Parsing macros/materializations/snapshot.sql
2021-06-05 20:18:40.726500 (MainThread): Parsing macros/core.sql
2021-06-05 20:18:40.731634 (MainThread): Parsing macros/materializations/helpers.sql
2021-06-05 20:18:40.743571 (MainThread): Parsing macros/materializations/snapshot/snapshot_merge.sql
2021-06-05 20:18:40.745987 (MainThread): Parsing macros/materializations/snapshot/strategies.sql
2021-06-05 20:18:40.770059 (MainThread): Parsing macros/materializations/snapshot/snapshot.sql
2021-06-05 20:18:40.814550 (MainThread): Parsing macros/materializations/seed/seed.sql
2021-06-05 20:18:40.843043 (MainThread): Parsing macros/materializations/incremental/helpers.sql
2021-06-05 20:18:40.845516 (MainThread): Parsing macros/materializations/incremental/incremental.sql
2021-06-05 20:18:40.853886 (MainThread): Parsing macros/materializations/common/merge.sql
2021-06-05 20:18:40.872910 (MainThread): Parsing macros/materializations/table/table.sql
2021-06-05 20:18:40.882162 (MainThread): Parsing macros/materializations/view/view.sql
2021-06-05 20:18:40.890953 (MainThread): Parsing macros/materializations/view/create_or_replace_view.sql
2021-06-05 20:18:40.897512 (MainThread): Parsing macros/etc/get_custom_alias.sql
2021-06-05 20:18:40.898855 (MainThread): Parsing macros/etc/query.sql
2021-06-05 20:18:40.900261 (MainThread): Parsing macros/etc/is_incremental.sql
2021-06-05 20:18:40.902413 (MainThread): Parsing macros/etc/datetime.sql
2021-06-05 20:18:40.914820 (MainThread): Parsing macros/etc/get_custom_schema.sql
2021-06-05 20:18:40.917505 (MainThread): Parsing macros/etc/get_custom_database.sql
2021-06-05 20:18:40.919763 (MainThread): Parsing macros/adapters/common.sql
2021-06-05 20:18:40.979126 (MainThread): Parsing macros/schema_tests/relationships.sql
2021-06-05 20:18:40.981733 (MainThread): Parsing macros/schema_tests/not_null.sql
2021-06-05 20:18:40.983777 (MainThread): Parsing macros/schema_tests/unique.sql
2021-06-05 20:18:40.986035 (MainThread): Parsing macros/schema_tests/accepted_values.sql
2021-06-05 20:18:40.996077 (MainThread): Partial parsing not enabled
2021-06-05 20:18:41.028704 (MainThread): Acquiring new bigquery connection "model.werkspot_technical_challenge.dim_service".
2021-06-05 20:18:41.048095 (MainThread): Acquiring new bigquery connection "model.werkspot_technical_challenge.dim_professional".
2021-06-05 20:18:41.054822 (MainThread): Acquiring new bigquery connection "model.werkspot_technical_challenge.fct_fee".
2021-06-05 20:18:41.061347 (MainThread): Acquiring new bigquery connection "model.werkspot_technical_challenge.event_logs_stg".
2021-06-05 20:18:41.127387 (MainThread): Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '5dbe82ca-bb3b-4649-8ded-0baeeb8647a4', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7feac499e3d0>]}
2021-06-05 20:18:41.143755 (MainThread): Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '5dbe82ca-bb3b-4649-8ded-0baeeb8647a4', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7feac4afc890>]}
2021-06-05 20:18:41.144180 (MainThread): Found 4 models, 0 tests, 0 snapshots, 0 analyses, 156 macros, 0 operations, 0 seed files, 0 sources, 0 exposures
2021-06-05 20:18:41.145172 (MainThread): 
2021-06-05 20:18:41.145647 (MainThread): Acquiring new bigquery connection "master".
2021-06-05 20:18:41.146791 (ThreadPoolExecutor-0_0): Acquiring new bigquery connection "list_poetic-genius-315513".
2021-06-05 20:18:41.147099 (ThreadPoolExecutor-0_0): Opening a new connection, currently in state init
2021-06-05 20:18:43.474288 (ThreadPoolExecutor-1_0): Acquiring new bigquery connection "list_poetic-genius-315513_events_information".
2021-06-05 20:18:43.474658 (ThreadPoolExecutor-1_0): Opening a new connection, currently in state closed
2021-06-05 20:18:43.474938 (ThreadPoolExecutor-1_0): Client.dataset is deprecated and will be removed in a future version. Use a string like 'my_project.my_dataset' or a cloud.google.bigquery.DatasetReference object, instead.
2021-06-05 20:18:44.696028 (MainThread): 01:18:44 | Concurrency: 1 threads (target='dev')
2021-06-05 20:18:44.696395 (MainThread): 01:18:44 | 
2021-06-05 20:18:44.698610 (Thread-1): Began running node model.werkspot_technical_challenge.dim_professional
2021-06-05 20:18:44.699005 (Thread-1): 01:18:44 | 1 of 2 START incremental model events_information.dim_professional... [RUN]
2021-06-05 20:18:44.699482 (Thread-1): Acquiring new bigquery connection "model.werkspot_technical_challenge.dim_professional".
2021-06-05 20:18:44.699683 (Thread-1): Compiling model.werkspot_technical_challenge.dim_professional
2021-06-05 20:18:44.700968 (Thread-1): unclosed <socket.socket fd=12, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('192.168.0.104', 61269), raddr=('142.250.185.42', 443)>
2021-06-05 20:18:44.701224 (Thread-1): unclosed <socket.socket fd=11, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('192.168.0.104', 61268), raddr=('172.217.18.138', 443)>
2021-06-05 20:18:44.701420 (Thread-1): unclosed <socket.socket fd=13, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('192.168.0.104', 61270), raddr=('142.250.185.42', 443)>
2021-06-05 20:18:44.708069 (Thread-1): Writing injected SQL for node "model.werkspot_technical_challenge.dim_professional"
2021-06-05 20:18:44.708666 (Thread-1): finished collecting timing info
2021-06-05 20:18:44.779015 (Thread-1): Writing runtime SQL for node "model.werkspot_technical_challenge.dim_professional"
2021-06-05 20:18:44.779641 (Thread-1): Opening a new connection, currently in state closed
2021-06-05 20:18:44.779847 (Thread-1): On model.werkspot_technical_challenge.dim_professional: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "werkspot_technical_challenge", "target_name": "dev", "node_id": "model.werkspot_technical_challenge.dim_professional"} */


  create or replace table `poetic-genius-315513`.`events_information`.`dim_professional`
  partition by datetime_trunc(AuditCreatedDateTime, day)
  
  OPTIONS()
  as (
    


SELECT
  
  DISTINCT

    ProfessionalID,
    CURRENT_DATETIME() as AuditCreatedDateTime,  -- Audit Column, Used for Partitioning & Filtering Day in daily runs

FROM 

  `poetic-genius-315513`.`events_information`.`event_logs_stg`
      
    -- this will only be applied on an incremental run & will filter data early
    -- `poetic-genius-315513`.`events_information`.`dim_professional` will give last run date which can then be used to pick CDC records daily
    
  );
  
2021-06-05 20:18:49.394705 (Thread-1): finished collecting timing info
2021-06-05 20:18:49.395286 (Thread-1): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '5dbe82ca-bb3b-4649-8ded-0baeeb8647a4', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7feac49bc050>]}
2021-06-05 20:18:49.395808 (Thread-1): 01:18:49 | 1 of 2 OK created incremental model events_information.dim_professional [CREATE TABLE (1.5k rows, 97.0 KB processed) in 4.70s]
2021-06-05 20:18:49.395999 (Thread-1): Finished running node model.werkspot_technical_challenge.dim_professional
2021-06-05 20:18:49.396250 (Thread-1): Began running node model.werkspot_technical_challenge.dim_service
2021-06-05 20:18:49.396654 (Thread-1): 01:18:49 | 2 of 2 START incremental model events_information.dim_service........ [RUN]
2021-06-05 20:18:49.397031 (Thread-1): Acquiring new bigquery connection "model.werkspot_technical_challenge.dim_service".
2021-06-05 20:18:49.397175 (Thread-1): Compiling model.werkspot_technical_challenge.dim_service
2021-06-05 20:18:49.401911 (Thread-1): Writing injected SQL for node "model.werkspot_technical_challenge.dim_service"
2021-06-05 20:18:49.402393 (Thread-1): finished collecting timing info
2021-06-05 20:18:49.405870 (Thread-1): Writing runtime SQL for node "model.werkspot_technical_challenge.dim_service"
2021-06-05 20:18:49.406392 (Thread-1): Opening a new connection, currently in state closed
2021-06-05 20:18:49.406579 (Thread-1): On model.werkspot_technical_challenge.dim_service: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "werkspot_technical_challenge", "target_name": "dev", "node_id": "model.werkspot_technical_challenge.dim_service"} */


  create or replace table `poetic-genius-315513`.`events_information`.`dim_service`
  partition by datetime_trunc(AuditCreatedDateTime, day)
  
  OPTIONS()
  as (
    


SELECT

  DISTINCT 

    CAST(ParsedMetdata[OFFSET(0)] AS STRING) AS ServiceID,
    ParsedMetdata[OFFSET(1)] AS ServiceNameDutch,
    ParsedMetdata[OFFSET(2)] AS ServiceNameEnglish,
    CURRENT_DATETIME() as AuditCreatedDateTime, -- Audit Column, Used for Partitioning & Filtering Day in daily runs

FROM 
(
  SELECT 
    
    SPLIT(Metadata,'_') AS ParsedMetdata
  
  FROM 
    `poetic-genius-315513.events_information.event_logs_stg`

    -- this will only be applied on an incremental run & will filter data early
    -- `poetic-genius-315513`.`events_information`.`dim_service` will give last run date which can then be used to pick CDC records daily
    
  
    AND Metadata!=''
)
  );
  
2021-06-05 20:18:50.748504 (Thread-1): Retry attempt 1 of 1 after error: BadRequest('Syntax error: Expected ")" but got keyword AND at [34:5]')
2021-06-05 20:18:51.387169 (Thread-1): finished collecting timing info
2021-06-05 20:18:51.387888 (Thread-1): Database Error in model dim_service (models/Dimensions/dim_service.sql)
  Syntax error: Expected ")" but got keyword AND at [34:5]
  compiled SQL at target/run/werkspot_technical_challenge/models/Dimensions/dim_service.sql
Traceback (most recent call last):
  File "/opt/anaconda3/lib/python3.7/site-packages/dbt/adapters/bigquery/connections.py", line 149, in exception_handler
    yield
  File "/opt/anaconda3/lib/python3.7/site-packages/dbt/adapters/bigquery/connections.py", line 539, in _retry_and_handle
    on_error=reopen_conn_on_error)
  File "/opt/anaconda3/lib/python3.7/site-packages/google/api_core/retry.py", line 184, in retry_target
    return target()
  File "/opt/anaconda3/lib/python3.7/site-packages/dbt/adapters/bigquery/connections.py", line 327, in fn
    return self._query_and_results(client, sql, conn, job_params)
  File "/opt/anaconda3/lib/python3.7/site-packages/dbt/adapters/bigquery/connections.py", line 520, in _query_and_results
    iterator = query_job.result(timeout=timeout)
  File "/opt/anaconda3/lib/python3.7/site-packages/google/cloud/bigquery/job.py", line 3207, in result
    super(QueryJob, self).result(retry=retry, timeout=timeout)
  File "/opt/anaconda3/lib/python3.7/site-packages/google/cloud/bigquery/job.py", line 812, in result
    return super(_AsyncJob, self).result(timeout=timeout)
  File "/opt/anaconda3/lib/python3.7/site-packages/google/api_core/future/polling.py", line 130, in result
    raise self._exception
google.api_core.exceptions.BadRequest: 400 Syntax error: Expected ")" but got keyword AND at [34:5]

(job ID: 741c732c-14cc-416f-8166-0ca4e08aaf0c)

                                                                           -----Query Job SQL Follows-----                                                                           

    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |
   1:/* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "werkspot_technical_challenge", "target_name": "dev", "node_id": "model.werkspot_technical_challenge.dim_service"} */
   2:
   3:
   4:  create or replace table `poetic-genius-315513`.`events_information`.`dim_service`
   5:  partition by datetime_trunc(AuditCreatedDateTime, day)
   6:  
   7:  OPTIONS()
   8:  as (
   9:    
  10:
  11:
  12:SELECT
  13:
  14:  DISTINCT 
  15:
  16:    CAST(ParsedMetdata[OFFSET(0)] AS STRING) AS ServiceID,
  17:    ParsedMetdata[OFFSET(1)] AS ServiceNameDutch,
  18:    ParsedMetdata[OFFSET(2)] AS ServiceNameEnglish,
  19:    CURRENT_DATETIME() as AuditCreatedDateTime, -- Audit Column, Used for Partitioning & Filtering Day in daily runs
  20:
  21:FROM 
  22:(
  23:  SELECT 
  24:    
  25:    SPLIT(Metadata,'_') AS ParsedMetdata
  26:  
  27:  FROM 
  28:    `poetic-genius-315513.events_information.event_logs_stg`
  29:
  30:    -- this will only be applied on an incremental run & will filter data early
  31:    -- `poetic-genius-315513`.`events_information`.`dim_service` will give last run date which can then be used to pick CDC records daily
  32:    
  33:  
  34:    AND Metadata!=''
  35:)
  36:  );
  37:  
    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/anaconda3/lib/python3.7/site-packages/dbt/task/base.py", line 344, in safe_run
    result = self.compile_and_execute(manifest, ctx)
  File "/opt/anaconda3/lib/python3.7/site-packages/dbt/task/base.py", line 287, in compile_and_execute
    result = self.run(ctx.node, manifest)
  File "/opt/anaconda3/lib/python3.7/site-packages/dbt/task/base.py", line 389, in run
    return self.execute(compiled_node, manifest)
  File "/opt/anaconda3/lib/python3.7/site-packages/dbt/task/run.py", line 248, in execute
    result = MacroGenerator(materialization_macro, context)()
  File "/opt/anaconda3/lib/python3.7/site-packages/dbt/clients/jinja.py", line 332, in __call__
    return self.call_macro(*args, **kwargs)
  File "/opt/anaconda3/lib/python3.7/site-packages/dbt/clients/jinja.py", line 259, in call_macro
    return macro(*args, **kwargs)
  File "/opt/anaconda3/lib/python3.7/site-packages/jinja2/runtime.py", line 675, in __call__
    return self._invoke(arguments, autoescape)
  File "/opt/anaconda3/lib/python3.7/site-packages/jinja2/runtime.py", line 679, in _invoke
    rv = self._func(*arguments)
  File "<template>", line 156, in macro
  File "/opt/anaconda3/lib/python3.7/site-packages/jinja2/sandbox.py", line 462, in call
    return __context.call(__obj, *args, **kwargs)
  File "/opt/anaconda3/lib/python3.7/site-packages/jinja2/runtime.py", line 290, in call
    return __obj(*args, **kwargs)
  File "/opt/anaconda3/lib/python3.7/site-packages/dbt/clients/jinja.py", line 332, in __call__
    return self.call_macro(*args, **kwargs)
  File "/opt/anaconda3/lib/python3.7/site-packages/dbt/clients/jinja.py", line 259, in call_macro
    return macro(*args, **kwargs)
  File "/opt/anaconda3/lib/python3.7/site-packages/jinja2/runtime.py", line 675, in __call__
    return self._invoke(arguments, autoescape)
  File "/opt/anaconda3/lib/python3.7/site-packages/jinja2/runtime.py", line 679, in _invoke
    rv = self._func(*arguments)
  File "<template>", line 41, in macro
  File "/opt/anaconda3/lib/python3.7/site-packages/jinja2/sandbox.py", line 462, in call
    return __context.call(__obj, *args, **kwargs)
  File "/opt/anaconda3/lib/python3.7/site-packages/jinja2/runtime.py", line 290, in call
    return __obj(*args, **kwargs)
  File "/opt/anaconda3/lib/python3.7/site-packages/dbt/adapters/base/impl.py", line 230, in execute
    fetch=fetch
  File "/opt/anaconda3/lib/python3.7/site-packages/dbt/adapters/bigquery/connections.py", line 338, in execute
    query_job, iterator = self.raw_execute(sql, fetch=fetch)
  File "/opt/anaconda3/lib/python3.7/site-packages/dbt/adapters/bigquery/connections.py", line 329, in raw_execute
    query_job, iterator = self._retry_and_handle(msg=sql, conn=conn, fn=fn)
  File "/opt/anaconda3/lib/python3.7/site-packages/dbt/adapters/bigquery/connections.py", line 539, in _retry_and_handle
    on_error=reopen_conn_on_error)
  File "/opt/anaconda3/lib/python3.7/contextlib.py", line 130, in __exit__
    self.gen.throw(type, value, traceback)
  File "/opt/anaconda3/lib/python3.7/site-packages/dbt/adapters/bigquery/connections.py", line 153, in exception_handler
    self.handle_error(e, message)
  File "/opt/anaconda3/lib/python3.7/site-packages/dbt/adapters/bigquery/connections.py", line 141, in handle_error
    raise DatabaseException(error_msg)
dbt.exceptions.DatabaseException: Database Error in model dim_service (models/Dimensions/dim_service.sql)
  Syntax error: Expected ")" but got keyword AND at [34:5]
  compiled SQL at target/run/werkspot_technical_challenge/models/Dimensions/dim_service.sql
2021-06-05 20:18:51.398087 (Thread-1): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '5dbe82ca-bb3b-4649-8ded-0baeeb8647a4', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7feac4a9f590>]}
2021-06-05 20:18:51.398535 (Thread-1): 01:18:51 | 2 of 2 ERROR creating incremental model events_information.dim_service [ERROR in 2.00s]
2021-06-05 20:18:51.398713 (Thread-1): Finished running node model.werkspot_technical_challenge.dim_service
2021-06-05 20:18:51.494893 (MainThread): Acquiring new bigquery connection "master".
2021-06-05 20:18:51.495558 (MainThread): 01:18:51 | 
2021-06-05 20:18:51.495818 (MainThread): 01:18:51 | Finished running 2 incremental models in 10.35s.
2021-06-05 20:18:51.496068 (MainThread): Connection 'master' was properly closed.
2021-06-05 20:18:51.496238 (MainThread): Connection 'model.werkspot_technical_challenge.dim_service' was properly closed.
2021-06-05 20:18:51.507099 (MainThread): 
2021-06-05 20:18:51.507364 (MainThread): Completed with 1 error and 0 warnings:
2021-06-05 20:18:51.507643 (MainThread): 
2021-06-05 20:18:51.507858 (MainThread): Database Error in model dim_service (models/Dimensions/dim_service.sql)
2021-06-05 20:18:51.508074 (MainThread):   Syntax error: Expected ")" but got keyword AND at [34:5]
2021-06-05 20:18:51.508258 (MainThread):   compiled SQL at target/run/werkspot_technical_challenge/models/Dimensions/dim_service.sql
2021-06-05 20:18:51.508433 (MainThread): 
Done. PASS=1 WARN=0 ERROR=1 SKIP=0 TOTAL=2
2021-06-05 20:18:51.508728 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7feac4cec510>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7feac2e77bd0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7feac4a9f590>]}
2021-06-05 20:18:51.508979 (MainThread): Flushing usage events
2021-06-05 20:20:38.557268 (MainThread): Running with dbt=0.19.1
2021-06-05 20:20:39.560947 (MainThread): running dbt with arguments Namespace(cls=<class 'dbt.task.run.RunTask'>, debug=False, defer=None, exclude=None, fail_fast=False, full_refresh=False, log_cache_events=False, log_format='default', models=['dim_service'], partial_parse=None, profile=None, profiles_dir='/Users/mac/.dbt', project_dir=None, record_timing_info=None, rpc_method='run', selector_name=None, single_threaded=False, state=None, strict=False, target=None, test_new_parser=False, threads=None, use_cache=True, use_colors=None, vars='{}', version_check=True, warn_error=False, which='run', write_json=True)
2021-06-05 20:20:39.562608 (MainThread): Tracking: tracking
2021-06-05 20:20:39.573483 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fd9e47df950>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fd9e47ee450>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fd9e47ee1d0>]}
2021-06-05 20:20:39.587688 (MainThread): Partial parsing not enabled
2021-06-05 20:20:39.589460 (MainThread): Parsing macros/etc.sql
2021-06-05 20:20:39.594673 (MainThread): Parsing macros/catalog.sql
2021-06-05 20:20:39.603495 (MainThread): Parsing macros/adapters.sql
2021-06-05 20:20:39.632986 (MainThread): Parsing macros/materializations/seed.sql
2021-06-05 20:20:39.637144 (MainThread): Parsing macros/materializations/view.sql
2021-06-05 20:20:39.641415 (MainThread): Parsing macros/materializations/table.sql
2021-06-05 20:20:39.654738 (MainThread): Parsing macros/materializations/copy.sql
2021-06-05 20:20:39.661452 (MainThread): Parsing macros/materializations/incremental.sql
2021-06-05 20:20:39.679138 (MainThread): Parsing macros/materializations/snapshot.sql
2021-06-05 20:20:39.686098 (MainThread): Parsing macros/core.sql
2021-06-05 20:20:39.691639 (MainThread): Parsing macros/materializations/helpers.sql
2021-06-05 20:20:39.704060 (MainThread): Parsing macros/materializations/snapshot/snapshot_merge.sql
2021-06-05 20:20:39.706972 (MainThread): Parsing macros/materializations/snapshot/strategies.sql
2021-06-05 20:20:39.732333 (MainThread): Parsing macros/materializations/snapshot/snapshot.sql
2021-06-05 20:20:39.778113 (MainThread): Parsing macros/materializations/seed/seed.sql
2021-06-05 20:20:39.808419 (MainThread): Parsing macros/materializations/incremental/helpers.sql
2021-06-05 20:20:39.812840 (MainThread): Parsing macros/materializations/incremental/incremental.sql
2021-06-05 20:20:39.822726 (MainThread): Parsing macros/materializations/common/merge.sql
2021-06-05 20:20:39.841777 (MainThread): Parsing macros/materializations/table/table.sql
2021-06-05 20:20:39.851320 (MainThread): Parsing macros/materializations/view/view.sql
2021-06-05 20:20:39.860102 (MainThread): Parsing macros/materializations/view/create_or_replace_view.sql
2021-06-05 20:20:39.867734 (MainThread): Parsing macros/etc/get_custom_alias.sql
2021-06-05 20:20:39.869468 (MainThread): Parsing macros/etc/query.sql
2021-06-05 20:20:39.871104 (MainThread): Parsing macros/etc/is_incremental.sql
2021-06-05 20:20:39.873714 (MainThread): Parsing macros/etc/datetime.sql
2021-06-05 20:20:39.885789 (MainThread): Parsing macros/etc/get_custom_schema.sql
2021-06-05 20:20:39.888492 (MainThread): Parsing macros/etc/get_custom_database.sql
2021-06-05 20:20:39.890806 (MainThread): Parsing macros/adapters/common.sql
2021-06-05 20:20:39.949197 (MainThread): Parsing macros/schema_tests/relationships.sql
2021-06-05 20:20:39.952205 (MainThread): Parsing macros/schema_tests/not_null.sql
2021-06-05 20:20:39.954578 (MainThread): Parsing macros/schema_tests/unique.sql
2021-06-05 20:20:39.957998 (MainThread): Parsing macros/schema_tests/accepted_values.sql
2021-06-05 20:20:39.969541 (MainThread): Partial parsing not enabled
2021-06-05 20:20:40.005179 (MainThread): Acquiring new bigquery connection "model.werkspot_technical_challenge.dim_service".
2021-06-05 20:20:40.025156 (MainThread): Acquiring new bigquery connection "model.werkspot_technical_challenge.dim_professional".
2021-06-05 20:20:40.032676 (MainThread): Acquiring new bigquery connection "model.werkspot_technical_challenge.fct_fee".
2021-06-05 20:20:40.040779 (MainThread): Acquiring new bigquery connection "model.werkspot_technical_challenge.event_logs_stg".
2021-06-05 20:20:40.111310 (MainThread): Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '59a445c7-0b4c-49b4-9e96-e388288c589d', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fd9e49b96d0>]}
2021-06-05 20:20:40.129689 (MainThread): Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '59a445c7-0b4c-49b4-9e96-e388288c589d', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fd9e4acc350>]}
2021-06-05 20:20:40.130107 (MainThread): Found 4 models, 0 tests, 0 snapshots, 0 analyses, 156 macros, 0 operations, 0 seed files, 0 sources, 0 exposures
2021-06-05 20:20:40.131084 (MainThread): 
2021-06-05 20:20:40.131623 (MainThread): Acquiring new bigquery connection "master".
2021-06-05 20:20:40.132700 (ThreadPoolExecutor-0_0): Acquiring new bigquery connection "list_poetic-genius-315513".
2021-06-05 20:20:40.133002 (ThreadPoolExecutor-0_0): Opening a new connection, currently in state init
2021-06-05 20:20:42.635433 (ThreadPoolExecutor-1_0): Acquiring new bigquery connection "list_poetic-genius-315513_events_information".
2021-06-05 20:20:42.635797 (ThreadPoolExecutor-1_0): Opening a new connection, currently in state closed
2021-06-05 20:20:42.636127 (ThreadPoolExecutor-1_0): Client.dataset is deprecated and will be removed in a future version. Use a string like 'my_project.my_dataset' or a cloud.google.bigquery.DatasetReference object, instead.
2021-06-05 20:20:43.851038 (MainThread): 01:20:43 | Concurrency: 1 threads (target='dev')
2021-06-05 20:20:43.851436 (MainThread): 01:20:43 | 
2021-06-05 20:20:43.854293 (Thread-1): Began running node model.werkspot_technical_challenge.dim_service
2021-06-05 20:20:43.854714 (Thread-1): 01:20:43 | 1 of 1 START incremental model events_information.dim_service........ [RUN]
2021-06-05 20:20:43.855212 (Thread-1): Acquiring new bigquery connection "model.werkspot_technical_challenge.dim_service".
2021-06-05 20:20:43.856622 (Thread-1): unclosed <socket.socket fd=12, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('192.168.0.104', 61318), raddr=('142.250.185.42', 443)>
2021-06-05 20:20:43.856875 (Thread-1): unclosed <socket.socket fd=11, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('192.168.0.104', 61317), raddr=('172.217.18.138', 443)>
2021-06-05 20:20:43.857077 (Thread-1): unclosed <socket.socket fd=13, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('192.168.0.104', 61319), raddr=('142.250.185.42', 443)>
2021-06-05 20:20:43.857545 (Thread-1): Compiling model.werkspot_technical_challenge.dim_service
2021-06-05 20:20:43.863616 (Thread-1): Writing injected SQL for node "model.werkspot_technical_challenge.dim_service"
2021-06-05 20:20:43.864176 (Thread-1): finished collecting timing info
2021-06-05 20:20:43.935847 (Thread-1): Writing runtime SQL for node "model.werkspot_technical_challenge.dim_service"
2021-06-05 20:20:43.936467 (Thread-1): Opening a new connection, currently in state closed
2021-06-05 20:20:43.936675 (Thread-1): On model.werkspot_technical_challenge.dim_service: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "werkspot_technical_challenge", "target_name": "dev", "node_id": "model.werkspot_technical_challenge.dim_service"} */


  create or replace table `poetic-genius-315513`.`events_information`.`dim_service`
  partition by datetime_trunc(AuditCreatedDateTime, day)
  
  OPTIONS()
  as (
    


SELECT

  DISTINCT 

    CAST(ParsedMetdata[OFFSET(0)] AS STRING) AS ServiceID,
    ParsedMetdata[OFFSET(1)] AS ServiceNameDutch,
    ParsedMetdata[OFFSET(2)] AS ServiceNameEnglish,
    CURRENT_DATETIME() as AuditCreatedDateTime, -- Audit Column, Used for Partitioning & Filtering Day in daily runs

FROM 
(
  SELECT 
    
    SPLIT(Metadata,'_') AS ParsedMetdata
  
  FROM 
    `poetic-genius-315513.events_information.event_logs_stg`

    -- this will only be applied on an incremental run & will filter data early
    -- `poetic-genius-315513`.`events_information`.`dim_service` will give last run date which can then be used to pick CDC records daily
    
)
  );
  
2021-06-05 20:20:46.121472 (Thread-1): Retry attempt 1 of 1 after error: BadRequest('GET https://bigquery.googleapis.com/bigquery/v2/projects/poetic-genius-315513/queries/0f0dd212-a2fd-4891-a978-924128fb79ff?maxResults=0&location=US: Array index 1 is out of bounds (overflow)')
2021-06-05 20:20:47.349919 (Thread-1): finished collecting timing info
2021-06-05 20:20:47.350644 (Thread-1): Database Error in model dim_service (models/Dimensions/dim_service.sql)
  Array index 1 is out of bounds (overflow)
  compiled SQL at target/run/werkspot_technical_challenge/models/Dimensions/dim_service.sql
Traceback (most recent call last):
  File "/opt/anaconda3/lib/python3.7/site-packages/dbt/adapters/bigquery/connections.py", line 149, in exception_handler
    yield
  File "/opt/anaconda3/lib/python3.7/site-packages/dbt/adapters/bigquery/connections.py", line 539, in _retry_and_handle
    on_error=reopen_conn_on_error)
  File "/opt/anaconda3/lib/python3.7/site-packages/google/api_core/retry.py", line 184, in retry_target
    return target()
  File "/opt/anaconda3/lib/python3.7/site-packages/dbt/adapters/bigquery/connections.py", line 327, in fn
    return self._query_and_results(client, sql, conn, job_params)
  File "/opt/anaconda3/lib/python3.7/site-packages/dbt/adapters/bigquery/connections.py", line 520, in _query_and_results
    iterator = query_job.result(timeout=timeout)
  File "/opt/anaconda3/lib/python3.7/site-packages/google/cloud/bigquery/job.py", line 3207, in result
    super(QueryJob, self).result(retry=retry, timeout=timeout)
  File "/opt/anaconda3/lib/python3.7/site-packages/google/cloud/bigquery/job.py", line 812, in result
    return super(_AsyncJob, self).result(timeout=timeout)
  File "/opt/anaconda3/lib/python3.7/site-packages/google/api_core/future/polling.py", line 125, in result
    self._blocking_poll(timeout=timeout)
  File "/opt/anaconda3/lib/python3.7/site-packages/google/cloud/bigquery/job.py", line 3103, in _blocking_poll
    super(QueryJob, self)._blocking_poll(timeout=timeout)
  File "/opt/anaconda3/lib/python3.7/site-packages/google/api_core/future/polling.py", line 104, in _blocking_poll
    retry_(self._done_or_raise)()
  File "/opt/anaconda3/lib/python3.7/site-packages/google/api_core/retry.py", line 286, in retry_wrapped_func
    on_error=on_error,
  File "/opt/anaconda3/lib/python3.7/site-packages/google/api_core/retry.py", line 184, in retry_target
    return target()
  File "/opt/anaconda3/lib/python3.7/site-packages/google/api_core/future/polling.py", line 83, in _done_or_raise
    if not self.done():
  File "/opt/anaconda3/lib/python3.7/site-packages/google/cloud/bigquery/job.py", line 3089, in done
    timeout=transport_timeout,
  File "/opt/anaconda3/lib/python3.7/site-packages/google/cloud/bigquery/client.py", line 1362, in _get_query_results
    retry, method="GET", path=path, query_params=extra_params, timeout=timeout
  File "/opt/anaconda3/lib/python3.7/site-packages/google/cloud/bigquery/client.py", line 578, in _call_api
    return call()
  File "/opt/anaconda3/lib/python3.7/site-packages/google/api_core/retry.py", line 286, in retry_wrapped_func
    on_error=on_error,
  File "/opt/anaconda3/lib/python3.7/site-packages/google/api_core/retry.py", line 184, in retry_target
    return target()
  File "/opt/anaconda3/lib/python3.7/site-packages/google/cloud/_http.py", line 423, in api_request
    raise exceptions.from_http_response(response)
google.api_core.exceptions.BadRequest: 400 GET https://bigquery.googleapis.com/bigquery/v2/projects/poetic-genius-315513/queries/c337479b-66d5-444d-8d44-ed0dfbf8db81?maxResults=0&location=US: Array index 1 is out of bounds (overflow)

(job ID: c337479b-66d5-444d-8d44-ed0dfbf8db81)

                                                                           -----Query Job SQL Follows-----                                                                           

    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |
   1:/* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "werkspot_technical_challenge", "target_name": "dev", "node_id": "model.werkspot_technical_challenge.dim_service"} */
   2:
   3:
   4:  create or replace table `poetic-genius-315513`.`events_information`.`dim_service`
   5:  partition by datetime_trunc(AuditCreatedDateTime, day)
   6:  
   7:  OPTIONS()
   8:  as (
   9:    
  10:
  11:
  12:SELECT
  13:
  14:  DISTINCT 
  15:
  16:    CAST(ParsedMetdata[OFFSET(0)] AS STRING) AS ServiceID,
  17:    ParsedMetdata[OFFSET(1)] AS ServiceNameDutch,
  18:    ParsedMetdata[OFFSET(2)] AS ServiceNameEnglish,
  19:    CURRENT_DATETIME() as AuditCreatedDateTime, -- Audit Column, Used for Partitioning & Filtering Day in daily runs
  20:
  21:FROM 
  22:(
  23:  SELECT 
  24:    
  25:    SPLIT(Metadata,'_') AS ParsedMetdata
  26:  
  27:  FROM 
  28:    `poetic-genius-315513.events_information.event_logs_stg`
  29:
  30:    -- this will only be applied on an incremental run & will filter data early
  31:    -- `poetic-genius-315513`.`events_information`.`dim_service` will give last run date which can then be used to pick CDC records daily
  32:    
  33:)
  34:  );
  35:  
    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/anaconda3/lib/python3.7/site-packages/dbt/task/base.py", line 344, in safe_run
    result = self.compile_and_execute(manifest, ctx)
  File "/opt/anaconda3/lib/python3.7/site-packages/dbt/task/base.py", line 287, in compile_and_execute
    result = self.run(ctx.node, manifest)
  File "/opt/anaconda3/lib/python3.7/site-packages/dbt/task/base.py", line 389, in run
    return self.execute(compiled_node, manifest)
  File "/opt/anaconda3/lib/python3.7/site-packages/dbt/task/run.py", line 248, in execute
    result = MacroGenerator(materialization_macro, context)()
  File "/opt/anaconda3/lib/python3.7/site-packages/dbt/clients/jinja.py", line 332, in __call__
    return self.call_macro(*args, **kwargs)
  File "/opt/anaconda3/lib/python3.7/site-packages/dbt/clients/jinja.py", line 259, in call_macro
    return macro(*args, **kwargs)
  File "/opt/anaconda3/lib/python3.7/site-packages/jinja2/runtime.py", line 675, in __call__
    return self._invoke(arguments, autoescape)
  File "/opt/anaconda3/lib/python3.7/site-packages/jinja2/runtime.py", line 679, in _invoke
    rv = self._func(*arguments)
  File "<template>", line 156, in macro
  File "/opt/anaconda3/lib/python3.7/site-packages/jinja2/sandbox.py", line 462, in call
    return __context.call(__obj, *args, **kwargs)
  File "/opt/anaconda3/lib/python3.7/site-packages/jinja2/runtime.py", line 290, in call
    return __obj(*args, **kwargs)
  File "/opt/anaconda3/lib/python3.7/site-packages/dbt/clients/jinja.py", line 332, in __call__
    return self.call_macro(*args, **kwargs)
  File "/opt/anaconda3/lib/python3.7/site-packages/dbt/clients/jinja.py", line 259, in call_macro
    return macro(*args, **kwargs)
  File "/opt/anaconda3/lib/python3.7/site-packages/jinja2/runtime.py", line 675, in __call__
    return self._invoke(arguments, autoescape)
  File "/opt/anaconda3/lib/python3.7/site-packages/jinja2/runtime.py", line 679, in _invoke
    rv = self._func(*arguments)
  File "<template>", line 41, in macro
  File "/opt/anaconda3/lib/python3.7/site-packages/jinja2/sandbox.py", line 462, in call
    return __context.call(__obj, *args, **kwargs)
  File "/opt/anaconda3/lib/python3.7/site-packages/jinja2/runtime.py", line 290, in call
    return __obj(*args, **kwargs)
  File "/opt/anaconda3/lib/python3.7/site-packages/dbt/adapters/base/impl.py", line 230, in execute
    fetch=fetch
  File "/opt/anaconda3/lib/python3.7/site-packages/dbt/adapters/bigquery/connections.py", line 338, in execute
    query_job, iterator = self.raw_execute(sql, fetch=fetch)
  File "/opt/anaconda3/lib/python3.7/site-packages/dbt/adapters/bigquery/connections.py", line 329, in raw_execute
    query_job, iterator = self._retry_and_handle(msg=sql, conn=conn, fn=fn)
  File "/opt/anaconda3/lib/python3.7/site-packages/dbt/adapters/bigquery/connections.py", line 539, in _retry_and_handle
    on_error=reopen_conn_on_error)
  File "/opt/anaconda3/lib/python3.7/contextlib.py", line 130, in __exit__
    self.gen.throw(type, value, traceback)
  File "/opt/anaconda3/lib/python3.7/site-packages/dbt/adapters/bigquery/connections.py", line 153, in exception_handler
    self.handle_error(e, message)
  File "/opt/anaconda3/lib/python3.7/site-packages/dbt/adapters/bigquery/connections.py", line 141, in handle_error
    raise DatabaseException(error_msg)
dbt.exceptions.DatabaseException: Database Error in model dim_service (models/Dimensions/dim_service.sql)
  Array index 1 is out of bounds (overflow)
  compiled SQL at target/run/werkspot_technical_challenge/models/Dimensions/dim_service.sql
2021-06-05 20:20:47.362740 (Thread-1): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '59a445c7-0b4c-49b4-9e96-e388288c589d', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fd9e4f10fd0>]}
2021-06-05 20:20:47.363242 (Thread-1): 01:20:47 | 1 of 1 ERROR creating incremental model events_information.dim_service [ERROR in 3.51s]
2021-06-05 20:20:47.363417 (Thread-1): Finished running node model.werkspot_technical_challenge.dim_service
2021-06-05 20:20:47.447842 (MainThread): Acquiring new bigquery connection "master".
2021-06-05 20:20:47.448497 (MainThread): 01:20:47 | 
2021-06-05 20:20:47.448768 (MainThread): 01:20:47 | Finished running 1 incremental model in 7.32s.
2021-06-05 20:20:47.449117 (MainThread): Connection 'master' was properly closed.
2021-06-05 20:20:47.449357 (MainThread): Connection 'model.werkspot_technical_challenge.dim_service' was properly closed.
2021-06-05 20:20:47.466573 (MainThread): 
2021-06-05 20:20:47.466847 (MainThread): Completed with 1 error and 0 warnings:
2021-06-05 20:20:47.467075 (MainThread): 
2021-06-05 20:20:47.467281 (MainThread): Database Error in model dim_service (models/Dimensions/dim_service.sql)
2021-06-05 20:20:47.467450 (MainThread):   Array index 1 is out of bounds (overflow)
2021-06-05 20:20:47.467608 (MainThread):   compiled SQL at target/run/werkspot_technical_challenge/models/Dimensions/dim_service.sql
2021-06-05 20:20:47.467772 (MainThread): 
Done. PASS=0 WARN=0 ERROR=1 SKIP=0 TOTAL=1
2021-06-05 20:20:47.468076 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fd9e47ee750>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fd9e4417050>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fd9e4b37c10>]}
2021-06-05 20:20:47.468352 (MainThread): Flushing usage events
2021-06-05 20:22:30.557969 (MainThread): Running with dbt=0.19.1
2021-06-05 20:22:31.308584 (MainThread): running dbt with arguments Namespace(cls=<class 'dbt.task.run.RunTask'>, debug=False, defer=None, exclude=None, fail_fast=False, full_refresh=False, log_cache_events=False, log_format='default', models=['dim_service'], partial_parse=None, profile=None, profiles_dir='/Users/mac/.dbt', project_dir=None, record_timing_info=None, rpc_method='run', selector_name=None, single_threaded=False, state=None, strict=False, target=None, test_new_parser=False, threads=None, use_cache=True, use_colors=None, vars='{}', version_check=True, warn_error=False, which='run', write_json=True)
2021-06-05 20:22:31.309572 (MainThread): Tracking: tracking
2021-06-05 20:22:31.319735 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f87b310ba50>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f87b310be90>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f87b310b0d0>]}
2021-06-05 20:22:31.334299 (MainThread): Partial parsing not enabled
2021-06-05 20:22:31.335681 (MainThread): Parsing macros/etc.sql
2021-06-05 20:22:31.339440 (MainThread): Parsing macros/catalog.sql
2021-06-05 20:22:31.348160 (MainThread): Parsing macros/adapters.sql
2021-06-05 20:22:31.376476 (MainThread): Parsing macros/materializations/seed.sql
2021-06-05 20:22:31.380109 (MainThread): Parsing macros/materializations/view.sql
2021-06-05 20:22:31.383743 (MainThread): Parsing macros/materializations/table.sql
2021-06-05 20:22:31.396641 (MainThread): Parsing macros/materializations/copy.sql
2021-06-05 20:22:31.402858 (MainThread): Parsing macros/materializations/incremental.sql
2021-06-05 20:22:31.420658 (MainThread): Parsing macros/materializations/snapshot.sql
2021-06-05 20:22:31.424505 (MainThread): Parsing macros/core.sql
2021-06-05 20:22:31.429551 (MainThread): Parsing macros/materializations/helpers.sql
2021-06-05 20:22:31.443843 (MainThread): Parsing macros/materializations/snapshot/snapshot_merge.sql
2021-06-05 20:22:31.446360 (MainThread): Parsing macros/materializations/snapshot/strategies.sql
2021-06-05 20:22:31.470542 (MainThread): Parsing macros/materializations/snapshot/snapshot.sql
2021-06-05 20:22:31.515336 (MainThread): Parsing macros/materializations/seed/seed.sql
2021-06-05 20:22:31.543090 (MainThread): Parsing macros/materializations/incremental/helpers.sql
2021-06-05 20:22:31.545782 (MainThread): Parsing macros/materializations/incremental/incremental.sql
2021-06-05 20:22:31.554294 (MainThread): Parsing macros/materializations/common/merge.sql
2021-06-05 20:22:31.573034 (MainThread): Parsing macros/materializations/table/table.sql
2021-06-05 20:22:31.582141 (MainThread): Parsing macros/materializations/view/view.sql
2021-06-05 20:22:31.590761 (MainThread): Parsing macros/materializations/view/create_or_replace_view.sql
2021-06-05 20:22:31.597498 (MainThread): Parsing macros/etc/get_custom_alias.sql
2021-06-05 20:22:31.598749 (MainThread): Parsing macros/etc/query.sql
2021-06-05 20:22:31.600124 (MainThread): Parsing macros/etc/is_incremental.sql
2021-06-05 20:22:31.602282 (MainThread): Parsing macros/etc/datetime.sql
2021-06-05 20:22:31.614385 (MainThread): Parsing macros/etc/get_custom_schema.sql
2021-06-05 20:22:31.617026 (MainThread): Parsing macros/etc/get_custom_database.sql
2021-06-05 20:22:31.619256 (MainThread): Parsing macros/adapters/common.sql
2021-06-05 20:22:31.677024 (MainThread): Parsing macros/schema_tests/relationships.sql
2021-06-05 20:22:31.679575 (MainThread): Parsing macros/schema_tests/not_null.sql
2021-06-05 20:22:31.681614 (MainThread): Parsing macros/schema_tests/unique.sql
2021-06-05 20:22:31.683889 (MainThread): Parsing macros/schema_tests/accepted_values.sql
2021-06-05 20:22:31.693858 (MainThread): Partial parsing not enabled
2021-06-05 20:22:31.729494 (MainThread): Acquiring new bigquery connection "model.werkspot_technical_challenge.dim_service".
2021-06-05 20:22:31.748474 (MainThread): Acquiring new bigquery connection "model.werkspot_technical_challenge.dim_professional".
2021-06-05 20:22:31.755072 (MainThread): Acquiring new bigquery connection "model.werkspot_technical_challenge.fct_fee".
2021-06-05 20:22:31.761768 (MainThread): Acquiring new bigquery connection "model.werkspot_technical_challenge.event_logs_stg".
2021-06-05 20:22:31.828005 (MainThread): Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'a05811a0-4d5e-4039-9864-9cdc4f0e541a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f87b32e15d0>]}
2021-06-05 20:22:31.850703 (MainThread): Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'a05811a0-4d5e-4039-9864-9cdc4f0e541a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f87b33f6410>]}
2021-06-05 20:22:31.851208 (MainThread): Found 4 models, 0 tests, 0 snapshots, 0 analyses, 156 macros, 0 operations, 0 seed files, 0 sources, 0 exposures
2021-06-05 20:22:31.852943 (MainThread): 
2021-06-05 20:22:31.854276 (MainThread): Acquiring new bigquery connection "master".
2021-06-05 20:22:31.855377 (ThreadPoolExecutor-0_0): Acquiring new bigquery connection "list_poetic-genius-315513".
2021-06-05 20:22:31.855685 (ThreadPoolExecutor-0_0): Opening a new connection, currently in state init
2021-06-05 20:22:34.360230 (ThreadPoolExecutor-1_0): Acquiring new bigquery connection "list_poetic-genius-315513_events_information".
2021-06-05 20:22:34.360597 (ThreadPoolExecutor-1_0): Opening a new connection, currently in state closed
2021-06-05 20:22:34.360881 (ThreadPoolExecutor-1_0): Client.dataset is deprecated and will be removed in a future version. Use a string like 'my_project.my_dataset' or a cloud.google.bigquery.DatasetReference object, instead.
2021-06-05 20:22:35.590574 (MainThread): 01:22:35 | Concurrency: 1 threads (target='dev')
2021-06-05 20:22:35.590915 (MainThread): 01:22:35 | 
2021-06-05 20:22:35.592933 (Thread-1): Began running node model.werkspot_technical_challenge.dim_service
2021-06-05 20:22:35.593326 (Thread-1): 01:22:35 | 1 of 1 START incremental model events_information.dim_service........ [RUN]
2021-06-05 20:22:35.593802 (Thread-1): Acquiring new bigquery connection "model.werkspot_technical_challenge.dim_service".
2021-06-05 20:22:35.594968 (Thread-1): unclosed <socket.socket fd=12, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('192.168.0.104', 61339), raddr=('142.250.185.42', 443)>
2021-06-05 20:22:35.595265 (Thread-1): unclosed <socket.socket fd=11, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('192.168.0.104', 61338), raddr=('172.217.18.138', 443)>
2021-06-05 20:22:35.595497 (Thread-1): unclosed <socket.socket fd=13, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('192.168.0.104', 61340), raddr=('142.250.185.42', 443)>
2021-06-05 20:22:35.595946 (Thread-1): Compiling model.werkspot_technical_challenge.dim_service
2021-06-05 20:22:35.601728 (Thread-1): Writing injected SQL for node "model.werkspot_technical_challenge.dim_service"
2021-06-05 20:22:35.602766 (Thread-1): finished collecting timing info
2021-06-05 20:22:35.673570 (Thread-1): Writing runtime SQL for node "model.werkspot_technical_challenge.dim_service"
2021-06-05 20:22:35.674195 (Thread-1): Opening a new connection, currently in state closed
2021-06-05 20:22:35.674398 (Thread-1): On model.werkspot_technical_challenge.dim_service: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "werkspot_technical_challenge", "target_name": "dev", "node_id": "model.werkspot_technical_challenge.dim_service"} */


  create or replace table `poetic-genius-315513`.`events_information`.`dim_service`
  partition by datetime_trunc(AuditCreatedDateTime, day)
  
  OPTIONS()
  as (
    


SELECT

  DISTINCT 

    CAST(ParsedMetdata[OFFSET(0)] AS STRING) AS ServiceID,
    ParsedMetdata[OFFSET(1)] AS ServiceNameDutch,
    ParsedMetdata[OFFSET(2)] AS ServiceNameEnglish,
    CURRENT_DATETIME() as AuditCreatedDateTime, -- Audit Column, Used for Partitioning & Filtering Day in daily runs

FROM 
(
  SELECT 
    
    SPLIT(Metadata,'_') AS ParsedMetdata
  
  FROM 
    `poetic-genius-315513.events_information.event_logs_stg`
     WHERE  Metadata!=''
)

  -- this will only be applied on an incremental run & will filter data early
  -- `poetic-genius-315513`.`events_information`.`dim_service` will give last run date which can then be used to pick CDC records daily
  
  );
  
2021-06-05 20:22:39.481010 (Thread-1): finished collecting timing info
2021-06-05 20:22:39.481565 (Thread-1): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'a05811a0-4d5e-4039-9864-9cdc4f0e541a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f87b32cc6d0>]}
2021-06-05 20:22:39.481968 (Thread-1): 01:22:39 | 1 of 1 OK created incremental model events_information.dim_service... [CREATE TABLE (171.0 rows, 867.6 KB processed) in 3.89s]
2021-06-05 20:22:39.482121 (Thread-1): Finished running node model.werkspot_technical_challenge.dim_service
2021-06-05 20:22:39.516823 (MainThread): Acquiring new bigquery connection "master".
2021-06-05 20:22:39.517984 (MainThread): 01:22:39 | 
2021-06-05 20:22:39.518339 (MainThread): 01:22:39 | Finished running 1 incremental model in 7.66s.
2021-06-05 20:22:39.518630 (MainThread): Connection 'master' was properly closed.
2021-06-05 20:22:39.518832 (MainThread): Connection 'model.werkspot_technical_challenge.dim_service' was properly closed.
2021-06-05 20:22:39.532369 (MainThread): 
2021-06-05 20:22:39.532629 (MainThread): Completed successfully
2021-06-05 20:22:39.532878 (MainThread): 
Done. PASS=1 WARN=0 ERROR=0 SKIP=0 TOTAL=1
2021-06-05 20:22:39.533255 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f87b32d4890>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f87b37267d0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f87b3726290>]}
2021-06-05 20:22:39.533558 (MainThread): Flushing usage events
2021-06-05 20:32:21.598173 (MainThread): Running with dbt=0.19.1
2021-06-05 20:32:22.565157 (MainThread): running dbt with arguments Namespace(cls=<class 'dbt.task.run.RunTask'>, debug=False, defer=None, exclude=None, fail_fast=False, full_refresh=False, log_cache_events=False, log_format='default', models=['fct_fee'], partial_parse=None, profile=None, profiles_dir='/Users/mac/.dbt', project_dir=None, record_timing_info=None, rpc_method='run', selector_name=None, single_threaded=False, state=None, strict=False, target=None, test_new_parser=False, threads=None, use_cache=True, use_colors=None, vars='{}', version_check=True, warn_error=False, which='run', write_json=True)
2021-06-05 20:32:22.567135 (MainThread): Tracking: tracking
2021-06-05 20:32:22.578398 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f9a007ede90>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f9a007eda90>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f9a007edad0>]}
2021-06-05 20:32:22.592837 (MainThread): Partial parsing not enabled
2021-06-05 20:32:22.594868 (MainThread): Parsing macros/etc.sql
2021-06-05 20:32:22.599222 (MainThread): Parsing macros/catalog.sql
2021-06-05 20:32:22.608324 (MainThread): Parsing macros/adapters.sql
2021-06-05 20:32:22.639145 (MainThread): Parsing macros/materializations/seed.sql
2021-06-05 20:32:22.643356 (MainThread): Parsing macros/materializations/view.sql
2021-06-05 20:32:22.647940 (MainThread): Parsing macros/materializations/table.sql
2021-06-05 20:32:22.661642 (MainThread): Parsing macros/materializations/copy.sql
2021-06-05 20:32:22.669158 (MainThread): Parsing macros/materializations/incremental.sql
2021-06-05 20:32:22.688855 (MainThread): Parsing macros/materializations/snapshot.sql
2021-06-05 20:32:22.693782 (MainThread): Parsing macros/core.sql
2021-06-05 20:32:22.699552 (MainThread): Parsing macros/materializations/helpers.sql
2021-06-05 20:32:22.712256 (MainThread): Parsing macros/materializations/snapshot/snapshot_merge.sql
2021-06-05 20:32:22.715189 (MainThread): Parsing macros/materializations/snapshot/strategies.sql
2021-06-05 20:32:22.739597 (MainThread): Parsing macros/materializations/snapshot/snapshot.sql
2021-06-05 20:32:22.787081 (MainThread): Parsing macros/materializations/seed/seed.sql
2021-06-05 20:32:22.816171 (MainThread): Parsing macros/materializations/incremental/helpers.sql
2021-06-05 20:32:22.818869 (MainThread): Parsing macros/materializations/incremental/incremental.sql
2021-06-05 20:32:22.827455 (MainThread): Parsing macros/materializations/common/merge.sql
2021-06-05 20:32:22.846168 (MainThread): Parsing macros/materializations/table/table.sql
2021-06-05 20:32:22.855778 (MainThread): Parsing macros/materializations/view/view.sql
2021-06-05 20:32:22.864464 (MainThread): Parsing macros/materializations/view/create_or_replace_view.sql
2021-06-05 20:32:22.871256 (MainThread): Parsing macros/etc/get_custom_alias.sql
2021-06-05 20:32:22.873028 (MainThread): Parsing macros/etc/query.sql
2021-06-05 20:32:22.874818 (MainThread): Parsing macros/etc/is_incremental.sql
2021-06-05 20:32:22.877574 (MainThread): Parsing macros/etc/datetime.sql
2021-06-05 20:32:22.890210 (MainThread): Parsing macros/etc/get_custom_schema.sql
2021-06-05 20:32:22.894683 (MainThread): Parsing macros/etc/get_custom_database.sql
2021-06-05 20:32:22.897663 (MainThread): Parsing macros/adapters/common.sql
2021-06-05 20:32:22.957751 (MainThread): Parsing macros/schema_tests/relationships.sql
2021-06-05 20:32:22.960716 (MainThread): Parsing macros/schema_tests/not_null.sql
2021-06-05 20:32:22.962985 (MainThread): Parsing macros/schema_tests/unique.sql
2021-06-05 20:32:22.965525 (MainThread): Parsing macros/schema_tests/accepted_values.sql
2021-06-05 20:32:22.975837 (MainThread): Partial parsing not enabled
2021-06-05 20:32:23.010034 (MainThread): Acquiring new bigquery connection "model.werkspot_technical_challenge.dim_service".
2021-06-05 20:32:23.030079 (MainThread): Acquiring new bigquery connection "model.werkspot_technical_challenge.dim_professional".
2021-06-05 20:32:23.045484 (MainThread): Acquiring new bigquery connection "model.werkspot_technical_challenge.fct_fee".
2021-06-05 20:32:23.054133 (MainThread): Acquiring new bigquery connection "model.werkspot_technical_challenge.event_logs_stg".
2021-06-05 20:32:23.121557 (MainThread): Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'c4d80da5-ba87-42e9-af7e-4f876842e1fb', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f9a00ae7f50>]}
2021-06-05 20:32:23.140556 (MainThread): Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'c4d80da5-ba87-42e9-af7e-4f876842e1fb', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f9a00bf7ad0>]}
2021-06-05 20:32:23.140963 (MainThread): Found 4 models, 0 tests, 0 snapshots, 0 analyses, 156 macros, 0 operations, 0 seed files, 0 sources, 0 exposures
2021-06-05 20:32:23.141929 (MainThread): 
2021-06-05 20:32:23.142438 (MainThread): Acquiring new bigquery connection "master".
2021-06-05 20:32:23.143377 (ThreadPoolExecutor-0_0): Acquiring new bigquery connection "list_poetic-genius-315513".
2021-06-05 20:32:23.143686 (ThreadPoolExecutor-0_0): Opening a new connection, currently in state init
2021-06-05 20:32:25.749114 (ThreadPoolExecutor-1_0): Acquiring new bigquery connection "list_poetic-genius-315513_events_information".
2021-06-05 20:32:25.749504 (ThreadPoolExecutor-1_0): Opening a new connection, currently in state closed
2021-06-05 20:32:25.749896 (ThreadPoolExecutor-1_0): Client.dataset is deprecated and will be removed in a future version. Use a string like 'my_project.my_dataset' or a cloud.google.bigquery.DatasetReference object, instead.
2021-06-05 20:32:26.956289 (MainThread): 01:32:26 | Concurrency: 1 threads (target='dev')
2021-06-05 20:32:26.956661 (MainThread): 01:32:26 | 
2021-06-05 20:32:26.959306 (Thread-1): Began running node model.werkspot_technical_challenge.fct_fee
2021-06-05 20:32:26.959752 (Thread-1): 01:32:26 | 1 of 1 START incremental model events_information.fct_fee............ [RUN]
2021-06-05 20:32:26.960407 (Thread-1): Acquiring new bigquery connection "model.werkspot_technical_challenge.fct_fee".
2021-06-05 20:32:26.961622 (Thread-1): unclosed <socket.socket fd=12, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('192.168.0.104', 61474), raddr=('142.250.185.42', 443)>
2021-06-05 20:32:26.961923 (Thread-1): unclosed <socket.socket fd=11, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('192.168.0.104', 61471), raddr=('172.217.169.234', 443)>
2021-06-05 20:32:26.962205 (Thread-1): unclosed <socket.socket fd=13, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('192.168.0.104', 61477), raddr=('142.250.185.42', 443)>
2021-06-05 20:32:26.962700 (Thread-1): Compiling model.werkspot_technical_challenge.fct_fee
2021-06-05 20:32:26.968610 (Thread-1): Writing injected SQL for node "model.werkspot_technical_challenge.fct_fee"
2021-06-05 20:32:26.969194 (Thread-1): finished collecting timing info
2021-06-05 20:32:27.040021 (Thread-1): Writing runtime SQL for node "model.werkspot_technical_challenge.fct_fee"
2021-06-05 20:32:27.041442 (Thread-1): Opening a new connection, currently in state closed
2021-06-05 20:32:27.041777 (Thread-1): On model.werkspot_technical_challenge.fct_fee: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "werkspot_technical_challenge", "target_name": "dev", "node_id": "model.werkspot_technical_challenge.fct_fee"} */


  create or replace table `poetic-genius-315513`.`events_information`.`fct_fee`
  partition by datetime_trunc(AuditCreatedDateTime, day)
  
  OPTIONS()
  as (
    



SELECT
  ProfessionalID,
  
  (CASE 
    WHEN ParsedMetadata[OFFSET(0)]='' 
      THEN 'Not provided' 
      ELSE  ParsedMetadata[OFFSET(0)]
    END
  ) AS ServiceID,
  
  EventID,
  EventType,
  CreatedAt,
  
  (CASE 
    WHEN ParsedMetadata[OFFSET(0)]!='' 
      THEN CAST(ParsedMetadata[OFFSET(3)] AS FLOAT64) 
      ELSE 0.0 
   END
  ) as LeadFee,
 
FROM
(
  SELECT
      EventID,
      EventType,
      ProfessionalID,
      CreatedAt,
      SPLIT(Metadata,'_') as ParsedMetadata,
      CURRENT_DATETIME() as AuditCreatedDateTime, -- Audit column
    FROM 
     `poetic-genius-315513.events_information.event_logs_stg`
     where Metadata!=''
)

    -- this will only be applied on an incremental run & will filter data early
    -- `poetic-genius-315513`.`events_information`.`fct_fee` will give last run date which can then be used to pick CDC records daily
    
  );
  
2021-06-05 20:32:29.208688 (Thread-1): Retry attempt 1 of 1 after error: BadRequest('GET https://bigquery.googleapis.com/bigquery/v2/projects/poetic-genius-315513/queries/480c5f19-c9e0-4e49-bd09-5b02b2c45681?maxResults=0&location=US: Unrecognized name: AuditCreatedDateTime at [5:31]')
2021-06-05 20:32:30.863759 (Thread-1): finished collecting timing info
2021-06-05 20:32:30.864529 (Thread-1): Database Error in model fct_fee (models/Facts/fct_fee.sql)
  Unrecognized name: AuditCreatedDateTime at [5:31]
  compiled SQL at target/run/werkspot_technical_challenge/models/Facts/fct_fee.sql
Traceback (most recent call last):
  File "/opt/anaconda3/lib/python3.7/site-packages/dbt/adapters/bigquery/connections.py", line 149, in exception_handler
    yield
  File "/opt/anaconda3/lib/python3.7/site-packages/dbt/adapters/bigquery/connections.py", line 539, in _retry_and_handle
    on_error=reopen_conn_on_error)
  File "/opt/anaconda3/lib/python3.7/site-packages/google/api_core/retry.py", line 184, in retry_target
    return target()
  File "/opt/anaconda3/lib/python3.7/site-packages/dbt/adapters/bigquery/connections.py", line 327, in fn
    return self._query_and_results(client, sql, conn, job_params)
  File "/opt/anaconda3/lib/python3.7/site-packages/dbt/adapters/bigquery/connections.py", line 520, in _query_and_results
    iterator = query_job.result(timeout=timeout)
  File "/opt/anaconda3/lib/python3.7/site-packages/google/cloud/bigquery/job.py", line 3207, in result
    super(QueryJob, self).result(retry=retry, timeout=timeout)
  File "/opt/anaconda3/lib/python3.7/site-packages/google/cloud/bigquery/job.py", line 812, in result
    return super(_AsyncJob, self).result(timeout=timeout)
  File "/opt/anaconda3/lib/python3.7/site-packages/google/api_core/future/polling.py", line 125, in result
    self._blocking_poll(timeout=timeout)
  File "/opt/anaconda3/lib/python3.7/site-packages/google/cloud/bigquery/job.py", line 3103, in _blocking_poll
    super(QueryJob, self)._blocking_poll(timeout=timeout)
  File "/opt/anaconda3/lib/python3.7/site-packages/google/api_core/future/polling.py", line 104, in _blocking_poll
    retry_(self._done_or_raise)()
  File "/opt/anaconda3/lib/python3.7/site-packages/google/api_core/retry.py", line 286, in retry_wrapped_func
    on_error=on_error,
  File "/opt/anaconda3/lib/python3.7/site-packages/google/api_core/retry.py", line 184, in retry_target
    return target()
  File "/opt/anaconda3/lib/python3.7/site-packages/google/api_core/future/polling.py", line 83, in _done_or_raise
    if not self.done():
  File "/opt/anaconda3/lib/python3.7/site-packages/google/cloud/bigquery/job.py", line 3089, in done
    timeout=transport_timeout,
  File "/opt/anaconda3/lib/python3.7/site-packages/google/cloud/bigquery/client.py", line 1362, in _get_query_results
    retry, method="GET", path=path, query_params=extra_params, timeout=timeout
  File "/opt/anaconda3/lib/python3.7/site-packages/google/cloud/bigquery/client.py", line 578, in _call_api
    return call()
  File "/opt/anaconda3/lib/python3.7/site-packages/google/api_core/retry.py", line 286, in retry_wrapped_func
    on_error=on_error,
  File "/opt/anaconda3/lib/python3.7/site-packages/google/api_core/retry.py", line 184, in retry_target
    return target()
  File "/opt/anaconda3/lib/python3.7/site-packages/google/cloud/_http.py", line 423, in api_request
    raise exceptions.from_http_response(response)
google.api_core.exceptions.BadRequest: 400 GET https://bigquery.googleapis.com/bigquery/v2/projects/poetic-genius-315513/queries/cd8104b5-0daf-423b-9b67-37b58b82f6f4?maxResults=0&location=US: Unrecognized name: AuditCreatedDateTime at [5:31]

(job ID: cd8104b5-0daf-423b-9b67-37b58b82f6f4)

                                                                         -----Query Job SQL Follows-----                                                                         

    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |
   1:/* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "werkspot_technical_challenge", "target_name": "dev", "node_id": "model.werkspot_technical_challenge.fct_fee"} */
   2:
   3:
   4:  create or replace table `poetic-genius-315513`.`events_information`.`fct_fee`
   5:  partition by datetime_trunc(AuditCreatedDateTime, day)
   6:  
   7:  OPTIONS()
   8:  as (
   9:    
  10:
  11:
  12:
  13:SELECT
  14:  ProfessionalID,
  15:  
  16:  (CASE 
  17:    WHEN ParsedMetadata[OFFSET(0)]='' 
  18:      THEN 'Not provided' 
  19:      ELSE  ParsedMetadata[OFFSET(0)]
  20:    END
  21:  ) AS ServiceID,
  22:  
  23:  EventID,
  24:  EventType,
  25:  CreatedAt,
  26:  
  27:  (CASE 
  28:    WHEN ParsedMetadata[OFFSET(0)]!='' 
  29:      THEN CAST(ParsedMetadata[OFFSET(3)] AS FLOAT64) 
  30:      ELSE 0.0 
  31:   END
  32:  ) as LeadFee,
  33: 
  34:FROM
  35:(
  36:  SELECT
  37:      EventID,
  38:      EventType,
  39:      ProfessionalID,
  40:      CreatedAt,
  41:      SPLIT(Metadata,'_') as ParsedMetadata,
  42:      CURRENT_DATETIME() as AuditCreatedDateTime, -- Audit column
  43:    FROM 
  44:     `poetic-genius-315513.events_information.event_logs_stg`
  45:     where Metadata!=''
  46:)
  47:
  48:    -- this will only be applied on an incremental run & will filter data early
  49:    -- `poetic-genius-315513`.`events_information`.`fct_fee` will give last run date which can then be used to pick CDC records daily
  50:    
  51:  );
  52:  
    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/anaconda3/lib/python3.7/site-packages/dbt/task/base.py", line 344, in safe_run
    result = self.compile_and_execute(manifest, ctx)
  File "/opt/anaconda3/lib/python3.7/site-packages/dbt/task/base.py", line 287, in compile_and_execute
    result = self.run(ctx.node, manifest)
  File "/opt/anaconda3/lib/python3.7/site-packages/dbt/task/base.py", line 389, in run
    return self.execute(compiled_node, manifest)
  File "/opt/anaconda3/lib/python3.7/site-packages/dbt/task/run.py", line 248, in execute
    result = MacroGenerator(materialization_macro, context)()
  File "/opt/anaconda3/lib/python3.7/site-packages/dbt/clients/jinja.py", line 332, in __call__
    return self.call_macro(*args, **kwargs)
  File "/opt/anaconda3/lib/python3.7/site-packages/dbt/clients/jinja.py", line 259, in call_macro
    return macro(*args, **kwargs)
  File "/opt/anaconda3/lib/python3.7/site-packages/jinja2/runtime.py", line 675, in __call__
    return self._invoke(arguments, autoescape)
  File "/opt/anaconda3/lib/python3.7/site-packages/jinja2/runtime.py", line 679, in _invoke
    rv = self._func(*arguments)
  File "<template>", line 156, in macro
  File "/opt/anaconda3/lib/python3.7/site-packages/jinja2/sandbox.py", line 462, in call
    return __context.call(__obj, *args, **kwargs)
  File "/opt/anaconda3/lib/python3.7/site-packages/jinja2/runtime.py", line 290, in call
    return __obj(*args, **kwargs)
  File "/opt/anaconda3/lib/python3.7/site-packages/dbt/clients/jinja.py", line 332, in __call__
    return self.call_macro(*args, **kwargs)
  File "/opt/anaconda3/lib/python3.7/site-packages/dbt/clients/jinja.py", line 259, in call_macro
    return macro(*args, **kwargs)
  File "/opt/anaconda3/lib/python3.7/site-packages/jinja2/runtime.py", line 675, in __call__
    return self._invoke(arguments, autoescape)
  File "/opt/anaconda3/lib/python3.7/site-packages/jinja2/runtime.py", line 679, in _invoke
    rv = self._func(*arguments)
  File "<template>", line 41, in macro
  File "/opt/anaconda3/lib/python3.7/site-packages/jinja2/sandbox.py", line 462, in call
    return __context.call(__obj, *args, **kwargs)
  File "/opt/anaconda3/lib/python3.7/site-packages/jinja2/runtime.py", line 290, in call
    return __obj(*args, **kwargs)
  File "/opt/anaconda3/lib/python3.7/site-packages/dbt/adapters/base/impl.py", line 230, in execute
    fetch=fetch
  File "/opt/anaconda3/lib/python3.7/site-packages/dbt/adapters/bigquery/connections.py", line 338, in execute
    query_job, iterator = self.raw_execute(sql, fetch=fetch)
  File "/opt/anaconda3/lib/python3.7/site-packages/dbt/adapters/bigquery/connections.py", line 329, in raw_execute
    query_job, iterator = self._retry_and_handle(msg=sql, conn=conn, fn=fn)
  File "/opt/anaconda3/lib/python3.7/site-packages/dbt/adapters/bigquery/connections.py", line 539, in _retry_and_handle
    on_error=reopen_conn_on_error)
  File "/opt/anaconda3/lib/python3.7/contextlib.py", line 130, in __exit__
    self.gen.throw(type, value, traceback)
  File "/opt/anaconda3/lib/python3.7/site-packages/dbt/adapters/bigquery/connections.py", line 153, in exception_handler
    self.handle_error(e, message)
  File "/opt/anaconda3/lib/python3.7/site-packages/dbt/adapters/bigquery/connections.py", line 141, in handle_error
    raise DatabaseException(error_msg)
dbt.exceptions.DatabaseException: Database Error in model fct_fee (models/Facts/fct_fee.sql)
  Unrecognized name: AuditCreatedDateTime at [5:31]
  compiled SQL at target/run/werkspot_technical_challenge/models/Facts/fct_fee.sql
2021-06-05 20:32:30.877515 (Thread-1): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'c4d80da5-ba87-42e9-af7e-4f876842e1fb', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f9a00f0add0>]}
2021-06-05 20:32:30.878008 (Thread-1): 01:32:30 | 1 of 1 ERROR creating incremental model events_information.fct_fee... [ERROR in 3.92s]
2021-06-05 20:32:30.878192 (Thread-1): Finished running node model.werkspot_technical_challenge.fct_fee
2021-06-05 20:32:30.980436 (MainThread): Acquiring new bigquery connection "master".
2021-06-05 20:32:30.981063 (MainThread): 01:32:30 | 
2021-06-05 20:32:30.981320 (MainThread): 01:32:30 | Finished running 1 incremental model in 7.84s.
2021-06-05 20:32:30.981661 (MainThread): Connection 'master' was properly closed.
2021-06-05 20:32:30.981885 (MainThread): Connection 'model.werkspot_technical_challenge.fct_fee' was properly closed.
2021-06-05 20:32:30.992950 (MainThread): 
2021-06-05 20:32:30.993214 (MainThread): Completed with 1 error and 0 warnings:
2021-06-05 20:32:30.993503 (MainThread): 
2021-06-05 20:32:30.993716 (MainThread): Database Error in model fct_fee (models/Facts/fct_fee.sql)
2021-06-05 20:32:30.993929 (MainThread):   Unrecognized name: AuditCreatedDateTime at [5:31]
2021-06-05 20:32:30.994115 (MainThread):   compiled SQL at target/run/werkspot_technical_challenge/models/Facts/fct_fee.sql
2021-06-05 20:32:30.994293 (MainThread): 
Done. PASS=0 WARN=0 ERROR=1 SKIP=0 TOTAL=1
2021-06-05 20:32:30.994607 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f9a00abcd50>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f99ff734b50>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f9a00acd850>]}
2021-06-05 20:32:30.994865 (MainThread): Flushing usage events
2021-06-05 20:33:14.079654 (MainThread): Running with dbt=0.19.1
2021-06-05 20:33:14.828160 (MainThread): running dbt with arguments Namespace(cls=<class 'dbt.task.run.RunTask'>, debug=False, defer=None, exclude=None, fail_fast=False, full_refresh=False, log_cache_events=False, log_format='default', models=['fct_fee'], partial_parse=None, profile=None, profiles_dir='/Users/mac/.dbt', project_dir=None, record_timing_info=None, rpc_method='run', selector_name=None, single_threaded=False, state=None, strict=False, target=None, test_new_parser=False, threads=None, use_cache=True, use_colors=None, vars='{}', version_check=True, warn_error=False, which='run', write_json=True)
2021-06-05 20:33:14.830661 (MainThread): Tracking: tracking
2021-06-05 20:33:14.840706 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f991d80b890>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f991d80bbd0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f991d80b0d0>]}
2021-06-05 20:33:14.859757 (MainThread): Partial parsing not enabled
2021-06-05 20:33:14.861228 (MainThread): Parsing macros/etc.sql
2021-06-05 20:33:14.865752 (MainThread): Parsing macros/catalog.sql
2021-06-05 20:33:14.876177 (MainThread): Parsing macros/adapters.sql
2021-06-05 20:33:14.904152 (MainThread): Parsing macros/materializations/seed.sql
2021-06-05 20:33:14.907881 (MainThread): Parsing macros/materializations/view.sql
2021-06-05 20:33:14.911638 (MainThread): Parsing macros/materializations/table.sql
2021-06-05 20:33:14.925158 (MainThread): Parsing macros/materializations/copy.sql
2021-06-05 20:33:14.931140 (MainThread): Parsing macros/materializations/incremental.sql
2021-06-05 20:33:14.947906 (MainThread): Parsing macros/materializations/snapshot.sql
2021-06-05 20:33:14.951637 (MainThread): Parsing macros/core.sql
2021-06-05 20:33:14.956978 (MainThread): Parsing macros/materializations/helpers.sql
2021-06-05 20:33:14.969174 (MainThread): Parsing macros/materializations/snapshot/snapshot_merge.sql
2021-06-05 20:33:14.971591 (MainThread): Parsing macros/materializations/snapshot/strategies.sql
2021-06-05 20:33:14.995728 (MainThread): Parsing macros/materializations/snapshot/snapshot.sql
2021-06-05 20:33:15.041222 (MainThread): Parsing macros/materializations/seed/seed.sql
2021-06-05 20:33:15.069637 (MainThread): Parsing macros/materializations/incremental/helpers.sql
2021-06-05 20:33:15.072169 (MainThread): Parsing macros/materializations/incremental/incremental.sql
2021-06-05 20:33:15.080785 (MainThread): Parsing macros/materializations/common/merge.sql
2021-06-05 20:33:15.100191 (MainThread): Parsing macros/materializations/table/table.sql
2021-06-05 20:33:15.109414 (MainThread): Parsing macros/materializations/view/view.sql
2021-06-05 20:33:15.117941 (MainThread): Parsing macros/materializations/view/create_or_replace_view.sql
2021-06-05 20:33:15.125012 (MainThread): Parsing macros/etc/get_custom_alias.sql
2021-06-05 20:33:15.126409 (MainThread): Parsing macros/etc/query.sql
2021-06-05 20:33:15.127967 (MainThread): Parsing macros/etc/is_incremental.sql
2021-06-05 20:33:15.130363 (MainThread): Parsing macros/etc/datetime.sql
2021-06-05 20:33:15.142247 (MainThread): Parsing macros/etc/get_custom_schema.sql
2021-06-05 20:33:15.145073 (MainThread): Parsing macros/etc/get_custom_database.sql
2021-06-05 20:33:15.147592 (MainThread): Parsing macros/adapters/common.sql
2021-06-05 20:33:15.206879 (MainThread): Parsing macros/schema_tests/relationships.sql
2021-06-05 20:33:15.209475 (MainThread): Parsing macros/schema_tests/not_null.sql
2021-06-05 20:33:15.211534 (MainThread): Parsing macros/schema_tests/unique.sql
2021-06-05 20:33:15.213834 (MainThread): Parsing macros/schema_tests/accepted_values.sql
2021-06-05 20:33:15.224340 (MainThread): Partial parsing not enabled
2021-06-05 20:33:15.256813 (MainThread): Acquiring new bigquery connection "model.werkspot_technical_challenge.dim_service".
2021-06-05 20:33:15.276420 (MainThread): Acquiring new bigquery connection "model.werkspot_technical_challenge.dim_professional".
2021-06-05 20:33:15.284412 (MainThread): Acquiring new bigquery connection "model.werkspot_technical_challenge.fct_fee".
2021-06-05 20:33:15.292606 (MainThread): Acquiring new bigquery connection "model.werkspot_technical_challenge.event_logs_stg".
2021-06-05 20:33:15.358443 (MainThread): Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '4de89aa8-dca8-4313-913f-7241d47f5286', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f991d9c35d0>]}
2021-06-05 20:33:15.376974 (MainThread): Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '4de89aa8-dca8-4313-913f-7241d47f5286', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f991dc25490>]}
2021-06-05 20:33:15.377495 (MainThread): Found 4 models, 0 tests, 0 snapshots, 0 analyses, 156 macros, 0 operations, 0 seed files, 0 sources, 0 exposures
2021-06-05 20:33:15.379009 (MainThread): 
2021-06-05 20:33:15.379620 (MainThread): Acquiring new bigquery connection "master".
2021-06-05 20:33:15.380699 (ThreadPoolExecutor-0_0): Acquiring new bigquery connection "list_poetic-genius-315513".
2021-06-05 20:33:15.381010 (ThreadPoolExecutor-0_0): Opening a new connection, currently in state init
2021-06-05 20:33:17.617853 (ThreadPoolExecutor-1_0): Acquiring new bigquery connection "list_poetic-genius-315513_events_information".
2021-06-05 20:33:17.618229 (ThreadPoolExecutor-1_0): Opening a new connection, currently in state closed
2021-06-05 20:33:17.618553 (ThreadPoolExecutor-1_0): Client.dataset is deprecated and will be removed in a future version. Use a string like 'my_project.my_dataset' or a cloud.google.bigquery.DatasetReference object, instead.
2021-06-05 20:33:18.773296 (MainThread): 01:33:18 | Concurrency: 1 threads (target='dev')
2021-06-05 20:33:18.773693 (MainThread): 01:33:18 | 
2021-06-05 20:33:18.775797 (Thread-1): Began running node model.werkspot_technical_challenge.fct_fee
2021-06-05 20:33:18.776204 (Thread-1): 01:33:18 | 1 of 1 START incremental model events_information.fct_fee............ [RUN]
2021-06-05 20:33:18.776672 (Thread-1): Acquiring new bigquery connection "model.werkspot_technical_challenge.fct_fee".
2021-06-05 20:33:18.778057 (Thread-1): unclosed <socket.socket fd=12, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('192.168.0.104', 61491), raddr=('142.250.185.42', 443)>
2021-06-05 20:33:18.778312 (Thread-1): unclosed <socket.socket fd=11, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('192.168.0.104', 61490), raddr=('172.217.169.234', 443)>
2021-06-05 20:33:18.778584 (Thread-1): unclosed <socket.socket fd=13, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('192.168.0.104', 61492), raddr=('142.250.185.42', 443)>
2021-06-05 20:33:18.779117 (Thread-1): Compiling model.werkspot_technical_challenge.fct_fee
2021-06-05 20:33:18.785119 (Thread-1): Writing injected SQL for node "model.werkspot_technical_challenge.fct_fee"
2021-06-05 20:33:18.785691 (Thread-1): finished collecting timing info
2021-06-05 20:33:18.860155 (Thread-1): Writing runtime SQL for node "model.werkspot_technical_challenge.fct_fee"
2021-06-05 20:33:18.860882 (Thread-1): Opening a new connection, currently in state closed
2021-06-05 20:33:18.861144 (Thread-1): On model.werkspot_technical_challenge.fct_fee: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "werkspot_technical_challenge", "target_name": "dev", "node_id": "model.werkspot_technical_challenge.fct_fee"} */


  create or replace table `poetic-genius-315513`.`events_information`.`fct_fee`
  partition by datetime_trunc(AuditCreatedDatetime, day)
  
  OPTIONS()
  as (
    



SELECT
  ProfessionalID,
  
  (CASE 
    WHEN ParsedMetadata[OFFSET(0)]='' 
      THEN 'Not provided' 
      ELSE  ParsedMetadata[OFFSET(0)]
    END
  ) AS ServiceID,
  
  EventID,
  EventType,
  CreatedAt,
  
  (CASE 
    WHEN ParsedMetadata[OFFSET(0)]!='' 
      THEN CAST(ParsedMetadata[OFFSET(3)] AS FLOAT64) 
      ELSE 0.0 
   END
  ) as LeadFee,
 
FROM
(
  SELECT
      EventID,
      EventType,
      ProfessionalID,
      CreatedAt,
      SPLIT(Metadata,'_') as ParsedMetadata,
      CURRENT_DATETIME() as AuditCreatedDatetime, -- Audit column
    FROM 
     `poetic-genius-315513.events_information.event_logs_stg`
     where Metadata!=''
)

    -- this will only be applied on an incremental run & will filter data early
    -- `poetic-genius-315513`.`events_information`.`fct_fee` will give last run date which can then be used to pick CDC records daily
    
  );
  
2021-06-05 20:33:20.717102 (Thread-1): Retry attempt 1 of 1 after error: BadRequest('GET https://bigquery.googleapis.com/bigquery/v2/projects/poetic-genius-315513/queries/362ed7c1-aff8-4f20-8489-3d60cb734006?maxResults=0&location=US: Unrecognized name: AuditCreatedDatetime at [5:31]')
2021-06-05 20:33:22.458777 (Thread-1): finished collecting timing info
2021-06-05 20:33:22.459473 (Thread-1): Database Error in model fct_fee (models/Facts/fct_fee.sql)
  Unrecognized name: AuditCreatedDatetime at [5:31]
  compiled SQL at target/run/werkspot_technical_challenge/models/Facts/fct_fee.sql
Traceback (most recent call last):
  File "/opt/anaconda3/lib/python3.7/site-packages/dbt/adapters/bigquery/connections.py", line 149, in exception_handler
    yield
  File "/opt/anaconda3/lib/python3.7/site-packages/dbt/adapters/bigquery/connections.py", line 539, in _retry_and_handle
    on_error=reopen_conn_on_error)
  File "/opt/anaconda3/lib/python3.7/site-packages/google/api_core/retry.py", line 184, in retry_target
    return target()
  File "/opt/anaconda3/lib/python3.7/site-packages/dbt/adapters/bigquery/connections.py", line 327, in fn
    return self._query_and_results(client, sql, conn, job_params)
  File "/opt/anaconda3/lib/python3.7/site-packages/dbt/adapters/bigquery/connections.py", line 520, in _query_and_results
    iterator = query_job.result(timeout=timeout)
  File "/opt/anaconda3/lib/python3.7/site-packages/google/cloud/bigquery/job.py", line 3207, in result
    super(QueryJob, self).result(retry=retry, timeout=timeout)
  File "/opt/anaconda3/lib/python3.7/site-packages/google/cloud/bigquery/job.py", line 812, in result
    return super(_AsyncJob, self).result(timeout=timeout)
  File "/opt/anaconda3/lib/python3.7/site-packages/google/api_core/future/polling.py", line 125, in result
    self._blocking_poll(timeout=timeout)
  File "/opt/anaconda3/lib/python3.7/site-packages/google/cloud/bigquery/job.py", line 3103, in _blocking_poll
    super(QueryJob, self)._blocking_poll(timeout=timeout)
  File "/opt/anaconda3/lib/python3.7/site-packages/google/api_core/future/polling.py", line 104, in _blocking_poll
    retry_(self._done_or_raise)()
  File "/opt/anaconda3/lib/python3.7/site-packages/google/api_core/retry.py", line 286, in retry_wrapped_func
    on_error=on_error,
  File "/opt/anaconda3/lib/python3.7/site-packages/google/api_core/retry.py", line 184, in retry_target
    return target()
  File "/opt/anaconda3/lib/python3.7/site-packages/google/api_core/future/polling.py", line 83, in _done_or_raise
    if not self.done():
  File "/opt/anaconda3/lib/python3.7/site-packages/google/cloud/bigquery/job.py", line 3089, in done
    timeout=transport_timeout,
  File "/opt/anaconda3/lib/python3.7/site-packages/google/cloud/bigquery/client.py", line 1362, in _get_query_results
    retry, method="GET", path=path, query_params=extra_params, timeout=timeout
  File "/opt/anaconda3/lib/python3.7/site-packages/google/cloud/bigquery/client.py", line 578, in _call_api
    return call()
  File "/opt/anaconda3/lib/python3.7/site-packages/google/api_core/retry.py", line 286, in retry_wrapped_func
    on_error=on_error,
  File "/opt/anaconda3/lib/python3.7/site-packages/google/api_core/retry.py", line 184, in retry_target
    return target()
  File "/opt/anaconda3/lib/python3.7/site-packages/google/cloud/_http.py", line 423, in api_request
    raise exceptions.from_http_response(response)
google.api_core.exceptions.BadRequest: 400 GET https://bigquery.googleapis.com/bigquery/v2/projects/poetic-genius-315513/queries/ff21e00c-bd29-49c1-a960-941f0c76b0ee?maxResults=0&location=US: Unrecognized name: AuditCreatedDatetime at [5:31]

(job ID: ff21e00c-bd29-49c1-a960-941f0c76b0ee)

                                                                         -----Query Job SQL Follows-----                                                                         

    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |
   1:/* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "werkspot_technical_challenge", "target_name": "dev", "node_id": "model.werkspot_technical_challenge.fct_fee"} */
   2:
   3:
   4:  create or replace table `poetic-genius-315513`.`events_information`.`fct_fee`
   5:  partition by datetime_trunc(AuditCreatedDatetime, day)
   6:  
   7:  OPTIONS()
   8:  as (
   9:    
  10:
  11:
  12:
  13:SELECT
  14:  ProfessionalID,
  15:  
  16:  (CASE 
  17:    WHEN ParsedMetadata[OFFSET(0)]='' 
  18:      THEN 'Not provided' 
  19:      ELSE  ParsedMetadata[OFFSET(0)]
  20:    END
  21:  ) AS ServiceID,
  22:  
  23:  EventID,
  24:  EventType,
  25:  CreatedAt,
  26:  
  27:  (CASE 
  28:    WHEN ParsedMetadata[OFFSET(0)]!='' 
  29:      THEN CAST(ParsedMetadata[OFFSET(3)] AS FLOAT64) 
  30:      ELSE 0.0 
  31:   END
  32:  ) as LeadFee,
  33: 
  34:FROM
  35:(
  36:  SELECT
  37:      EventID,
  38:      EventType,
  39:      ProfessionalID,
  40:      CreatedAt,
  41:      SPLIT(Metadata,'_') as ParsedMetadata,
  42:      CURRENT_DATETIME() as AuditCreatedDatetime, -- Audit column
  43:    FROM 
  44:     `poetic-genius-315513.events_information.event_logs_stg`
  45:     where Metadata!=''
  46:)
  47:
  48:    -- this will only be applied on an incremental run & will filter data early
  49:    -- `poetic-genius-315513`.`events_information`.`fct_fee` will give last run date which can then be used to pick CDC records daily
  50:    
  51:  );
  52:  
    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/anaconda3/lib/python3.7/site-packages/dbt/task/base.py", line 344, in safe_run
    result = self.compile_and_execute(manifest, ctx)
  File "/opt/anaconda3/lib/python3.7/site-packages/dbt/task/base.py", line 287, in compile_and_execute
    result = self.run(ctx.node, manifest)
  File "/opt/anaconda3/lib/python3.7/site-packages/dbt/task/base.py", line 389, in run
    return self.execute(compiled_node, manifest)
  File "/opt/anaconda3/lib/python3.7/site-packages/dbt/task/run.py", line 248, in execute
    result = MacroGenerator(materialization_macro, context)()
  File "/opt/anaconda3/lib/python3.7/site-packages/dbt/clients/jinja.py", line 332, in __call__
    return self.call_macro(*args, **kwargs)
  File "/opt/anaconda3/lib/python3.7/site-packages/dbt/clients/jinja.py", line 259, in call_macro
    return macro(*args, **kwargs)
  File "/opt/anaconda3/lib/python3.7/site-packages/jinja2/runtime.py", line 675, in __call__
    return self._invoke(arguments, autoescape)
  File "/opt/anaconda3/lib/python3.7/site-packages/jinja2/runtime.py", line 679, in _invoke
    rv = self._func(*arguments)
  File "<template>", line 156, in macro
  File "/opt/anaconda3/lib/python3.7/site-packages/jinja2/sandbox.py", line 462, in call
    return __context.call(__obj, *args, **kwargs)
  File "/opt/anaconda3/lib/python3.7/site-packages/jinja2/runtime.py", line 290, in call
    return __obj(*args, **kwargs)
  File "/opt/anaconda3/lib/python3.7/site-packages/dbt/clients/jinja.py", line 332, in __call__
    return self.call_macro(*args, **kwargs)
  File "/opt/anaconda3/lib/python3.7/site-packages/dbt/clients/jinja.py", line 259, in call_macro
    return macro(*args, **kwargs)
  File "/opt/anaconda3/lib/python3.7/site-packages/jinja2/runtime.py", line 675, in __call__
    return self._invoke(arguments, autoescape)
  File "/opt/anaconda3/lib/python3.7/site-packages/jinja2/runtime.py", line 679, in _invoke
    rv = self._func(*arguments)
  File "<template>", line 41, in macro
  File "/opt/anaconda3/lib/python3.7/site-packages/jinja2/sandbox.py", line 462, in call
    return __context.call(__obj, *args, **kwargs)
  File "/opt/anaconda3/lib/python3.7/site-packages/jinja2/runtime.py", line 290, in call
    return __obj(*args, **kwargs)
  File "/opt/anaconda3/lib/python3.7/site-packages/dbt/adapters/base/impl.py", line 230, in execute
    fetch=fetch
  File "/opt/anaconda3/lib/python3.7/site-packages/dbt/adapters/bigquery/connections.py", line 338, in execute
    query_job, iterator = self.raw_execute(sql, fetch=fetch)
  File "/opt/anaconda3/lib/python3.7/site-packages/dbt/adapters/bigquery/connections.py", line 329, in raw_execute
    query_job, iterator = self._retry_and_handle(msg=sql, conn=conn, fn=fn)
  File "/opt/anaconda3/lib/python3.7/site-packages/dbt/adapters/bigquery/connections.py", line 539, in _retry_and_handle
    on_error=reopen_conn_on_error)
  File "/opt/anaconda3/lib/python3.7/contextlib.py", line 130, in __exit__
    self.gen.throw(type, value, traceback)
  File "/opt/anaconda3/lib/python3.7/site-packages/dbt/adapters/bigquery/connections.py", line 153, in exception_handler
    self.handle_error(e, message)
  File "/opt/anaconda3/lib/python3.7/site-packages/dbt/adapters/bigquery/connections.py", line 141, in handle_error
    raise DatabaseException(error_msg)
dbt.exceptions.DatabaseException: Database Error in model fct_fee (models/Facts/fct_fee.sql)
  Unrecognized name: AuditCreatedDatetime at [5:31]
  compiled SQL at target/run/werkspot_technical_challenge/models/Facts/fct_fee.sql
2021-06-05 20:33:22.464990 (Thread-1): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '4de89aa8-dca8-4313-913f-7241d47f5286', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f991d9bcf50>]}
2021-06-05 20:33:22.465542 (Thread-1): 01:33:22 | 1 of 1 ERROR creating incremental model events_information.fct_fee... [ERROR in 3.69s]
2021-06-05 20:33:22.465767 (Thread-1): Finished running node model.werkspot_technical_challenge.fct_fee
2021-06-05 20:33:22.484379 (MainThread): Acquiring new bigquery connection "master".
2021-06-05 20:33:22.485059 (MainThread): 01:33:22 | 
2021-06-05 20:33:22.485332 (MainThread): 01:33:22 | Finished running 1 incremental model in 7.11s.
2021-06-05 20:33:22.485595 (MainThread): Connection 'master' was properly closed.
2021-06-05 20:33:22.485811 (MainThread): Connection 'model.werkspot_technical_challenge.fct_fee' was properly closed.
2021-06-05 20:33:22.497202 (MainThread): 
2021-06-05 20:33:22.497470 (MainThread): Completed with 1 error and 0 warnings:
2021-06-05 20:33:22.497767 (MainThread): 
2021-06-05 20:33:22.497987 (MainThread): Database Error in model fct_fee (models/Facts/fct_fee.sql)
2021-06-05 20:33:22.498205 (MainThread):   Unrecognized name: AuditCreatedDatetime at [5:31]
2021-06-05 20:33:22.498394 (MainThread):   compiled SQL at target/run/werkspot_technical_challenge/models/Facts/fct_fee.sql
2021-06-05 20:33:22.498575 (MainThread): 
Done. PASS=0 WARN=0 ERROR=1 SKIP=0 TOTAL=1
2021-06-05 20:33:22.498907 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f991d8a8610>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f991de12950>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f991dc681d0>]}
2021-06-05 20:33:22.499173 (MainThread): Flushing usage events
2021-06-05 20:34:17.088015 (MainThread): Running with dbt=0.19.1
2021-06-05 20:34:17.876868 (MainThread): running dbt with arguments Namespace(cls=<class 'dbt.task.run.RunTask'>, debug=False, defer=None, exclude=None, fail_fast=False, full_refresh=False, log_cache_events=False, log_format='default', models=['fct_fee'], partial_parse=None, profile=None, profiles_dir='/Users/mac/.dbt', project_dir=None, record_timing_info=None, rpc_method='run', selector_name=None, single_threaded=False, state=None, strict=False, target=None, test_new_parser=False, threads=None, use_cache=True, use_colors=None, vars='{}', version_check=True, warn_error=False, which='run', write_json=True)
2021-06-05 20:34:17.878388 (MainThread): Tracking: tracking
2021-06-05 20:34:17.888610 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f843b01b2d0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f843b01b550>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f843b01b190>]}
2021-06-05 20:34:17.902888 (MainThread): Partial parsing not enabled
2021-06-05 20:34:17.904671 (MainThread): Parsing macros/etc.sql
2021-06-05 20:34:17.909085 (MainThread): Parsing macros/catalog.sql
2021-06-05 20:34:17.918376 (MainThread): Parsing macros/adapters.sql
2021-06-05 20:34:17.947560 (MainThread): Parsing macros/materializations/seed.sql
2021-06-05 20:34:17.951259 (MainThread): Parsing macros/materializations/view.sql
2021-06-05 20:34:17.954949 (MainThread): Parsing macros/materializations/table.sql
2021-06-05 20:34:17.968627 (MainThread): Parsing macros/materializations/copy.sql
2021-06-05 20:34:17.974585 (MainThread): Parsing macros/materializations/incremental.sql
2021-06-05 20:34:17.996764 (MainThread): Parsing macros/materializations/snapshot.sql
2021-06-05 20:34:18.000719 (MainThread): Parsing macros/core.sql
2021-06-05 20:34:18.006336 (MainThread): Parsing macros/materializations/helpers.sql
2021-06-05 20:34:18.018353 (MainThread): Parsing macros/materializations/snapshot/snapshot_merge.sql
2021-06-05 20:34:18.020721 (MainThread): Parsing macros/materializations/snapshot/strategies.sql
2021-06-05 20:34:18.044616 (MainThread): Parsing macros/materializations/snapshot/snapshot.sql
2021-06-05 20:34:18.089262 (MainThread): Parsing macros/materializations/seed/seed.sql
2021-06-05 20:34:18.117344 (MainThread): Parsing macros/materializations/incremental/helpers.sql
2021-06-05 20:34:18.119833 (MainThread): Parsing macros/materializations/incremental/incremental.sql
2021-06-05 20:34:18.128239 (MainThread): Parsing macros/materializations/common/merge.sql
2021-06-05 20:34:18.147057 (MainThread): Parsing macros/materializations/table/table.sql
2021-06-05 20:34:18.156789 (MainThread): Parsing macros/materializations/view/view.sql
2021-06-05 20:34:18.165248 (MainThread): Parsing macros/materializations/view/create_or_replace_view.sql
2021-06-05 20:34:18.172100 (MainThread): Parsing macros/etc/get_custom_alias.sql
2021-06-05 20:34:18.173420 (MainThread): Parsing macros/etc/query.sql
2021-06-05 20:34:18.174843 (MainThread): Parsing macros/etc/is_incremental.sql
2021-06-05 20:34:18.177018 (MainThread): Parsing macros/etc/datetime.sql
2021-06-05 20:34:18.188967 (MainThread): Parsing macros/etc/get_custom_schema.sql
2021-06-05 20:34:18.191570 (MainThread): Parsing macros/etc/get_custom_database.sql
2021-06-05 20:34:18.194042 (MainThread): Parsing macros/adapters/common.sql
2021-06-05 20:34:18.252168 (MainThread): Parsing macros/schema_tests/relationships.sql
2021-06-05 20:34:18.254721 (MainThread): Parsing macros/schema_tests/not_null.sql
2021-06-05 20:34:18.256755 (MainThread): Parsing macros/schema_tests/unique.sql
2021-06-05 20:34:18.259029 (MainThread): Parsing macros/schema_tests/accepted_values.sql
2021-06-05 20:34:18.269982 (MainThread): Partial parsing not enabled
2021-06-05 20:34:18.302624 (MainThread): Acquiring new bigquery connection "model.werkspot_technical_challenge.dim_service".
2021-06-05 20:34:18.322341 (MainThread): Acquiring new bigquery connection "model.werkspot_technical_challenge.dim_professional".
2021-06-05 20:34:18.330276 (MainThread): Acquiring new bigquery connection "model.werkspot_technical_challenge.fct_fee".
2021-06-05 20:34:18.337539 (MainThread): Acquiring new bigquery connection "model.werkspot_technical_challenge.event_logs_stg".
2021-06-05 20:34:18.404000 (MainThread): Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '25d62651-d779-4e0a-a147-a814bdf77dbb', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f843b2e2b90>]}
2021-06-05 20:34:18.421654 (MainThread): Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '25d62651-d779-4e0a-a147-a814bdf77dbb', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f843b4320d0>]}
2021-06-05 20:34:18.422177 (MainThread): Found 4 models, 0 tests, 0 snapshots, 0 analyses, 156 macros, 0 operations, 0 seed files, 0 sources, 0 exposures
2021-06-05 20:34:18.423442 (MainThread): 
2021-06-05 20:34:18.423905 (MainThread): Acquiring new bigquery connection "master".
2021-06-05 20:34:18.425080 (ThreadPoolExecutor-0_0): Acquiring new bigquery connection "list_poetic-genius-315513".
2021-06-05 20:34:18.425387 (ThreadPoolExecutor-0_0): Opening a new connection, currently in state init
2021-06-05 20:34:20.831555 (ThreadPoolExecutor-1_0): Acquiring new bigquery connection "list_poetic-genius-315513_events_information".
2021-06-05 20:34:20.831915 (ThreadPoolExecutor-1_0): Opening a new connection, currently in state closed
2021-06-05 20:34:20.832229 (ThreadPoolExecutor-1_0): Client.dataset is deprecated and will be removed in a future version. Use a string like 'my_project.my_dataset' or a cloud.google.bigquery.DatasetReference object, instead.
2021-06-05 20:34:21.961854 (MainThread): 01:34:21 | Concurrency: 1 threads (target='dev')
2021-06-05 20:34:21.962227 (MainThread): 01:34:21 | 
2021-06-05 20:34:21.964520 (Thread-1): Began running node model.werkspot_technical_challenge.fct_fee
2021-06-05 20:34:21.964936 (Thread-1): 01:34:21 | 1 of 1 START incremental model events_information.fct_fee............ [RUN]
2021-06-05 20:34:21.965412 (Thread-1): Acquiring new bigquery connection "model.werkspot_technical_challenge.fct_fee".
2021-06-05 20:34:21.966752 (Thread-1): unclosed <socket.socket fd=12, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('192.168.0.104', 61510), raddr=('142.250.185.42', 443)>
2021-06-05 20:34:21.967007 (Thread-1): unclosed <socket.socket fd=11, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('192.168.0.104', 61509), raddr=('172.217.169.234', 443)>
2021-06-05 20:34:21.967208 (Thread-1): unclosed <socket.socket fd=13, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('192.168.0.104', 61511), raddr=('142.250.185.42', 443)>
2021-06-05 20:34:21.967702 (Thread-1): Compiling model.werkspot_technical_challenge.fct_fee
2021-06-05 20:34:21.973586 (Thread-1): Writing injected SQL for node "model.werkspot_technical_challenge.fct_fee"
2021-06-05 20:34:21.974119 (Thread-1): finished collecting timing info
2021-06-05 20:34:22.045152 (Thread-1): Writing runtime SQL for node "model.werkspot_technical_challenge.fct_fee"
2021-06-05 20:34:22.046040 (Thread-1): Opening a new connection, currently in state closed
2021-06-05 20:34:22.046263 (Thread-1): On model.werkspot_technical_challenge.fct_fee: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "werkspot_technical_challenge", "target_name": "dev", "node_id": "model.werkspot_technical_challenge.fct_fee"} */


  create or replace table `poetic-genius-315513`.`events_information`.`fct_fee`
  partition by datetime_trunc(AuditCreatedDatetime, day)
  
  OPTIONS()
  as (
    



SELECT
  ProfessionalID,
  
  (CASE 
    WHEN ParsedMetadata[OFFSET(0)]='' 
      THEN 'Not provided' 
      ELSE  ParsedMetadata[OFFSET(0)]
    END
  ) AS ServiceID,
  
  EventID,
  EventType,
  CreatedAt,
  
  (CASE 
    WHEN ParsedMetadata[OFFSET(0)]!='' 
      THEN CAST(ParsedMetadata[OFFSET(3)] AS FLOAT64) 
      ELSE 0.0 
   END
  ) as LeadFee,

  AuditCreatedDatetime
 
FROM
(
  SELECT
      EventID,
      EventType,
      ProfessionalID,
      CreatedAt,
      SPLIT(Metadata,'_') as ParsedMetadata,
      CURRENT_DATETIME() as AuditCreatedDatetime, -- Audit column
    FROM 
     `poetic-genius-315513.events_information.event_logs_stg`
     where Metadata!=''
)

    -- this will only be applied on an incremental run & will filter data early
    -- `poetic-genius-315513`.`events_information`.`fct_fee` will give last run date which can then be used to pick CDC records daily
    
  );
  
2021-06-05 20:34:26.067849 (Thread-1): finished collecting timing info
2021-06-05 20:34:26.068437 (Thread-1): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '25d62651-d779-4e0a-a147-a814bdf77dbb', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f843b61b410>]}
2021-06-05 20:34:26.068913 (Thread-1): 01:34:26 | 1 of 1 OK created incremental model events_information.fct_fee....... [CREATE TABLE (16.5k rows, 1.6 MB processed) in 4.10s]
2021-06-05 20:34:26.069115 (Thread-1): Finished running node model.werkspot_technical_challenge.fct_fee
2021-06-05 20:34:26.100021 (MainThread): Acquiring new bigquery connection "master".
2021-06-05 20:34:26.100669 (MainThread): 01:34:26 | 
2021-06-05 20:34:26.100931 (MainThread): 01:34:26 | Finished running 1 incremental model in 7.68s.
2021-06-05 20:34:26.101185 (MainThread): Connection 'master' was properly closed.
2021-06-05 20:34:26.101395 (MainThread): Connection 'model.werkspot_technical_challenge.fct_fee' was properly closed.
2021-06-05 20:34:26.143902 (MainThread): 
2021-06-05 20:34:26.144259 (MainThread): Completed successfully
2021-06-05 20:34:26.144604 (MainThread): 
Done. PASS=1 WARN=0 ERROR=0 SKIP=0 TOTAL=1
2021-06-05 20:34:26.145118 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f843b467a90>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f843b4e5b10>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f843b4e5910>]}
2021-06-05 20:34:26.145417 (MainThread): Flushing usage events
2021-06-05 20:47:25.052519 (MainThread): Running with dbt=0.19.1
2021-06-05 20:47:26.314796 (MainThread): running dbt with arguments Namespace(cls=<class 'dbt.task.run.RunTask'>, debug=False, defer=None, exclude=None, fail_fast=False, full_refresh=False, log_cache_events=False, log_format='default', models=['fct_fee'], partial_parse=None, profile=None, profiles_dir='/Users/mac/.dbt', project_dir=None, record_timing_info=None, rpc_method='run', selector_name=None, single_threaded=False, state=None, strict=False, target=None, test_new_parser=False, threads=None, use_cache=True, use_colors=None, vars='{}', version_check=True, warn_error=False, which='run', write_json=True)
2021-06-05 20:47:26.316346 (MainThread): Tracking: tracking
2021-06-05 20:47:26.327270 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fdef100c910>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fdef100ca10>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fdef100c0d0>]}
2021-06-05 20:47:26.342156 (MainThread): Partial parsing not enabled
2021-06-05 20:47:26.343829 (MainThread): Parsing macros/etc.sql
2021-06-05 20:47:26.348787 (MainThread): Parsing macros/catalog.sql
2021-06-05 20:47:26.358312 (MainThread): Parsing macros/adapters.sql
2021-06-05 20:47:26.388255 (MainThread): Parsing macros/materializations/seed.sql
2021-06-05 20:47:26.392631 (MainThread): Parsing macros/materializations/view.sql
2021-06-05 20:47:26.396895 (MainThread): Parsing macros/materializations/table.sql
2021-06-05 20:47:26.411089 (MainThread): Parsing macros/materializations/copy.sql
2021-06-05 20:47:26.418016 (MainThread): Parsing macros/materializations/incremental.sql
2021-06-05 20:47:26.439052 (MainThread): Parsing macros/materializations/snapshot.sql
2021-06-05 20:47:26.443937 (MainThread): Parsing macros/core.sql
2021-06-05 20:47:26.449387 (MainThread): Parsing macros/materializations/helpers.sql
2021-06-05 20:47:26.462020 (MainThread): Parsing macros/materializations/snapshot/snapshot_merge.sql
2021-06-05 20:47:26.464896 (MainThread): Parsing macros/materializations/snapshot/strategies.sql
2021-06-05 20:47:26.488669 (MainThread): Parsing macros/materializations/snapshot/snapshot.sql
2021-06-05 20:47:26.532777 (MainThread): Parsing macros/materializations/seed/seed.sql
2021-06-05 20:47:26.560922 (MainThread): Parsing macros/materializations/incremental/helpers.sql
2021-06-05 20:47:26.563552 (MainThread): Parsing macros/materializations/incremental/incremental.sql
2021-06-05 20:47:26.571832 (MainThread): Parsing macros/materializations/common/merge.sql
2021-06-05 20:47:26.591057 (MainThread): Parsing macros/materializations/table/table.sql
2021-06-05 20:47:26.600230 (MainThread): Parsing macros/materializations/view/view.sql
2021-06-05 20:47:26.608591 (MainThread): Parsing macros/materializations/view/create_or_replace_view.sql
2021-06-05 20:47:26.615114 (MainThread): Parsing macros/etc/get_custom_alias.sql
2021-06-05 20:47:26.616445 (MainThread): Parsing macros/etc/query.sql
2021-06-05 20:47:26.617910 (MainThread): Parsing macros/etc/is_incremental.sql
2021-06-05 20:47:26.620138 (MainThread): Parsing macros/etc/datetime.sql
2021-06-05 20:47:26.631873 (MainThread): Parsing macros/etc/get_custom_schema.sql
2021-06-05 20:47:26.634530 (MainThread): Parsing macros/etc/get_custom_database.sql
2021-06-05 20:47:26.636835 (MainThread): Parsing macros/adapters/common.sql
2021-06-05 20:47:26.694338 (MainThread): Parsing macros/schema_tests/relationships.sql
2021-06-05 20:47:26.698677 (MainThread): Parsing macros/schema_tests/not_null.sql
2021-06-05 20:47:26.701109 (MainThread): Parsing macros/schema_tests/unique.sql
2021-06-05 20:47:26.703822 (MainThread): Parsing macros/schema_tests/accepted_values.sql
2021-06-05 20:47:26.714272 (MainThread): Partial parsing not enabled
2021-06-05 20:47:26.749179 (MainThread): Acquiring new bigquery connection "model.werkspot_technical_challenge.dim_service".
2021-06-05 20:47:26.768845 (MainThread): Acquiring new bigquery connection "model.werkspot_technical_challenge.dim_professional".
2021-06-05 20:47:26.778424 (MainThread): Acquiring new bigquery connection "model.werkspot_technical_challenge.fct_fee".
2021-06-05 20:47:26.787757 (MainThread): Acquiring new bigquery connection "model.werkspot_technical_challenge.event_logs_stg".
2021-06-05 20:47:26.853554 (MainThread): Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '70883763-d525-4c8e-a12e-69a632083994', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fdef12ee810>]}
2021-06-05 20:47:26.869197 (MainThread): Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '70883763-d525-4c8e-a12e-69a632083994', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fdef14193d0>]}
2021-06-05 20:47:26.869720 (MainThread): Found 4 models, 0 tests, 0 snapshots, 0 analyses, 156 macros, 0 operations, 0 seed files, 0 sources, 0 exposures
2021-06-05 20:47:26.871080 (MainThread): 
2021-06-05 20:47:26.871539 (MainThread): Acquiring new bigquery connection "master".
2021-06-05 20:47:26.872584 (ThreadPoolExecutor-0_0): Acquiring new bigquery connection "list_poetic-genius-315513".
2021-06-05 20:47:26.872885 (ThreadPoolExecutor-0_0): Opening a new connection, currently in state init
2021-06-05 20:47:29.517623 (ThreadPoolExecutor-1_0): Acquiring new bigquery connection "list_poetic-genius-315513_events_information".
2021-06-05 20:47:29.517987 (ThreadPoolExecutor-1_0): Opening a new connection, currently in state closed
2021-06-05 20:47:29.518299 (ThreadPoolExecutor-1_0): Client.dataset is deprecated and will be removed in a future version. Use a string like 'my_project.my_dataset' or a cloud.google.bigquery.DatasetReference object, instead.
2021-06-05 20:47:30.749135 (MainThread): 01:47:30 | Concurrency: 1 threads (target='dev')
2021-06-05 20:47:30.749516 (MainThread): 01:47:30 | 
2021-06-05 20:47:30.751777 (Thread-1): Began running node model.werkspot_technical_challenge.fct_fee
2021-06-05 20:47:30.752187 (Thread-1): 01:47:30 | 1 of 1 START incremental model events_information.fct_fee............ [RUN]
2021-06-05 20:47:30.752683 (Thread-1): Acquiring new bigquery connection "model.werkspot_technical_challenge.fct_fee".
2021-06-05 20:47:30.754024 (Thread-1): unclosed <socket.socket fd=12, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('192.168.0.104', 61735), raddr=('142.250.185.42', 443)>
2021-06-05 20:47:30.754282 (Thread-1): unclosed <socket.socket fd=11, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('192.168.0.104', 61734), raddr=('172.217.169.234', 443)>
2021-06-05 20:47:30.754488 (Thread-1): unclosed <socket.socket fd=13, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('192.168.0.104', 61736), raddr=('142.250.185.42', 443)>
2021-06-05 20:47:30.754996 (Thread-1): Compiling model.werkspot_technical_challenge.fct_fee
2021-06-05 20:47:30.761757 (Thread-1): Writing injected SQL for node "model.werkspot_technical_challenge.fct_fee"
2021-06-05 20:47:30.762973 (Thread-1): finished collecting timing info
2021-06-05 20:47:30.832819 (Thread-1): Writing runtime SQL for node "model.werkspot_technical_challenge.fct_fee"
2021-06-05 20:47:30.834019 (Thread-1): Opening a new connection, currently in state closed
2021-06-05 20:47:30.834259 (Thread-1): On model.werkspot_technical_challenge.fct_fee: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "werkspot_technical_challenge", "target_name": "dev", "node_id": "model.werkspot_technical_challenge.fct_fee"} */


  create or replace table `poetic-genius-315513`.`events_information`.`fct_fee`
  partition by datetime_trunc(AuditCreatedDatetime, day)
  
  OPTIONS()
  as (
    



SELECT
  ProfessionalID,
  
  (CASE 
    WHEN ParsedMetadata[OFFSET(0)]='' 
      THEN 'Not provided' 
      ELSE  ParsedMetadata[OFFSET(0)]
    END
  ) AS ServiceID,
  
  EventID,
  EventType,
  CreatedAt,
  
  (CASE 
    WHEN ParsedMetadata[OFFSET(0)]!='' 
      THEN CAST(ParsedMetadata[OFFSET(3)] AS FLOAT64) 
      ELSE 0.0 
   END
  ) as LeadFee,

  AuditCreatedDatetime
 
FROM
(
  SELECT
      EventID,
      EventType,
      ProfessionalID,
      CreatedAt,
      SPLIT(Metadata,'_') as ParsedMetadata,
      CURRENT_DATETIME() as AuditCreatedDatetime, -- Audit column
    
    FROM 
  
      `poetic-genius-315513`.`events_information`.`event_logs_stg`
     

      -- this will only be applied on an incremental run & will filter data early
      -- `poetic-genius-315513`.`events_information`.`fct_fee` will give last run date which can then be used to pick CDC records daily
      
)
  );
  
2021-06-05 20:47:34.880809 (Thread-1): finished collecting timing info
2021-06-05 20:47:34.881336 (Thread-1): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '70883763-d525-4c8e-a12e-69a632083994', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fdef12ada10>]}
2021-06-05 20:47:34.881728 (Thread-1): 01:47:34 | 1 of 1 OK created incremental model events_information.fct_fee....... [CREATE TABLE (19.0k rows, 1.6 MB processed) in 4.13s]
2021-06-05 20:47:34.881881 (Thread-1): Finished running node model.werkspot_technical_challenge.fct_fee
2021-06-05 20:47:34.987126 (MainThread): Acquiring new bigquery connection "master".
2021-06-05 20:47:34.987732 (MainThread): 01:47:34 | 
2021-06-05 20:47:34.987988 (MainThread): 01:47:34 | Finished running 1 incremental model in 8.12s.
2021-06-05 20:47:34.988332 (MainThread): Connection 'master' was properly closed.
2021-06-05 20:47:34.988563 (MainThread): Connection 'model.werkspot_technical_challenge.fct_fee' was properly closed.
2021-06-05 20:47:35.005987 (MainThread): 
2021-06-05 20:47:35.006348 (MainThread): Completed successfully
2021-06-05 20:47:35.006604 (MainThread): 
Done. PASS=1 WARN=0 ERROR=0 SKIP=0 TOTAL=1
2021-06-05 20:47:35.006939 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fdef1448d50>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fdef1801f50>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fdef14fa090>]}
2021-06-05 20:47:35.007209 (MainThread): Flushing usage events
2021-06-06 18:36:36.266917 (MainThread): Running with dbt=0.19.1
2021-06-06 18:36:41.749867 (MainThread): running dbt with arguments Namespace(cls=<class 'dbt.task.run.RunTask'>, debug=False, defer=None, exclude=None, fail_fast=False, full_refresh=False, log_cache_events=False, log_format='default', models=['availibility_snapshot'], partial_parse=None, profile=None, profiles_dir='/Users/mac/.dbt', project_dir=None, record_timing_info=None, rpc_method='run', selector_name=None, single_threaded=False, state=None, strict=False, target=None, test_new_parser=False, threads=None, use_cache=True, use_colors=None, vars='{}', version_check=True, warn_error=False, which='run', write_json=True)
2021-06-06 18:36:41.751626 (MainThread): Tracking: tracking
2021-06-06 18:36:41.784416 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fd28388a050>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fd28388af10>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fd28388ac50>]}
2021-06-06 18:36:41.806602 (MainThread): Partial parsing not enabled
2021-06-06 18:36:41.814969 (MainThread): Parsing macros/etc.sql
2021-06-06 18:36:41.832671 (MainThread): Parsing macros/catalog.sql
2021-06-06 18:36:41.849110 (MainThread): Parsing macros/adapters.sql
2021-06-06 18:36:41.882955 (MainThread): Parsing macros/materializations/seed.sql
2021-06-06 18:36:41.888154 (MainThread): Parsing macros/materializations/view.sql
2021-06-06 18:36:41.893334 (MainThread): Parsing macros/materializations/table.sql
2021-06-06 18:36:41.909549 (MainThread): Parsing macros/materializations/copy.sql
2021-06-06 18:36:41.918044 (MainThread): Parsing macros/materializations/incremental.sql
2021-06-06 18:36:41.936437 (MainThread): Parsing macros/materializations/snapshot.sql
2021-06-06 18:36:41.943481 (MainThread): Parsing macros/core.sql
2021-06-06 18:36:41.951538 (MainThread): Parsing macros/materializations/helpers.sql
2021-06-06 18:36:41.965916 (MainThread): Parsing macros/materializations/snapshot/snapshot_merge.sql
2021-06-06 18:36:41.970224 (MainThread): Parsing macros/materializations/snapshot/strategies.sql
2021-06-06 18:36:41.998687 (MainThread): Parsing macros/materializations/snapshot/snapshot.sql
2021-06-06 18:36:42.050462 (MainThread): Parsing macros/materializations/seed/seed.sql
2021-06-06 18:36:42.083493 (MainThread): Parsing macros/materializations/incremental/helpers.sql
2021-06-06 18:36:42.087956 (MainThread): Parsing macros/materializations/incremental/incremental.sql
2021-06-06 18:36:42.098932 (MainThread): Parsing macros/materializations/common/merge.sql
2021-06-06 18:36:42.123549 (MainThread): Parsing macros/materializations/table/table.sql
2021-06-06 18:36:42.135168 (MainThread): Parsing macros/materializations/view/view.sql
2021-06-06 18:36:42.145715 (MainThread): Parsing macros/materializations/view/create_or_replace_view.sql
2021-06-06 18:36:42.155599 (MainThread): Parsing macros/etc/get_custom_alias.sql
2021-06-06 18:36:42.158172 (MainThread): Parsing macros/etc/query.sql
2021-06-06 18:36:42.160899 (MainThread): Parsing macros/etc/is_incremental.sql
2021-06-06 18:36:42.165453 (MainThread): Parsing macros/etc/datetime.sql
2021-06-06 18:36:42.181764 (MainThread): Parsing macros/etc/get_custom_schema.sql
2021-06-06 18:36:42.186357 (MainThread): Parsing macros/etc/get_custom_database.sql
2021-06-06 18:36:42.191628 (MainThread): Parsing macros/adapters/common.sql
2021-06-06 18:36:42.264317 (MainThread): Parsing macros/schema_tests/relationships.sql
2021-06-06 18:36:42.267893 (MainThread): Parsing macros/schema_tests/not_null.sql
2021-06-06 18:36:42.271212 (MainThread): Parsing macros/schema_tests/unique.sql
2021-06-06 18:36:42.275073 (MainThread): Parsing macros/schema_tests/accepted_values.sql
2021-06-06 18:36:42.285624 (MainThread): Partial parsing not enabled
2021-06-06 18:36:42.332659 (MainThread): Acquiring new bigquery connection "model.werkspot_technical_challenge.availability_snapshot".
2021-06-06 18:36:42.366736 (MainThread): Acquiring new bigquery connection "model.werkspot_technical_challenge.dim_service".
2021-06-06 18:36:42.450980 (MainThread): Acquiring new bigquery connection "model.werkspot_technical_challenge.dim_professional".
2021-06-06 18:36:42.460442 (MainThread): Acquiring new bigquery connection "model.werkspot_technical_challenge.fct_fee".
2021-06-06 18:36:42.473864 (MainThread): Acquiring new bigquery connection "model.werkspot_technical_challenge.event_logs_stg".
2021-06-06 18:36:43.093643 (MainThread): Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '27a7d8c8-aa28-4a77-9137-3f38aeb01833', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fd283a75c90>]}
2021-06-06 18:36:43.404804 (MainThread): Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '27a7d8c8-aa28-4a77-9137-3f38aeb01833', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fd283a5e3d0>]}
2021-06-06 18:36:43.405788 (MainThread): Found 5 models, 0 tests, 0 snapshots, 0 analyses, 156 macros, 0 operations, 0 seed files, 0 sources, 0 exposures
2021-06-06 18:36:43.406677 (MainThread): The selector 'availibility_snapshot' does not match any nodes and will be ignored
2021-06-06 18:36:43.407380 (MainThread): WARNING: Nothing to do. Try checking your model configs and model specification args
2021-06-06 18:36:43.407782 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fd283a6d310>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fd283a8cf50>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fd283b775d0>]}
2021-06-06 18:36:43.408195 (MainThread): Flushing usage events
2021-06-06 18:36:44.664042 (MainThread): Connection 'model.werkspot_technical_challenge.event_logs_stg' was properly closed.
2021-06-06 18:37:59.080524 (MainThread): Running with dbt=0.19.1
2021-06-06 18:38:00.410386 (MainThread): running dbt with arguments Namespace(cls=<class 'dbt.task.run.RunTask'>, debug=False, defer=None, exclude=None, fail_fast=False, full_refresh=False, log_cache_events=False, log_format='default', models=['availibility_snapshot'], partial_parse=None, profile=None, profiles_dir='/Users/mac/.dbt', project_dir=None, record_timing_info=None, rpc_method='run', selector_name=None, single_threaded=False, state=None, strict=False, target=None, test_new_parser=False, threads=None, use_cache=True, use_colors=None, vars='{}', version_check=True, warn_error=False, which='run', write_json=True)
2021-06-06 18:38:00.413550 (MainThread): Tracking: tracking
2021-06-06 18:38:00.428554 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ff5b900d410>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ff5b9000950>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ff5b900d9d0>]}
2021-06-06 18:38:00.443687 (MainThread): Partial parsing not enabled
2021-06-06 18:38:00.445455 (MainThread): Parsing macros/etc.sql
2021-06-06 18:38:00.450150 (MainThread): Parsing macros/catalog.sql
2021-06-06 18:38:00.459664 (MainThread): Parsing macros/adapters.sql
2021-06-06 18:38:00.490302 (MainThread): Parsing macros/materializations/seed.sql
2021-06-06 18:38:00.495305 (MainThread): Parsing macros/materializations/view.sql
2021-06-06 18:38:00.499337 (MainThread): Parsing macros/materializations/table.sql
2021-06-06 18:38:00.517792 (MainThread): Parsing macros/materializations/copy.sql
2021-06-06 18:38:00.524267 (MainThread): Parsing macros/materializations/incremental.sql
2021-06-06 18:38:00.541965 (MainThread): Parsing macros/materializations/snapshot.sql
2021-06-06 18:38:00.546528 (MainThread): Parsing macros/core.sql
2021-06-06 18:38:00.552676 (MainThread): Parsing macros/materializations/helpers.sql
2021-06-06 18:38:00.564948 (MainThread): Parsing macros/materializations/snapshot/snapshot_merge.sql
2021-06-06 18:38:00.567699 (MainThread): Parsing macros/materializations/snapshot/strategies.sql
2021-06-06 18:38:00.592253 (MainThread): Parsing macros/materializations/snapshot/snapshot.sql
2021-06-06 18:38:00.640253 (MainThread): Parsing macros/materializations/seed/seed.sql
2021-06-06 18:38:00.670548 (MainThread): Parsing macros/materializations/incremental/helpers.sql
2021-06-06 18:38:00.673461 (MainThread): Parsing macros/materializations/incremental/incremental.sql
2021-06-06 18:38:00.682002 (MainThread): Parsing macros/materializations/common/merge.sql
2021-06-06 18:38:00.701627 (MainThread): Parsing macros/materializations/table/table.sql
2021-06-06 18:38:00.711248 (MainThread): Parsing macros/materializations/view/view.sql
2021-06-06 18:38:00.721570 (MainThread): Parsing macros/materializations/view/create_or_replace_view.sql
2021-06-06 18:38:00.728165 (MainThread): Parsing macros/etc/get_custom_alias.sql
2021-06-06 18:38:00.729572 (MainThread): Parsing macros/etc/query.sql
2021-06-06 18:38:00.731163 (MainThread): Parsing macros/etc/is_incremental.sql
2021-06-06 18:38:00.733663 (MainThread): Parsing macros/etc/datetime.sql
2021-06-06 18:38:00.746558 (MainThread): Parsing macros/etc/get_custom_schema.sql
2021-06-06 18:38:00.749270 (MainThread): Parsing macros/etc/get_custom_database.sql
2021-06-06 18:38:00.752120 (MainThread): Parsing macros/adapters/common.sql
2021-06-06 18:38:00.813231 (MainThread): Parsing macros/schema_tests/relationships.sql
2021-06-06 18:38:00.817440 (MainThread): Parsing macros/schema_tests/not_null.sql
2021-06-06 18:38:00.820015 (MainThread): Parsing macros/schema_tests/unique.sql
2021-06-06 18:38:00.822745 (MainThread): Parsing macros/schema_tests/accepted_values.sql
2021-06-06 18:38:00.837463 (MainThread): Partial parsing not enabled
2021-06-06 18:38:00.871308 (MainThread): Acquiring new bigquery connection "model.werkspot_technical_challenge.availibility_snapshot".
2021-06-06 18:38:00.886897 (MainThread): Acquiring new bigquery connection "model.werkspot_technical_challenge.dim_service".
2021-06-06 18:38:00.898893 (MainThread): Acquiring new bigquery connection "model.werkspot_technical_challenge.dim_professional".
2021-06-06 18:38:00.906568 (MainThread): Acquiring new bigquery connection "model.werkspot_technical_challenge.fct_fee".
2021-06-06 18:38:00.916597 (MainThread): Acquiring new bigquery connection "model.werkspot_technical_challenge.event_logs_stg".
2021-06-06 18:38:00.984336 (MainThread): Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '3a5dc857-20a2-4b28-8e2b-5a137e3ec4b8', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ff5b92ca6d0>]}
2021-06-06 18:38:01.002235 (MainThread): Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '3a5dc857-20a2-4b28-8e2b-5a137e3ec4b8', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ff5b9396d50>]}
2021-06-06 18:38:01.006140 (MainThread): Found 5 models, 0 tests, 0 snapshots, 0 analyses, 156 macros, 0 operations, 0 seed files, 0 sources, 0 exposures
2021-06-06 18:38:01.007289 (MainThread): 
2021-06-06 18:38:01.007803 (MainThread): Acquiring new bigquery connection "master".
2021-06-06 18:38:01.008813 (ThreadPoolExecutor-0_0): Acquiring new bigquery connection "list_poetic-genius-315513".
2021-06-06 18:38:01.009172 (ThreadPoolExecutor-0_0): Opening a new connection, currently in state init
2021-06-06 18:38:08.744868 (ThreadPoolExecutor-1_0): Acquiring new bigquery connection "list_poetic-genius-315513_events_information".
2021-06-06 18:38:08.745224 (ThreadPoolExecutor-1_0): Opening a new connection, currently in state closed
2021-06-06 18:38:08.745529 (ThreadPoolExecutor-1_0): Client.dataset is deprecated and will be removed in a future version. Use a string like 'my_project.my_dataset' or a cloud.google.bigquery.DatasetReference object, instead.
2021-06-06 18:38:09.997142 (MainThread): 23:38:09 | Concurrency: 1 threads (target='dev')
2021-06-06 18:38:09.997517 (MainThread): 23:38:09 | 
2021-06-06 18:38:10.014404 (Thread-1): Began running node model.werkspot_technical_challenge.availibility_snapshot
2021-06-06 18:38:10.014993 (Thread-1): 23:38:10 | 1 of 1 START incremental model events_information.availibility_snapshot [RUN]
2021-06-06 18:38:10.015708 (Thread-1): Acquiring new bigquery connection "model.werkspot_technical_challenge.availibility_snapshot".
2021-06-06 18:38:10.016286 (Thread-1): unclosed <socket.socket fd=13, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('192.168.0.104', 54148), raddr=('142.250.185.42', 443)>
2021-06-06 18:38:10.016493 (Thread-1): Compiling model.werkspot_technical_challenge.availibility_snapshot
2021-06-06 18:38:10.021466 (Thread-1): Writing injected SQL for node "model.werkspot_technical_challenge.availibility_snapshot"
2021-06-06 18:38:10.022161 (Thread-1): finished collecting timing info
2021-06-06 18:38:10.095591 (Thread-1): Writing runtime SQL for node "model.werkspot_technical_challenge.availibility_snapshot"
2021-06-06 18:38:10.096317 (Thread-1): Opening a new connection, currently in state closed
2021-06-06 18:38:10.096535 (Thread-1): On model.werkspot_technical_challenge.availibility_snapshot: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "werkspot_technical_challenge", "target_name": "dev", "node_id": "model.werkspot_technical_challenge.availibility_snapshot"} */


  create or replace table `poetic-genius-315513`.`events_information`.`availibility_snapshot`
  partition by datetime_trunc(AuditCreatedDatetime, day)
  
  OPTIONS()
  as (
    


SELECT

  CreatedAt,
  COUNT(DISTINCT CASE WHEN ProfessionalStatus IS TRUE THEN ProfessionalID END) AS ActiveProfessionals

FROM 
(
  SELECT
    *,
    CASE
      WHEN 
        EventType IN ('created_account','became_unable_to_propose') AND NextEvent IS NULL 
        THEN False 
      WHEN EventType IN ('created_account','became_able_to_propose') AND NextEvent='became_unable_to_propose' 
        THEN False 
      WHEN EventType IN ('proposed','became_unable_to_propose') AND (NextEvent='became_unable_to_propose') 
        THEN False
      
      WHEN EventType IN ('proposed','became_able_to_propose','became_unable_to_propose') AND 
           NextEvent IN ('proposed','became_able_to_propose') 
        THEN True
      WHEN EventType IN ('proposed','became_able_to_propose','became_unable_to_propose') AND 
           NextEvent IN ('proposed','became_able_to_propose') 
        THEN True
      WHEN EventType IN ('created_account','became_able_to_propose','proposed') AND 
           (NextEvent IS NULL OR NextEvent='became_able_to_propose') 
        THEN True
    END AS ProfessionalStatus
  
  FROM 
  (
    SELECT

     DISTINCT
      EXTRACT(DATE FROM CAST(CreatedAt AS DATETIME)) AS CreatedAt,
      ProfessionalID,
      EventType,
      LEAD(EventType,1 ) OVER 
          (PARTITION By EXTRACT(DATE FROM CAST(CreatedAt AS DATETIME)),ProfessionalID 
            ORDER BY CreatedAt ASC) as NextEvent
    FROM
    (
      SELECT 

        DISTINCT
          CreatedAt,
          ProfessionalID,
          EventType

      FROM 
        `poetic-genius-315513`.`events_information`.`event_logs_stg`
        
      GROUP BY 1,2,3 
      HAVING CreatedAt BETWEEN MIN(CreatedAt) AND '2020-03-10 23:59:59'
    )
  )
) 
GROUP BY 1 ORDER BY 1 ASC;
  );
  
2021-06-06 18:38:11.398680 (Thread-1): Retry attempt 1 of 1 after error: BadRequest('Syntax error: Expected ")" but got ";" at [69:26]')
2021-06-06 18:38:11.995469 (Thread-1): finished collecting timing info
2021-06-06 18:38:11.996264 (Thread-1): Database Error in model availibility_snapshot (models/Snapshot/availibility_snapshot.sql)
  Syntax error: Expected ")" but got ";" at [69:26]
  compiled SQL at target/run/werkspot_technical_challenge/models/Snapshot/availibility_snapshot.sql
Traceback (most recent call last):
  File "/opt/anaconda3/lib/python3.7/site-packages/dbt/adapters/bigquery/connections.py", line 149, in exception_handler
    yield
  File "/opt/anaconda3/lib/python3.7/site-packages/dbt/adapters/bigquery/connections.py", line 539, in _retry_and_handle
    on_error=reopen_conn_on_error)
  File "/opt/anaconda3/lib/python3.7/site-packages/google/api_core/retry.py", line 184, in retry_target
    return target()
  File "/opt/anaconda3/lib/python3.7/site-packages/dbt/adapters/bigquery/connections.py", line 327, in fn
    return self._query_and_results(client, sql, conn, job_params)
  File "/opt/anaconda3/lib/python3.7/site-packages/dbt/adapters/bigquery/connections.py", line 520, in _query_and_results
    iterator = query_job.result(timeout=timeout)
  File "/opt/anaconda3/lib/python3.7/site-packages/google/cloud/bigquery/job.py", line 3207, in result
    super(QueryJob, self).result(retry=retry, timeout=timeout)
  File "/opt/anaconda3/lib/python3.7/site-packages/google/cloud/bigquery/job.py", line 812, in result
    return super(_AsyncJob, self).result(timeout=timeout)
  File "/opt/anaconda3/lib/python3.7/site-packages/google/api_core/future/polling.py", line 130, in result
    raise self._exception
google.api_core.exceptions.BadRequest: 400 Syntax error: Expected ")" but got ";" at [69:26]

(job ID: ad1da937-e7ea-47b5-919f-d3e531c7a1e9)

                                                                                -----Query Job SQL Follows-----                                                                                

    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |
   1:/* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "werkspot_technical_challenge", "target_name": "dev", "node_id": "model.werkspot_technical_challenge.availibility_snapshot"} */
   2:
   3:
   4:  create or replace table `poetic-genius-315513`.`events_information`.`availibility_snapshot`
   5:  partition by datetime_trunc(AuditCreatedDatetime, day)
   6:  
   7:  OPTIONS()
   8:  as (
   9:    
  10:
  11:
  12:SELECT
  13:
  14:  CreatedAt,
  15:  COUNT(DISTINCT CASE WHEN ProfessionalStatus IS TRUE THEN ProfessionalID END) AS ActiveProfessionals
  16:
  17:FROM 
  18:(
  19:  SELECT
  20:    *,
  21:    CASE
  22:      WHEN 
  23:        EventType IN ('created_account','became_unable_to_propose') AND NextEvent IS NULL 
  24:        THEN False 
  25:      WHEN EventType IN ('created_account','became_able_to_propose') AND NextEvent='became_unable_to_propose' 
  26:        THEN False 
  27:      WHEN EventType IN ('proposed','became_unable_to_propose') AND (NextEvent='became_unable_to_propose') 
  28:        THEN False
  29:      
  30:      WHEN EventType IN ('proposed','became_able_to_propose','became_unable_to_propose') AND 
  31:           NextEvent IN ('proposed','became_able_to_propose') 
  32:        THEN True
  33:      WHEN EventType IN ('proposed','became_able_to_propose','became_unable_to_propose') AND 
  34:           NextEvent IN ('proposed','became_able_to_propose') 
  35:        THEN True
  36:      WHEN EventType IN ('created_account','became_able_to_propose','proposed') AND 
  37:           (NextEvent IS NULL OR NextEvent='became_able_to_propose') 
  38:        THEN True
  39:    END AS ProfessionalStatus
  40:  
  41:  FROM 
  42:  (
  43:    SELECT
  44:
  45:     DISTINCT
  46:      EXTRACT(DATE FROM CAST(CreatedAt AS DATETIME)) AS CreatedAt,
  47:      ProfessionalID,
  48:      EventType,
  49:      LEAD(EventType,1 ) OVER 
  50:          (PARTITION By EXTRACT(DATE FROM CAST(CreatedAt AS DATETIME)),ProfessionalID 
  51:            ORDER BY CreatedAt ASC) as NextEvent
  52:    FROM
  53:    (
  54:      SELECT 
  55:
  56:        DISTINCT
  57:          CreatedAt,
  58:          ProfessionalID,
  59:          EventType
  60:
  61:      FROM 
  62:        `poetic-genius-315513`.`events_information`.`event_logs_stg`
  63:        
  64:      GROUP BY 1,2,3 
  65:      HAVING CreatedAt BETWEEN MIN(CreatedAt) AND '2020-03-10 23:59:59'
  66:    )
  67:  )
  68:) 
  69:GROUP BY 1 ORDER BY 1 ASC;
  70:  );
  71:  
    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/anaconda3/lib/python3.7/site-packages/dbt/task/base.py", line 344, in safe_run
    result = self.compile_and_execute(manifest, ctx)
  File "/opt/anaconda3/lib/python3.7/site-packages/dbt/task/base.py", line 287, in compile_and_execute
    result = self.run(ctx.node, manifest)
  File "/opt/anaconda3/lib/python3.7/site-packages/dbt/task/base.py", line 389, in run
    return self.execute(compiled_node, manifest)
  File "/opt/anaconda3/lib/python3.7/site-packages/dbt/task/run.py", line 248, in execute
    result = MacroGenerator(materialization_macro, context)()
  File "/opt/anaconda3/lib/python3.7/site-packages/dbt/clients/jinja.py", line 332, in __call__
    return self.call_macro(*args, **kwargs)
  File "/opt/anaconda3/lib/python3.7/site-packages/dbt/clients/jinja.py", line 259, in call_macro
    return macro(*args, **kwargs)
  File "/opt/anaconda3/lib/python3.7/site-packages/jinja2/runtime.py", line 675, in __call__
    return self._invoke(arguments, autoescape)
  File "/opt/anaconda3/lib/python3.7/site-packages/jinja2/runtime.py", line 679, in _invoke
    rv = self._func(*arguments)
  File "<template>", line 156, in macro
  File "/opt/anaconda3/lib/python3.7/site-packages/jinja2/sandbox.py", line 462, in call
    return __context.call(__obj, *args, **kwargs)
  File "/opt/anaconda3/lib/python3.7/site-packages/jinja2/runtime.py", line 290, in call
    return __obj(*args, **kwargs)
  File "/opt/anaconda3/lib/python3.7/site-packages/dbt/clients/jinja.py", line 332, in __call__
    return self.call_macro(*args, **kwargs)
  File "/opt/anaconda3/lib/python3.7/site-packages/dbt/clients/jinja.py", line 259, in call_macro
    return macro(*args, **kwargs)
  File "/opt/anaconda3/lib/python3.7/site-packages/jinja2/runtime.py", line 675, in __call__
    return self._invoke(arguments, autoescape)
  File "/opt/anaconda3/lib/python3.7/site-packages/jinja2/runtime.py", line 679, in _invoke
    rv = self._func(*arguments)
  File "<template>", line 41, in macro
  File "/opt/anaconda3/lib/python3.7/site-packages/jinja2/sandbox.py", line 462, in call
    return __context.call(__obj, *args, **kwargs)
  File "/opt/anaconda3/lib/python3.7/site-packages/jinja2/runtime.py", line 290, in call
    return __obj(*args, **kwargs)
  File "/opt/anaconda3/lib/python3.7/site-packages/dbt/adapters/base/impl.py", line 230, in execute
    fetch=fetch
  File "/opt/anaconda3/lib/python3.7/site-packages/dbt/adapters/bigquery/connections.py", line 338, in execute
    query_job, iterator = self.raw_execute(sql, fetch=fetch)
  File "/opt/anaconda3/lib/python3.7/site-packages/dbt/adapters/bigquery/connections.py", line 329, in raw_execute
    query_job, iterator = self._retry_and_handle(msg=sql, conn=conn, fn=fn)
  File "/opt/anaconda3/lib/python3.7/site-packages/dbt/adapters/bigquery/connections.py", line 539, in _retry_and_handle
    on_error=reopen_conn_on_error)
  File "/opt/anaconda3/lib/python3.7/contextlib.py", line 130, in __exit__
    self.gen.throw(type, value, traceback)
  File "/opt/anaconda3/lib/python3.7/site-packages/dbt/adapters/bigquery/connections.py", line 153, in exception_handler
    self.handle_error(e, message)
  File "/opt/anaconda3/lib/python3.7/site-packages/dbt/adapters/bigquery/connections.py", line 141, in handle_error
    raise DatabaseException(error_msg)
dbt.exceptions.DatabaseException: Database Error in model availibility_snapshot (models/Snapshot/availibility_snapshot.sql)
  Syntax error: Expected ")" but got ";" at [69:26]
  compiled SQL at target/run/werkspot_technical_challenge/models/Snapshot/availibility_snapshot.sql
2021-06-06 18:38:12.097866 (Thread-1): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '3a5dc857-20a2-4b28-8e2b-5a137e3ec4b8', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ff5b92ddf50>]}
2021-06-06 18:38:12.098509 (Thread-1): 23:38:12 | 1 of 1 ERROR creating incremental model events_information.availibility_snapshot [ERROR in 2.08s]
2021-06-06 18:38:12.098707 (Thread-1): Finished running node model.werkspot_technical_challenge.availibility_snapshot
2021-06-06 18:38:12.182487 (MainThread): Acquiring new bigquery connection "master".
2021-06-06 18:38:12.183108 (MainThread): 23:38:12 | 
2021-06-06 18:38:12.183488 (MainThread): 23:38:12 | Finished running 1 incremental model in 11.18s.
2021-06-06 18:38:12.183778 (MainThread): Connection 'master' was properly closed.
2021-06-06 18:38:12.184353 (MainThread): Connection 'model.werkspot_technical_challenge.availibility_snapshot' was properly closed.
2021-06-06 18:38:12.196056 (MainThread): 
2021-06-06 18:38:12.196301 (MainThread): Completed with 1 error and 0 warnings:
2021-06-06 18:38:12.196535 (MainThread): 
2021-06-06 18:38:12.196744 (MainThread): Database Error in model availibility_snapshot (models/Snapshot/availibility_snapshot.sql)
2021-06-06 18:38:12.196955 (MainThread):   Syntax error: Expected ")" but got ";" at [69:26]
2021-06-06 18:38:12.197141 (MainThread):   compiled SQL at target/run/werkspot_technical_challenge/models/Snapshot/availibility_snapshot.sql
2021-06-06 18:38:12.197313 (MainThread): 
Done. PASS=0 WARN=0 ERROR=1 SKIP=0 TOTAL=1
2021-06-06 18:38:12.197606 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ff5b943d050>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ff5b93a9850>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ff5b93a96d0>]}
2021-06-06 18:38:12.197868 (MainThread): Flushing usage events
2021-06-06 18:40:14.948495 (MainThread): Running with dbt=0.19.1
2021-06-06 18:40:16.412112 (MainThread): running dbt with arguments Namespace(cls=<class 'dbt.task.run.RunTask'>, debug=False, defer=None, exclude=None, fail_fast=False, full_refresh=False, log_cache_events=False, log_format='default', models=['availibility_snapshot'], partial_parse=None, profile=None, profiles_dir='/Users/mac/.dbt', project_dir=None, record_timing_info=None, rpc_method='run', selector_name=None, single_threaded=False, state=None, strict=False, target=None, test_new_parser=False, threads=None, use_cache=True, use_colors=None, vars='{}', version_check=True, warn_error=False, which='run', write_json=True)
2021-06-06 18:40:16.414565 (MainThread): Tracking: tracking
2021-06-06 18:40:16.426330 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fa2eb6d5110>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fa2eb6d5f50>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fa2eb6d52d0>]}
2021-06-06 18:40:16.442577 (MainThread): Partial parsing not enabled
2021-06-06 18:40:16.444202 (MainThread): Parsing macros/etc.sql
2021-06-06 18:40:16.449055 (MainThread): Parsing macros/catalog.sql
2021-06-06 18:40:16.458800 (MainThread): Parsing macros/adapters.sql
2021-06-06 18:40:16.489814 (MainThread): Parsing macros/materializations/seed.sql
2021-06-06 18:40:16.493896 (MainThread): Parsing macros/materializations/view.sql
2021-06-06 18:40:16.498619 (MainThread): Parsing macros/materializations/table.sql
2021-06-06 18:40:16.517384 (MainThread): Parsing macros/materializations/copy.sql
2021-06-06 18:40:16.525637 (MainThread): Parsing macros/materializations/incremental.sql
2021-06-06 18:40:16.544397 (MainThread): Parsing macros/materializations/snapshot.sql
2021-06-06 18:40:16.548605 (MainThread): Parsing macros/core.sql
2021-06-06 18:40:16.554019 (MainThread): Parsing macros/materializations/helpers.sql
2021-06-06 18:40:16.566431 (MainThread): Parsing macros/materializations/snapshot/snapshot_merge.sql
2021-06-06 18:40:16.570734 (MainThread): Parsing macros/materializations/snapshot/strategies.sql
2021-06-06 18:40:16.616572 (MainThread): Parsing macros/materializations/snapshot/snapshot.sql
2021-06-06 18:40:16.679530 (MainThread): Parsing macros/materializations/seed/seed.sql
2021-06-06 18:40:16.712177 (MainThread): Parsing macros/materializations/incremental/helpers.sql
2021-06-06 18:40:16.715169 (MainThread): Parsing macros/materializations/incremental/incremental.sql
2021-06-06 18:40:16.726242 (MainThread): Parsing macros/materializations/common/merge.sql
2021-06-06 18:40:16.748135 (MainThread): Parsing macros/materializations/table/table.sql
2021-06-06 18:40:16.757811 (MainThread): Parsing macros/materializations/view/view.sql
2021-06-06 18:40:16.768568 (MainThread): Parsing macros/materializations/view/create_or_replace_view.sql
2021-06-06 18:40:16.778026 (MainThread): Parsing macros/etc/get_custom_alias.sql
2021-06-06 18:40:16.779760 (MainThread): Parsing macros/etc/query.sql
2021-06-06 18:40:16.781811 (MainThread): Parsing macros/etc/is_incremental.sql
2021-06-06 18:40:16.784543 (MainThread): Parsing macros/etc/datetime.sql
2021-06-06 18:40:16.800646 (MainThread): Parsing macros/etc/get_custom_schema.sql
2021-06-06 18:40:16.803762 (MainThread): Parsing macros/etc/get_custom_database.sql
2021-06-06 18:40:16.806297 (MainThread): Parsing macros/adapters/common.sql
2021-06-06 18:40:16.894425 (MainThread): Parsing macros/schema_tests/relationships.sql
2021-06-06 18:40:16.897719 (MainThread): Parsing macros/schema_tests/not_null.sql
2021-06-06 18:40:16.900571 (MainThread): Parsing macros/schema_tests/unique.sql
2021-06-06 18:40:16.904444 (MainThread): Parsing macros/schema_tests/accepted_values.sql
2021-06-06 18:40:16.915191 (MainThread): Partial parsing not enabled
2021-06-06 18:40:16.955118 (MainThread): Acquiring new bigquery connection "model.werkspot_technical_challenge.availibility_snapshot".
2021-06-06 18:40:16.972188 (MainThread): Acquiring new bigquery connection "model.werkspot_technical_challenge.dim_service".
2021-06-06 18:40:16.985193 (MainThread): Acquiring new bigquery connection "model.werkspot_technical_challenge.dim_professional".
2021-06-06 18:40:16.992902 (MainThread): Acquiring new bigquery connection "model.werkspot_technical_challenge.fct_fee".
2021-06-06 18:40:17.000697 (MainThread): Acquiring new bigquery connection "model.werkspot_technical_challenge.event_logs_stg".
2021-06-06 18:40:17.068115 (MainThread): Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'c3280527-90d6-45a9-8d8f-e5dfc13ee122', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fa2ec26a490>]}
2021-06-06 18:40:17.087741 (MainThread): Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'c3280527-90d6-45a9-8d8f-e5dfc13ee122', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fa2ec0fc910>]}
2021-06-06 18:40:17.088212 (MainThread): Found 5 models, 0 tests, 0 snapshots, 0 analyses, 156 macros, 0 operations, 0 seed files, 0 sources, 0 exposures
2021-06-06 18:40:17.089125 (MainThread): 
2021-06-06 18:40:17.089551 (MainThread): Acquiring new bigquery connection "master".
2021-06-06 18:40:17.090423 (ThreadPoolExecutor-0_0): Acquiring new bigquery connection "list_poetic-genius-315513".
2021-06-06 18:40:17.090674 (ThreadPoolExecutor-0_0): Opening a new connection, currently in state init
2021-06-06 18:40:20.402749 (ThreadPoolExecutor-1_0): Acquiring new bigquery connection "list_poetic-genius-315513_events_information".
2021-06-06 18:40:20.403087 (ThreadPoolExecutor-1_0): Opening a new connection, currently in state closed
2021-06-06 18:40:20.403376 (ThreadPoolExecutor-1_0): Client.dataset is deprecated and will be removed in a future version. Use a string like 'my_project.my_dataset' or a cloud.google.bigquery.DatasetReference object, instead.
2021-06-06 18:40:21.631220 (MainThread): 23:40:21 | Concurrency: 1 threads (target='dev')
2021-06-06 18:40:21.631482 (MainThread): 23:40:21 | 
2021-06-06 18:40:21.633801 (Thread-1): Began running node model.werkspot_technical_challenge.availibility_snapshot
2021-06-06 18:40:21.634213 (Thread-1): 23:40:21 | 1 of 1 START incremental model events_information.availibility_snapshot [RUN]
2021-06-06 18:40:21.634707 (Thread-1): Acquiring new bigquery connection "model.werkspot_technical_challenge.availibility_snapshot".
2021-06-06 18:40:21.635264 (Thread-1): unclosed <socket.socket fd=13, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('192.168.0.104', 54190), raddr=('142.250.185.42', 443)>
2021-06-06 18:40:21.635484 (Thread-1): Compiling model.werkspot_technical_challenge.availibility_snapshot
2021-06-06 18:40:21.641767 (Thread-1): Writing injected SQL for node "model.werkspot_technical_challenge.availibility_snapshot"
2021-06-06 18:40:21.642856 (Thread-1): finished collecting timing info
2021-06-06 18:40:21.714806 (Thread-1): Writing runtime SQL for node "model.werkspot_technical_challenge.availibility_snapshot"
2021-06-06 18:40:21.715426 (Thread-1): Opening a new connection, currently in state closed
2021-06-06 18:40:21.715617 (Thread-1): On model.werkspot_technical_challenge.availibility_snapshot: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "werkspot_technical_challenge", "target_name": "dev", "node_id": "model.werkspot_technical_challenge.availibility_snapshot"} */


  create or replace table `poetic-genius-315513`.`events_information`.`availibility_snapshot`
  partition by datetime_trunc(AuditCreatedDatetime, day)
  
  OPTIONS()
  as (
    


SELECT

  CreatedAt,
  COUNT(DISTINCT CASE WHEN ProfessionalStatus IS TRUE THEN ProfessionalID END) AS ActiveProfessionals

FROM 
(
  SELECT
    *,
    CASE
      
      WHEN 
        EventType IN ('created_account','became_unable_to_propose') AND NextEvent IS NULL 
        THEN False 
      
      WHEN EventType IN ('created_account','became_able_to_propose') AND NextEvent='became_unable_to_propose' 
        THEN False 
      
      WHEN EventType IN ('proposed','became_unable_to_propose') AND (NextEvent='became_unable_to_propose') 
        THEN False
      
      WHEN EventType IN ('proposed','became_able_to_propose','became_unable_to_propose') AND 
           NextEvent IN ('proposed','became_able_to_propose') 
        THEN True
      
      WHEN EventType IN ('proposed','became_able_to_propose','became_unable_to_propose') AND 
           NextEvent IN ('proposed','became_able_to_propose') 
        THEN True
      
      WHEN EventType IN ('created_account','became_able_to_propose','proposed') AND 
           (NextEvent IS NULL OR NextEvent='became_able_to_propose') 
        THEN True
    
    END AS ProfessionalStatus
  
  FROM 
  (
    SELECT

     DISTINCT
      EXTRACT(DATE FROM CAST(CreatedAt AS DATETIME)) AS CreatedAt,
      ProfessionalID,
      EventType,
      LEAD(EventType,1 ) OVER 
          (PARTITION By EXTRACT(DATE FROM CAST(CreatedAt AS DATETIME)),ProfessionalID 
            ORDER BY CreatedAt ASC) as NextEvent
    FROM
    (
      SELECT 

        DISTINCT
          CreatedAt,
          ProfessionalID,
          EventType

      FROM 
        `poetic-genius-315513`.`events_information`.`event_logs_stg`
        
      GROUP BY 1,2,3 
      HAVING CreatedAt BETWEEN MIN(CreatedAt) AND '2020-03-10 23:59:59'
    )
  )
) 
GROUP BY 1 ORDER BY 1 ASC
  );
  
2021-06-06 18:40:23.484364 (Thread-1): Retry attempt 1 of 1 after error: BadRequest('GET https://bigquery.googleapis.com/bigquery/v2/projects/poetic-genius-315513/queries/5b2662fa-9169-4179-a386-72d49a3816e6?maxResults=0&location=US: Unrecognized name: AuditCreatedDatetime at [5:31]')
2021-06-06 18:40:25.412772 (Thread-1): finished collecting timing info
2021-06-06 18:40:25.413469 (Thread-1): Database Error in model availibility_snapshot (models/Snapshot/availibility_snapshot.sql)
  Unrecognized name: AuditCreatedDatetime at [5:31]
  compiled SQL at target/run/werkspot_technical_challenge/models/Snapshot/availibility_snapshot.sql
Traceback (most recent call last):
  File "/opt/anaconda3/lib/python3.7/site-packages/dbt/adapters/bigquery/connections.py", line 149, in exception_handler
    yield
  File "/opt/anaconda3/lib/python3.7/site-packages/dbt/adapters/bigquery/connections.py", line 539, in _retry_and_handle
    on_error=reopen_conn_on_error)
  File "/opt/anaconda3/lib/python3.7/site-packages/google/api_core/retry.py", line 184, in retry_target
    return target()
  File "/opt/anaconda3/lib/python3.7/site-packages/dbt/adapters/bigquery/connections.py", line 327, in fn
    return self._query_and_results(client, sql, conn, job_params)
  File "/opt/anaconda3/lib/python3.7/site-packages/dbt/adapters/bigquery/connections.py", line 520, in _query_and_results
    iterator = query_job.result(timeout=timeout)
  File "/opt/anaconda3/lib/python3.7/site-packages/google/cloud/bigquery/job.py", line 3207, in result
    super(QueryJob, self).result(retry=retry, timeout=timeout)
  File "/opt/anaconda3/lib/python3.7/site-packages/google/cloud/bigquery/job.py", line 812, in result
    return super(_AsyncJob, self).result(timeout=timeout)
  File "/opt/anaconda3/lib/python3.7/site-packages/google/api_core/future/polling.py", line 125, in result
    self._blocking_poll(timeout=timeout)
  File "/opt/anaconda3/lib/python3.7/site-packages/google/cloud/bigquery/job.py", line 3103, in _blocking_poll
    super(QueryJob, self)._blocking_poll(timeout=timeout)
  File "/opt/anaconda3/lib/python3.7/site-packages/google/api_core/future/polling.py", line 104, in _blocking_poll
    retry_(self._done_or_raise)()
  File "/opt/anaconda3/lib/python3.7/site-packages/google/api_core/retry.py", line 286, in retry_wrapped_func
    on_error=on_error,
  File "/opt/anaconda3/lib/python3.7/site-packages/google/api_core/retry.py", line 184, in retry_target
    return target()
  File "/opt/anaconda3/lib/python3.7/site-packages/google/api_core/future/polling.py", line 83, in _done_or_raise
    if not self.done():
  File "/opt/anaconda3/lib/python3.7/site-packages/google/cloud/bigquery/job.py", line 3089, in done
    timeout=transport_timeout,
  File "/opt/anaconda3/lib/python3.7/site-packages/google/cloud/bigquery/client.py", line 1362, in _get_query_results
    retry, method="GET", path=path, query_params=extra_params, timeout=timeout
  File "/opt/anaconda3/lib/python3.7/site-packages/google/cloud/bigquery/client.py", line 578, in _call_api
    return call()
  File "/opt/anaconda3/lib/python3.7/site-packages/google/api_core/retry.py", line 286, in retry_wrapped_func
    on_error=on_error,
  File "/opt/anaconda3/lib/python3.7/site-packages/google/api_core/retry.py", line 184, in retry_target
    return target()
  File "/opt/anaconda3/lib/python3.7/site-packages/google/cloud/_http.py", line 423, in api_request
    raise exceptions.from_http_response(response)
google.api_core.exceptions.BadRequest: 400 GET https://bigquery.googleapis.com/bigquery/v2/projects/poetic-genius-315513/queries/bf170894-7520-4dc4-b3c5-cbedc741b6ec?maxResults=0&location=US: Unrecognized name: AuditCreatedDatetime at [5:31]

(job ID: bf170894-7520-4dc4-b3c5-cbedc741b6ec)

                                                                                -----Query Job SQL Follows-----                                                                                

    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |
   1:/* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "werkspot_technical_challenge", "target_name": "dev", "node_id": "model.werkspot_technical_challenge.availibility_snapshot"} */
   2:
   3:
   4:  create or replace table `poetic-genius-315513`.`events_information`.`availibility_snapshot`
   5:  partition by datetime_trunc(AuditCreatedDatetime, day)
   6:  
   7:  OPTIONS()
   8:  as (
   9:    
  10:
  11:
  12:SELECT
  13:
  14:  CreatedAt,
  15:  COUNT(DISTINCT CASE WHEN ProfessionalStatus IS TRUE THEN ProfessionalID END) AS ActiveProfessionals
  16:
  17:FROM 
  18:(
  19:  SELECT
  20:    *,
  21:    CASE
  22:      
  23:      WHEN 
  24:        EventType IN ('created_account','became_unable_to_propose') AND NextEvent IS NULL 
  25:        THEN False 
  26:      
  27:      WHEN EventType IN ('created_account','became_able_to_propose') AND NextEvent='became_unable_to_propose' 
  28:        THEN False 
  29:      
  30:      WHEN EventType IN ('proposed','became_unable_to_propose') AND (NextEvent='became_unable_to_propose') 
  31:        THEN False
  32:      
  33:      WHEN EventType IN ('proposed','became_able_to_propose','became_unable_to_propose') AND 
  34:           NextEvent IN ('proposed','became_able_to_propose') 
  35:        THEN True
  36:      
  37:      WHEN EventType IN ('proposed','became_able_to_propose','became_unable_to_propose') AND 
  38:           NextEvent IN ('proposed','became_able_to_propose') 
  39:        THEN True
  40:      
  41:      WHEN EventType IN ('created_account','became_able_to_propose','proposed') AND 
  42:           (NextEvent IS NULL OR NextEvent='became_able_to_propose') 
  43:        THEN True
  44:    
  45:    END AS ProfessionalStatus
  46:  
  47:  FROM 
  48:  (
  49:    SELECT
  50:
  51:     DISTINCT
  52:      EXTRACT(DATE FROM CAST(CreatedAt AS DATETIME)) AS CreatedAt,
  53:      ProfessionalID,
  54:      EventType,
  55:      LEAD(EventType,1 ) OVER 
  56:          (PARTITION By EXTRACT(DATE FROM CAST(CreatedAt AS DATETIME)),ProfessionalID 
  57:            ORDER BY CreatedAt ASC) as NextEvent
  58:    FROM
  59:    (
  60:      SELECT 
  61:
  62:        DISTINCT
  63:          CreatedAt,
  64:          ProfessionalID,
  65:          EventType
  66:
  67:      FROM 
  68:        `poetic-genius-315513`.`events_information`.`event_logs_stg`
  69:        
  70:      GROUP BY 1,2,3 
  71:      HAVING CreatedAt BETWEEN MIN(CreatedAt) AND '2020-03-10 23:59:59'
  72:    )
  73:  )
  74:) 
  75:GROUP BY 1 ORDER BY 1 ASC
  76:  );
  77:  
    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/anaconda3/lib/python3.7/site-packages/dbt/task/base.py", line 344, in safe_run
    result = self.compile_and_execute(manifest, ctx)
  File "/opt/anaconda3/lib/python3.7/site-packages/dbt/task/base.py", line 287, in compile_and_execute
    result = self.run(ctx.node, manifest)
  File "/opt/anaconda3/lib/python3.7/site-packages/dbt/task/base.py", line 389, in run
    return self.execute(compiled_node, manifest)
  File "/opt/anaconda3/lib/python3.7/site-packages/dbt/task/run.py", line 248, in execute
    result = MacroGenerator(materialization_macro, context)()
  File "/opt/anaconda3/lib/python3.7/site-packages/dbt/clients/jinja.py", line 332, in __call__
    return self.call_macro(*args, **kwargs)
  File "/opt/anaconda3/lib/python3.7/site-packages/dbt/clients/jinja.py", line 259, in call_macro
    return macro(*args, **kwargs)
  File "/opt/anaconda3/lib/python3.7/site-packages/jinja2/runtime.py", line 675, in __call__
    return self._invoke(arguments, autoescape)
  File "/opt/anaconda3/lib/python3.7/site-packages/jinja2/runtime.py", line 679, in _invoke
    rv = self._func(*arguments)
  File "<template>", line 156, in macro
  File "/opt/anaconda3/lib/python3.7/site-packages/jinja2/sandbox.py", line 462, in call
    return __context.call(__obj, *args, **kwargs)
  File "/opt/anaconda3/lib/python3.7/site-packages/jinja2/runtime.py", line 290, in call
    return __obj(*args, **kwargs)
  File "/opt/anaconda3/lib/python3.7/site-packages/dbt/clients/jinja.py", line 332, in __call__
    return self.call_macro(*args, **kwargs)
  File "/opt/anaconda3/lib/python3.7/site-packages/dbt/clients/jinja.py", line 259, in call_macro
    return macro(*args, **kwargs)
  File "/opt/anaconda3/lib/python3.7/site-packages/jinja2/runtime.py", line 675, in __call__
    return self._invoke(arguments, autoescape)
  File "/opt/anaconda3/lib/python3.7/site-packages/jinja2/runtime.py", line 679, in _invoke
    rv = self._func(*arguments)
  File "<template>", line 41, in macro
  File "/opt/anaconda3/lib/python3.7/site-packages/jinja2/sandbox.py", line 462, in call
    return __context.call(__obj, *args, **kwargs)
  File "/opt/anaconda3/lib/python3.7/site-packages/jinja2/runtime.py", line 290, in call
    return __obj(*args, **kwargs)
  File "/opt/anaconda3/lib/python3.7/site-packages/dbt/adapters/base/impl.py", line 230, in execute
    fetch=fetch
  File "/opt/anaconda3/lib/python3.7/site-packages/dbt/adapters/bigquery/connections.py", line 338, in execute
    query_job, iterator = self.raw_execute(sql, fetch=fetch)
  File "/opt/anaconda3/lib/python3.7/site-packages/dbt/adapters/bigquery/connections.py", line 329, in raw_execute
    query_job, iterator = self._retry_and_handle(msg=sql, conn=conn, fn=fn)
  File "/opt/anaconda3/lib/python3.7/site-packages/dbt/adapters/bigquery/connections.py", line 539, in _retry_and_handle
    on_error=reopen_conn_on_error)
  File "/opt/anaconda3/lib/python3.7/contextlib.py", line 130, in __exit__
    self.gen.throw(type, value, traceback)
  File "/opt/anaconda3/lib/python3.7/site-packages/dbt/adapters/bigquery/connections.py", line 153, in exception_handler
    self.handle_error(e, message)
  File "/opt/anaconda3/lib/python3.7/site-packages/dbt/adapters/bigquery/connections.py", line 141, in handle_error
    raise DatabaseException(error_msg)
dbt.exceptions.DatabaseException: Database Error in model availibility_snapshot (models/Snapshot/availibility_snapshot.sql)
  Unrecognized name: AuditCreatedDatetime at [5:31]
  compiled SQL at target/run/werkspot_technical_challenge/models/Snapshot/availibility_snapshot.sql
2021-06-06 18:40:25.457254 (Thread-1): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'c3280527-90d6-45a9-8d8f-e5dfc13ee122', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fa2ec0bc990>]}
2021-06-06 18:40:25.458020 (Thread-1): 23:40:25 | 1 of 1 ERROR creating incremental model events_information.availibility_snapshot [ERROR in 3.82s]
2021-06-06 18:40:25.458338 (Thread-1): Finished running node model.werkspot_technical_challenge.availibility_snapshot
2021-06-06 18:40:25.525279 (MainThread): Acquiring new bigquery connection "master".
2021-06-06 18:40:25.525918 (MainThread): 23:40:25 | 
2021-06-06 18:40:25.526179 (MainThread): 23:40:25 | Finished running 1 incremental model in 8.44s.
2021-06-06 18:40:25.526511 (MainThread): Connection 'master' was properly closed.
2021-06-06 18:40:25.526746 (MainThread): Connection 'model.werkspot_technical_challenge.availibility_snapshot' was properly closed.
2021-06-06 18:40:25.538234 (MainThread): 
2021-06-06 18:40:25.538633 (MainThread): Completed with 1 error and 0 warnings:
2021-06-06 18:40:25.538906 (MainThread): 
2021-06-06 18:40:25.539149 (MainThread): Database Error in model availibility_snapshot (models/Snapshot/availibility_snapshot.sql)
2021-06-06 18:40:25.539360 (MainThread):   Unrecognized name: AuditCreatedDatetime at [5:31]
2021-06-06 18:40:25.539564 (MainThread):   compiled SQL at target/run/werkspot_technical_challenge/models/Snapshot/availibility_snapshot.sql
2021-06-06 18:40:25.539789 (MainThread): 
Done. PASS=0 WARN=0 ERROR=1 SKIP=0 TOTAL=1
2021-06-06 18:40:25.540174 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fa2eb7209d0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fa2ec202d50>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fa2ec0ec6d0>]}
2021-06-06 18:40:25.540511 (MainThread): Flushing usage events
2021-06-06 18:40:58.751834 (MainThread): Running with dbt=0.19.1
2021-06-06 18:40:59.898079 (MainThread): running dbt with arguments Namespace(cls=<class 'dbt.task.run.RunTask'>, debug=False, defer=None, exclude=None, fail_fast=False, full_refresh=False, log_cache_events=False, log_format='default', models=['availibility_snapshot'], partial_parse=None, profile=None, profiles_dir='/Users/mac/.dbt', project_dir=None, record_timing_info=None, rpc_method='run', selector_name=None, single_threaded=False, state=None, strict=False, target=None, test_new_parser=False, threads=None, use_cache=True, use_colors=None, vars='{}', version_check=True, warn_error=False, which='run', write_json=True)
2021-06-06 18:40:59.899899 (MainThread): Tracking: tracking
2021-06-06 18:40:59.910258 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fc17700b7d0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fc17700bf90>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fc17700b0d0>]}
2021-06-06 18:40:59.924401 (MainThread): Partial parsing not enabled
2021-06-06 18:40:59.925976 (MainThread): Parsing macros/etc.sql
2021-06-06 18:40:59.930135 (MainThread): Parsing macros/catalog.sql
2021-06-06 18:40:59.939928 (MainThread): Parsing macros/adapters.sql
2021-06-06 18:40:59.968939 (MainThread): Parsing macros/materializations/seed.sql
2021-06-06 18:40:59.973430 (MainThread): Parsing macros/materializations/view.sql
2021-06-06 18:40:59.977635 (MainThread): Parsing macros/materializations/table.sql
2021-06-06 18:40:59.991159 (MainThread): Parsing macros/materializations/copy.sql
2021-06-06 18:40:59.998271 (MainThread): Parsing macros/materializations/incremental.sql
2021-06-06 18:41:00.021735 (MainThread): Parsing macros/materializations/snapshot.sql
2021-06-06 18:41:00.025791 (MainThread): Parsing macros/core.sql
2021-06-06 18:41:00.032432 (MainThread): Parsing macros/materializations/helpers.sql
2021-06-06 18:41:00.046664 (MainThread): Parsing macros/materializations/snapshot/snapshot_merge.sql
2021-06-06 18:41:00.049713 (MainThread): Parsing macros/materializations/snapshot/strategies.sql
2021-06-06 18:41:00.075746 (MainThread): Parsing macros/materializations/snapshot/snapshot.sql
2021-06-06 18:41:00.122849 (MainThread): Parsing macros/materializations/seed/seed.sql
2021-06-06 18:41:00.153010 (MainThread): Parsing macros/materializations/incremental/helpers.sql
2021-06-06 18:41:00.156260 (MainThread): Parsing macros/materializations/incremental/incremental.sql
2021-06-06 18:41:00.165382 (MainThread): Parsing macros/materializations/common/merge.sql
2021-06-06 18:41:00.185203 (MainThread): Parsing macros/materializations/table/table.sql
2021-06-06 18:41:00.195586 (MainThread): Parsing macros/materializations/view/view.sql
2021-06-06 18:41:00.205686 (MainThread): Parsing macros/materializations/view/create_or_replace_view.sql
2021-06-06 18:41:00.212572 (MainThread): Parsing macros/etc/get_custom_alias.sql
2021-06-06 18:41:00.214095 (MainThread): Parsing macros/etc/query.sql
2021-06-06 18:41:00.215834 (MainThread): Parsing macros/etc/is_incremental.sql
2021-06-06 18:41:00.218308 (MainThread): Parsing macros/etc/datetime.sql
2021-06-06 18:41:00.230979 (MainThread): Parsing macros/etc/get_custom_schema.sql
2021-06-06 18:41:00.234185 (MainThread): Parsing macros/etc/get_custom_database.sql
2021-06-06 18:41:00.236816 (MainThread): Parsing macros/adapters/common.sql
2021-06-06 18:41:00.306140 (MainThread): Parsing macros/schema_tests/relationships.sql
2021-06-06 18:41:00.309043 (MainThread): Parsing macros/schema_tests/not_null.sql
2021-06-06 18:41:00.311438 (MainThread): Parsing macros/schema_tests/unique.sql
2021-06-06 18:41:00.314269 (MainThread): Parsing macros/schema_tests/accepted_values.sql
2021-06-06 18:41:00.325036 (MainThread): Partial parsing not enabled
2021-06-06 18:41:00.371518 (MainThread): Acquiring new bigquery connection "model.werkspot_technical_challenge.availibility_snapshot".
2021-06-06 18:41:00.390643 (MainThread): Acquiring new bigquery connection "model.werkspot_technical_challenge.dim_service".
2021-06-06 18:41:00.403090 (MainThread): Acquiring new bigquery connection "model.werkspot_technical_challenge.dim_professional".
2021-06-06 18:41:00.411462 (MainThread): Acquiring new bigquery connection "model.werkspot_technical_challenge.fct_fee".
2021-06-06 18:41:00.419798 (MainThread): Acquiring new bigquery connection "model.werkspot_technical_challenge.event_logs_stg".
2021-06-06 18:41:00.509250 (MainThread): Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '01a19e23-b261-4ea9-85bb-641d8b6e6f4e', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fc1770a8990>]}
2021-06-06 18:41:00.527092 (MainThread): Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '01a19e23-b261-4ea9-85bb-641d8b6e6f4e', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fc1772b47d0>]}
2021-06-06 18:41:00.527618 (MainThread): Found 5 models, 0 tests, 0 snapshots, 0 analyses, 156 macros, 0 operations, 0 seed files, 0 sources, 0 exposures
2021-06-06 18:41:00.528932 (MainThread): 
2021-06-06 18:41:00.529389 (MainThread): Acquiring new bigquery connection "master".
2021-06-06 18:41:00.530408 (ThreadPoolExecutor-0_0): Acquiring new bigquery connection "list_poetic-genius-315513".
2021-06-06 18:41:00.530711 (ThreadPoolExecutor-0_0): Opening a new connection, currently in state init
2021-06-06 18:41:03.233736 (ThreadPoolExecutor-1_0): Acquiring new bigquery connection "list_poetic-genius-315513_events_information".
2021-06-06 18:41:03.234096 (ThreadPoolExecutor-1_0): Opening a new connection, currently in state closed
2021-06-06 18:41:03.234408 (ThreadPoolExecutor-1_0): Client.dataset is deprecated and will be removed in a future version. Use a string like 'my_project.my_dataset' or a cloud.google.bigquery.DatasetReference object, instead.
2021-06-06 18:41:04.422927 (MainThread): 23:41:04 | Concurrency: 1 threads (target='dev')
2021-06-06 18:41:04.423284 (MainThread): 23:41:04 | 
2021-06-06 18:41:04.425625 (Thread-1): Began running node model.werkspot_technical_challenge.availibility_snapshot
2021-06-06 18:41:04.426024 (Thread-1): 23:41:04 | 1 of 1 START incremental model events_information.availibility_snapshot [RUN]
2021-06-06 18:41:04.426479 (Thread-1): Acquiring new bigquery connection "model.werkspot_technical_challenge.availibility_snapshot".
2021-06-06 18:41:04.426961 (Thread-1): unclosed <socket.socket fd=13, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('192.168.0.104', 54205), raddr=('142.250.185.42', 443)>
2021-06-06 18:41:04.427150 (Thread-1): Compiling model.werkspot_technical_challenge.availibility_snapshot
2021-06-06 18:41:04.432015 (Thread-1): Writing injected SQL for node "model.werkspot_technical_challenge.availibility_snapshot"
2021-06-06 18:41:04.432579 (Thread-1): finished collecting timing info
2021-06-06 18:41:04.503840 (Thread-1): Writing runtime SQL for node "model.werkspot_technical_challenge.availibility_snapshot"
2021-06-06 18:41:04.504483 (Thread-1): Opening a new connection, currently in state closed
2021-06-06 18:41:04.504691 (Thread-1): On model.werkspot_technical_challenge.availibility_snapshot: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "werkspot_technical_challenge", "target_name": "dev", "node_id": "model.werkspot_technical_challenge.availibility_snapshot"} */


  create or replace table `poetic-genius-315513`.`events_information`.`availibility_snapshot`
  partition by datetime_trunc(AuditCreatedDatetime, day)
  
  OPTIONS()
  as (
    


SELECT

  CreatedAt,
  COUNT(DISTINCT CASE WHEN ProfessionalStatus IS TRUE THEN ProfessionalID END) AS ActiveProfessionals

FROM 
(
  SELECT
    *,
    CASE
      
      WHEN 
        EventType IN ('created_account','became_unable_to_propose') AND NextEvent IS NULL 
        THEN False 
      
      WHEN EventType IN ('created_account','became_able_to_propose') AND NextEvent='became_unable_to_propose' 
        THEN False 
      
      WHEN EventType IN ('proposed','became_unable_to_propose') AND (NextEvent='became_unable_to_propose') 
        THEN False
      
      WHEN EventType IN ('proposed','became_able_to_propose','became_unable_to_propose') AND 
           NextEvent IN ('proposed','became_able_to_propose') 
        THEN True
      
      WHEN EventType IN ('proposed','became_able_to_propose','became_unable_to_propose') AND 
           NextEvent IN ('proposed','became_able_to_propose') 
        THEN True
      
      WHEN EventType IN ('created_account','became_able_to_propose','proposed') AND 
           (NextEvent IS NULL OR NextEvent='became_able_to_propose') 
        THEN True
    
    END AS ProfessionalStatus,

    CURRENT_DATETIME() as AuditCreatedDatetime, -- Audit column
  
  FROM 
  (
    SELECT

     DISTINCT
      EXTRACT(DATE FROM CAST(CreatedAt AS DATETIME)) AS CreatedAt,
      ProfessionalID,
      EventType,
      LEAD(EventType,1 ) OVER 
          (PARTITION By EXTRACT(DATE FROM CAST(CreatedAt AS DATETIME)),ProfessionalID 
            ORDER BY CreatedAt ASC) as NextEvent
    FROM
    (
      SELECT 

        DISTINCT
          CreatedAt,
          ProfessionalID,
          EventType

      FROM 
        `poetic-genius-315513`.`events_information`.`event_logs_stg`
        
      GROUP BY 1,2,3 
      HAVING CreatedAt BETWEEN MIN(CreatedAt) AND '2020-03-10 23:59:59'
    )
  )
) 
GROUP BY 1 ORDER BY 1 ASC
  );
  
2021-06-06 18:41:06.308136 (Thread-1): Retry attempt 1 of 1 after error: BadRequest('GET https://bigquery.googleapis.com/bigquery/v2/projects/poetic-genius-315513/queries/d86db2af-42cf-4df3-ac28-a6d66d82210d?maxResults=0&location=US: Unrecognized name: AuditCreatedDatetime at [5:31]')
2021-06-06 18:41:08.230023 (Thread-1): finished collecting timing info
2021-06-06 18:41:08.230708 (Thread-1): Database Error in model availibility_snapshot (models/Snapshot/availibility_snapshot.sql)
  Unrecognized name: AuditCreatedDatetime at [5:31]
  compiled SQL at target/run/werkspot_technical_challenge/models/Snapshot/availibility_snapshot.sql
Traceback (most recent call last):
  File "/opt/anaconda3/lib/python3.7/site-packages/dbt/adapters/bigquery/connections.py", line 149, in exception_handler
    yield
  File "/opt/anaconda3/lib/python3.7/site-packages/dbt/adapters/bigquery/connections.py", line 539, in _retry_and_handle
    on_error=reopen_conn_on_error)
  File "/opt/anaconda3/lib/python3.7/site-packages/google/api_core/retry.py", line 184, in retry_target
    return target()
  File "/opt/anaconda3/lib/python3.7/site-packages/dbt/adapters/bigquery/connections.py", line 327, in fn
    return self._query_and_results(client, sql, conn, job_params)
  File "/opt/anaconda3/lib/python3.7/site-packages/dbt/adapters/bigquery/connections.py", line 520, in _query_and_results
    iterator = query_job.result(timeout=timeout)
  File "/opt/anaconda3/lib/python3.7/site-packages/google/cloud/bigquery/job.py", line 3207, in result
    super(QueryJob, self).result(retry=retry, timeout=timeout)
  File "/opt/anaconda3/lib/python3.7/site-packages/google/cloud/bigquery/job.py", line 812, in result
    return super(_AsyncJob, self).result(timeout=timeout)
  File "/opt/anaconda3/lib/python3.7/site-packages/google/api_core/future/polling.py", line 125, in result
    self._blocking_poll(timeout=timeout)
  File "/opt/anaconda3/lib/python3.7/site-packages/google/cloud/bigquery/job.py", line 3103, in _blocking_poll
    super(QueryJob, self)._blocking_poll(timeout=timeout)
  File "/opt/anaconda3/lib/python3.7/site-packages/google/api_core/future/polling.py", line 104, in _blocking_poll
    retry_(self._done_or_raise)()
  File "/opt/anaconda3/lib/python3.7/site-packages/google/api_core/retry.py", line 286, in retry_wrapped_func
    on_error=on_error,
  File "/opt/anaconda3/lib/python3.7/site-packages/google/api_core/retry.py", line 184, in retry_target
    return target()
  File "/opt/anaconda3/lib/python3.7/site-packages/google/api_core/future/polling.py", line 83, in _done_or_raise
    if not self.done():
  File "/opt/anaconda3/lib/python3.7/site-packages/google/cloud/bigquery/job.py", line 3089, in done
    timeout=transport_timeout,
  File "/opt/anaconda3/lib/python3.7/site-packages/google/cloud/bigquery/client.py", line 1362, in _get_query_results
    retry, method="GET", path=path, query_params=extra_params, timeout=timeout
  File "/opt/anaconda3/lib/python3.7/site-packages/google/cloud/bigquery/client.py", line 578, in _call_api
    return call()
  File "/opt/anaconda3/lib/python3.7/site-packages/google/api_core/retry.py", line 286, in retry_wrapped_func
    on_error=on_error,
  File "/opt/anaconda3/lib/python3.7/site-packages/google/api_core/retry.py", line 184, in retry_target
    return target()
  File "/opt/anaconda3/lib/python3.7/site-packages/google/cloud/_http.py", line 423, in api_request
    raise exceptions.from_http_response(response)
google.api_core.exceptions.BadRequest: 400 GET https://bigquery.googleapis.com/bigquery/v2/projects/poetic-genius-315513/queries/d0d2cb4f-1b49-4bf3-bd98-e2e2c42a9268?maxResults=0&location=US: Unrecognized name: AuditCreatedDatetime at [5:31]

(job ID: d0d2cb4f-1b49-4bf3-bd98-e2e2c42a9268)

                                                                                -----Query Job SQL Follows-----                                                                                

    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |
   1:/* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "werkspot_technical_challenge", "target_name": "dev", "node_id": "model.werkspot_technical_challenge.availibility_snapshot"} */
   2:
   3:
   4:  create or replace table `poetic-genius-315513`.`events_information`.`availibility_snapshot`
   5:  partition by datetime_trunc(AuditCreatedDatetime, day)
   6:  
   7:  OPTIONS()
   8:  as (
   9:    
  10:
  11:
  12:SELECT
  13:
  14:  CreatedAt,
  15:  COUNT(DISTINCT CASE WHEN ProfessionalStatus IS TRUE THEN ProfessionalID END) AS ActiveProfessionals
  16:
  17:FROM 
  18:(
  19:  SELECT
  20:    *,
  21:    CASE
  22:      
  23:      WHEN 
  24:        EventType IN ('created_account','became_unable_to_propose') AND NextEvent IS NULL 
  25:        THEN False 
  26:      
  27:      WHEN EventType IN ('created_account','became_able_to_propose') AND NextEvent='became_unable_to_propose' 
  28:        THEN False 
  29:      
  30:      WHEN EventType IN ('proposed','became_unable_to_propose') AND (NextEvent='became_unable_to_propose') 
  31:        THEN False
  32:      
  33:      WHEN EventType IN ('proposed','became_able_to_propose','became_unable_to_propose') AND 
  34:           NextEvent IN ('proposed','became_able_to_propose') 
  35:        THEN True
  36:      
  37:      WHEN EventType IN ('proposed','became_able_to_propose','became_unable_to_propose') AND 
  38:           NextEvent IN ('proposed','became_able_to_propose') 
  39:        THEN True
  40:      
  41:      WHEN EventType IN ('created_account','became_able_to_propose','proposed') AND 
  42:           (NextEvent IS NULL OR NextEvent='became_able_to_propose') 
  43:        THEN True
  44:    
  45:    END AS ProfessionalStatus,
  46:
  47:    CURRENT_DATETIME() as AuditCreatedDatetime, -- Audit column
  48:  
  49:  FROM 
  50:  (
  51:    SELECT
  52:
  53:     DISTINCT
  54:      EXTRACT(DATE FROM CAST(CreatedAt AS DATETIME)) AS CreatedAt,
  55:      ProfessionalID,
  56:      EventType,
  57:      LEAD(EventType,1 ) OVER 
  58:          (PARTITION By EXTRACT(DATE FROM CAST(CreatedAt AS DATETIME)),ProfessionalID 
  59:            ORDER BY CreatedAt ASC) as NextEvent
  60:    FROM
  61:    (
  62:      SELECT 
  63:
  64:        DISTINCT
  65:          CreatedAt,
  66:          ProfessionalID,
  67:          EventType
  68:
  69:      FROM 
  70:        `poetic-genius-315513`.`events_information`.`event_logs_stg`
  71:        
  72:      GROUP BY 1,2,3 
  73:      HAVING CreatedAt BETWEEN MIN(CreatedAt) AND '2020-03-10 23:59:59'
  74:    )
  75:  )
  76:) 
  77:GROUP BY 1 ORDER BY 1 ASC
  78:  );
  79:  
    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/anaconda3/lib/python3.7/site-packages/dbt/task/base.py", line 344, in safe_run
    result = self.compile_and_execute(manifest, ctx)
  File "/opt/anaconda3/lib/python3.7/site-packages/dbt/task/base.py", line 287, in compile_and_execute
    result = self.run(ctx.node, manifest)
  File "/opt/anaconda3/lib/python3.7/site-packages/dbt/task/base.py", line 389, in run
    return self.execute(compiled_node, manifest)
  File "/opt/anaconda3/lib/python3.7/site-packages/dbt/task/run.py", line 248, in execute
    result = MacroGenerator(materialization_macro, context)()
  File "/opt/anaconda3/lib/python3.7/site-packages/dbt/clients/jinja.py", line 332, in __call__
    return self.call_macro(*args, **kwargs)
  File "/opt/anaconda3/lib/python3.7/site-packages/dbt/clients/jinja.py", line 259, in call_macro
    return macro(*args, **kwargs)
  File "/opt/anaconda3/lib/python3.7/site-packages/jinja2/runtime.py", line 675, in __call__
    return self._invoke(arguments, autoescape)
  File "/opt/anaconda3/lib/python3.7/site-packages/jinja2/runtime.py", line 679, in _invoke
    rv = self._func(*arguments)
  File "<template>", line 156, in macro
  File "/opt/anaconda3/lib/python3.7/site-packages/jinja2/sandbox.py", line 462, in call
    return __context.call(__obj, *args, **kwargs)
  File "/opt/anaconda3/lib/python3.7/site-packages/jinja2/runtime.py", line 290, in call
    return __obj(*args, **kwargs)
  File "/opt/anaconda3/lib/python3.7/site-packages/dbt/clients/jinja.py", line 332, in __call__
    return self.call_macro(*args, **kwargs)
  File "/opt/anaconda3/lib/python3.7/site-packages/dbt/clients/jinja.py", line 259, in call_macro
    return macro(*args, **kwargs)
  File "/opt/anaconda3/lib/python3.7/site-packages/jinja2/runtime.py", line 675, in __call__
    return self._invoke(arguments, autoescape)
  File "/opt/anaconda3/lib/python3.7/site-packages/jinja2/runtime.py", line 679, in _invoke
    rv = self._func(*arguments)
  File "<template>", line 41, in macro
  File "/opt/anaconda3/lib/python3.7/site-packages/jinja2/sandbox.py", line 462, in call
    return __context.call(__obj, *args, **kwargs)
  File "/opt/anaconda3/lib/python3.7/site-packages/jinja2/runtime.py", line 290, in call
    return __obj(*args, **kwargs)
  File "/opt/anaconda3/lib/python3.7/site-packages/dbt/adapters/base/impl.py", line 230, in execute
    fetch=fetch
  File "/opt/anaconda3/lib/python3.7/site-packages/dbt/adapters/bigquery/connections.py", line 338, in execute
    query_job, iterator = self.raw_execute(sql, fetch=fetch)
  File "/opt/anaconda3/lib/python3.7/site-packages/dbt/adapters/bigquery/connections.py", line 329, in raw_execute
    query_job, iterator = self._retry_and_handle(msg=sql, conn=conn, fn=fn)
  File "/opt/anaconda3/lib/python3.7/site-packages/dbt/adapters/bigquery/connections.py", line 539, in _retry_and_handle
    on_error=reopen_conn_on_error)
  File "/opt/anaconda3/lib/python3.7/contextlib.py", line 130, in __exit__
    self.gen.throw(type, value, traceback)
  File "/opt/anaconda3/lib/python3.7/site-packages/dbt/adapters/bigquery/connections.py", line 153, in exception_handler
    self.handle_error(e, message)
  File "/opt/anaconda3/lib/python3.7/site-packages/dbt/adapters/bigquery/connections.py", line 141, in handle_error
    raise DatabaseException(error_msg)
dbt.exceptions.DatabaseException: Database Error in model availibility_snapshot (models/Snapshot/availibility_snapshot.sql)
  Unrecognized name: AuditCreatedDatetime at [5:31]
  compiled SQL at target/run/werkspot_technical_challenge/models/Snapshot/availibility_snapshot.sql
2021-06-06 18:41:08.242718 (Thread-1): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '01a19e23-b261-4ea9-85bb-641d8b6e6f4e', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fc17720e1d0>]}
2021-06-06 18:41:08.243204 (Thread-1): 23:41:08 | 1 of 1 ERROR creating incremental model events_information.availibility_snapshot [ERROR in 3.82s]
2021-06-06 18:41:08.243380 (Thread-1): Finished running node model.werkspot_technical_challenge.availibility_snapshot
2021-06-06 18:41:08.330994 (MainThread): Acquiring new bigquery connection "master".
2021-06-06 18:41:08.331619 (MainThread): 23:41:08 | 
2021-06-06 18:41:08.331870 (MainThread): 23:41:08 | Finished running 1 incremental model in 7.80s.
2021-06-06 18:41:08.332216 (MainThread): Connection 'master' was properly closed.
2021-06-06 18:41:08.332438 (MainThread): Connection 'model.werkspot_technical_challenge.availibility_snapshot' was properly closed.
2021-06-06 18:41:08.343547 (MainThread): 
2021-06-06 18:41:08.343785 (MainThread): Completed with 1 error and 0 warnings:
2021-06-06 18:41:08.344032 (MainThread): 
2021-06-06 18:41:08.344284 (MainThread): Database Error in model availibility_snapshot (models/Snapshot/availibility_snapshot.sql)
2021-06-06 18:41:08.344443 (MainThread):   Unrecognized name: AuditCreatedDatetime at [5:31]
2021-06-06 18:41:08.344595 (MainThread):   compiled SQL at target/run/werkspot_technical_challenge/models/Snapshot/availibility_snapshot.sql
2021-06-06 18:41:08.344767 (MainThread): 
Done. PASS=0 WARN=0 ERROR=1 SKIP=0 TOTAL=1
2021-06-06 18:41:08.345034 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fc177208390>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fc1771e9210>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fc1771d2a10>]}
2021-06-06 18:41:08.345291 (MainThread): Flushing usage events
2021-06-06 18:41:50.469113 (MainThread): Running with dbt=0.19.1
2021-06-06 18:41:51.443352 (MainThread): running dbt with arguments Namespace(cls=<class 'dbt.task.run.RunTask'>, debug=False, defer=None, exclude=None, fail_fast=False, full_refresh=False, log_cache_events=False, log_format='default', models=['availibility_snapshot'], partial_parse=None, profile=None, profiles_dir='/Users/mac/.dbt', project_dir=None, record_timing_info=None, rpc_method='run', selector_name=None, single_threaded=False, state=None, strict=False, target=None, test_new_parser=False, threads=None, use_cache=True, use_colors=None, vars='{}', version_check=True, warn_error=False, which='run', write_json=True)
2021-06-06 18:41:51.444688 (MainThread): Tracking: tracking
2021-06-06 18:41:51.454625 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f8abe80c7d0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f8abe80cf50>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f8abe80cc90>]}
2021-06-06 18:41:51.468703 (MainThread): Partial parsing not enabled
2021-06-06 18:41:51.470473 (MainThread): Parsing macros/etc.sql
2021-06-06 18:41:51.474867 (MainThread): Parsing macros/catalog.sql
2021-06-06 18:41:51.483914 (MainThread): Parsing macros/adapters.sql
2021-06-06 18:41:51.511823 (MainThread): Parsing macros/materializations/seed.sql
2021-06-06 18:41:51.515867 (MainThread): Parsing macros/materializations/view.sql
2021-06-06 18:41:51.520518 (MainThread): Parsing macros/materializations/table.sql
2021-06-06 18:41:51.534374 (MainThread): Parsing macros/materializations/copy.sql
2021-06-06 18:41:51.540473 (MainThread): Parsing macros/materializations/incremental.sql
2021-06-06 18:41:51.558626 (MainThread): Parsing macros/materializations/snapshot.sql
2021-06-06 18:41:51.562574 (MainThread): Parsing macros/core.sql
2021-06-06 18:41:51.569707 (MainThread): Parsing macros/materializations/helpers.sql
2021-06-06 18:41:51.585448 (MainThread): Parsing macros/materializations/snapshot/snapshot_merge.sql
2021-06-06 18:41:51.588544 (MainThread): Parsing macros/materializations/snapshot/strategies.sql
2021-06-06 18:41:51.613879 (MainThread): Parsing macros/materializations/snapshot/snapshot.sql
2021-06-06 18:41:51.661305 (MainThread): Parsing macros/materializations/seed/seed.sql
2021-06-06 18:41:51.693256 (MainThread): Parsing macros/materializations/incremental/helpers.sql
2021-06-06 18:41:51.696232 (MainThread): Parsing macros/materializations/incremental/incremental.sql
2021-06-06 18:41:51.705028 (MainThread): Parsing macros/materializations/common/merge.sql
2021-06-06 18:41:51.725417 (MainThread): Parsing macros/materializations/table/table.sql
2021-06-06 18:41:51.735756 (MainThread): Parsing macros/materializations/view/view.sql
2021-06-06 18:41:51.747735 (MainThread): Parsing macros/materializations/view/create_or_replace_view.sql
2021-06-06 18:41:51.755447 (MainThread): Parsing macros/etc/get_custom_alias.sql
2021-06-06 18:41:51.756914 (MainThread): Parsing macros/etc/query.sql
2021-06-06 18:41:51.758568 (MainThread): Parsing macros/etc/is_incremental.sql
2021-06-06 18:41:51.761070 (MainThread): Parsing macros/etc/datetime.sql
2021-06-06 18:41:51.773518 (MainThread): Parsing macros/etc/get_custom_schema.sql
2021-06-06 18:41:51.776544 (MainThread): Parsing macros/etc/get_custom_database.sql
2021-06-06 18:41:51.778894 (MainThread): Parsing macros/adapters/common.sql
2021-06-06 18:41:51.837874 (MainThread): Parsing macros/schema_tests/relationships.sql
2021-06-06 18:41:51.842419 (MainThread): Parsing macros/schema_tests/not_null.sql
2021-06-06 18:41:51.845125 (MainThread): Parsing macros/schema_tests/unique.sql
2021-06-06 18:41:51.848065 (MainThread): Parsing macros/schema_tests/accepted_values.sql
2021-06-06 18:41:51.860029 (MainThread): Partial parsing not enabled
2021-06-06 18:41:51.894377 (MainThread): Acquiring new bigquery connection "model.werkspot_technical_challenge.availibility_snapshot".
2021-06-06 18:41:51.907977 (MainThread): Acquiring new bigquery connection "model.werkspot_technical_challenge.dim_service".
2021-06-06 18:41:51.920424 (MainThread): Acquiring new bigquery connection "model.werkspot_technical_challenge.dim_professional".
2021-06-06 18:41:51.928096 (MainThread): Acquiring new bigquery connection "model.werkspot_technical_challenge.fct_fee".
2021-06-06 18:41:51.935968 (MainThread): Acquiring new bigquery connection "model.werkspot_technical_challenge.event_logs_stg".
2021-06-06 18:41:52.004067 (MainThread): Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '6a1f544f-a935-4f58-859c-5a711902441c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f8abe85af10>]}
2021-06-06 18:41:52.020757 (MainThread): Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '6a1f544f-a935-4f58-859c-5a711902441c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f8abec29d10>]}
2021-06-06 18:41:52.021268 (MainThread): Found 5 models, 0 tests, 0 snapshots, 0 analyses, 156 macros, 0 operations, 0 seed files, 0 sources, 0 exposures
2021-06-06 18:41:52.022714 (MainThread): 
2021-06-06 18:41:52.023211 (MainThread): Acquiring new bigquery connection "master".
2021-06-06 18:41:52.024185 (ThreadPoolExecutor-0_0): Acquiring new bigquery connection "list_poetic-genius-315513".
2021-06-06 18:41:52.024479 (ThreadPoolExecutor-0_0): Opening a new connection, currently in state init
2021-06-06 18:41:54.575164 (ThreadPoolExecutor-1_0): Acquiring new bigquery connection "list_poetic-genius-315513_events_information".
2021-06-06 18:41:54.575506 (ThreadPoolExecutor-1_0): Opening a new connection, currently in state closed
2021-06-06 18:41:54.575798 (ThreadPoolExecutor-1_0): Client.dataset is deprecated and will be removed in a future version. Use a string like 'my_project.my_dataset' or a cloud.google.bigquery.DatasetReference object, instead.
2021-06-06 18:41:55.744245 (MainThread): 23:41:55 | Concurrency: 1 threads (target='dev')
2021-06-06 18:41:55.744504 (MainThread): 23:41:55 | 
2021-06-06 18:41:55.746919 (Thread-1): Began running node model.werkspot_technical_challenge.availibility_snapshot
2021-06-06 18:41:55.747314 (Thread-1): 23:41:55 | 1 of 1 START incremental model events_information.availibility_snapshot [RUN]
2021-06-06 18:41:55.747774 (Thread-1): Acquiring new bigquery connection "model.werkspot_technical_challenge.availibility_snapshot".
2021-06-06 18:41:55.748279 (Thread-1): unclosed <socket.socket fd=13, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('192.168.0.104', 54220), raddr=('142.250.185.42', 443)>
2021-06-06 18:41:55.748489 (Thread-1): Compiling model.werkspot_technical_challenge.availibility_snapshot
2021-06-06 18:41:55.752664 (Thread-1): Writing injected SQL for node "model.werkspot_technical_challenge.availibility_snapshot"
2021-06-06 18:41:55.753218 (Thread-1): finished collecting timing info
2021-06-06 18:41:55.817938 (Thread-1): Writing runtime SQL for node "model.werkspot_technical_challenge.availibility_snapshot"
2021-06-06 18:41:55.818533 (Thread-1): Opening a new connection, currently in state closed
2021-06-06 18:41:55.818714 (Thread-1): On model.werkspot_technical_challenge.availibility_snapshot: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "werkspot_technical_challenge", "target_name": "dev", "node_id": "model.werkspot_technical_challenge.availibility_snapshot"} */


  create or replace table `poetic-genius-315513`.`events_information`.`availibility_snapshot`
  
  
  OPTIONS()
  as (
    


SELECT

  CreatedAt,
  COUNT(DISTINCT CASE WHEN ProfessionalStatus IS TRUE THEN ProfessionalID END) AS ActiveProfessionals,

FROM 
(
  SELECT
    *,
    CASE
      
      WHEN 
        EventType IN ('created_account','became_unable_to_propose') AND NextEvent IS NULL 
        THEN False 
      
      WHEN EventType IN ('created_account','became_able_to_propose') AND NextEvent='became_unable_to_propose' 
        THEN False 
      
      WHEN EventType IN ('proposed','became_unable_to_propose') AND (NextEvent='became_unable_to_propose') 
        THEN False
      
      WHEN EventType IN ('proposed','became_able_to_propose','became_unable_to_propose') AND 
           NextEvent IN ('proposed','became_able_to_propose') 
        THEN True
      
      WHEN EventType IN ('proposed','became_able_to_propose','became_unable_to_propose') AND 
           NextEvent IN ('proposed','became_able_to_propose') 
        THEN True
      
      WHEN EventType IN ('created_account','became_able_to_propose','proposed') AND 
           (NextEvent IS NULL OR NextEvent='became_able_to_propose') 
        THEN True
    
    END AS ProfessionalStatus,
  
  FROM 
  (
    SELECT

     DISTINCT
      EXTRACT(DATE FROM CAST(CreatedAt AS DATETIME)) AS CreatedAt,
      ProfessionalID,
      EventType,
      LEAD(EventType,1 ) OVER 
          (PARTITION By EXTRACT(DATE FROM CAST(CreatedAt AS DATETIME)),ProfessionalID 
            ORDER BY CreatedAt ASC) as NextEvent
    FROM
    (
      SELECT 

        DISTINCT
          CreatedAt,
          ProfessionalID,
          EventType

      FROM 
        `poetic-genius-315513`.`events_information`.`event_logs_stg`
        
      GROUP BY 1,2,3 
      HAVING CreatedAt BETWEEN MIN(CreatedAt) AND '2020-03-10 23:59:59'
    )
  )
) 
GROUP BY 1 ORDER BY 1 ASC
  );
  
2021-06-06 18:41:59.874678 (Thread-1): finished collecting timing info
2021-06-06 18:41:59.875223 (Thread-1): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '6a1f544f-a935-4f58-859c-5a711902441c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f8abebecf10>]}
2021-06-06 18:41:59.875706 (Thread-1): 23:41:59 | 1 of 1 OK created incremental model events_information.availibility_snapshot [CREATE TABLE (70.0 rows, 696.8 KB processed) in 4.13s]
2021-06-06 18:41:59.875893 (Thread-1): Finished running node model.werkspot_technical_challenge.availibility_snapshot
2021-06-06 18:41:59.970367 (MainThread): Acquiring new bigquery connection "master".
2021-06-06 18:41:59.971013 (MainThread): 23:41:59 | 
2021-06-06 18:41:59.971288 (MainThread): 23:41:59 | Finished running 1 incremental model in 7.95s.
2021-06-06 18:41:59.971656 (MainThread): Connection 'master' was properly closed.
2021-06-06 18:41:59.971950 (MainThread): Connection 'model.werkspot_technical_challenge.availibility_snapshot' was properly closed.
2021-06-06 18:41:59.982622 (MainThread): 
2021-06-06 18:41:59.982885 (MainThread): Completed successfully
2021-06-06 18:41:59.983114 (MainThread): 
Done. PASS=1 WARN=0 ERROR=0 SKIP=0 TOTAL=1
2021-06-06 18:41:59.983444 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f8abe48c110>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f8abeba6e90>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f8abeb102d0>]}
2021-06-06 18:41:59.983729 (MainThread): Flushing usage events
2021-06-07 07:23:09.720616 (MainThread): Running with dbt=0.19.1
2021-06-07 07:23:11.012110 (MainThread): running dbt with arguments Namespace(cls=<class 'dbt.task.run.RunTask'>, debug=False, defer=None, exclude=None, fail_fast=False, full_refresh=False, log_cache_events=False, log_format='default', models=['availibility_snapshot'], partial_parse=None, profile=None, profiles_dir='/Users/mac/.dbt', project_dir=None, record_timing_info=None, rpc_method='run', selector_name=None, single_threaded=False, state=None, strict=False, target=None, test_new_parser=False, threads=None, use_cache=True, use_colors=None, vars='{}', version_check=True, warn_error=False, which='run', write_json=True)
2021-06-07 07:23:11.014831 (MainThread): Tracking: tracking
2021-06-07 07:23:11.037332 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fce89a970d0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fce89fbe810>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fce89fed110>]}
2021-06-07 07:23:11.057537 (MainThread): Partial parsing not enabled
2021-06-07 07:23:11.059589 (MainThread): Parsing macros/etc.sql
2021-06-07 07:23:11.067149 (MainThread): Parsing macros/catalog.sql
2021-06-07 07:23:11.078524 (MainThread): Parsing macros/adapters.sql
2021-06-07 07:23:11.123538 (MainThread): Parsing macros/materializations/seed.sql
2021-06-07 07:23:11.129967 (MainThread): Parsing macros/materializations/view.sql
2021-06-07 07:23:11.138622 (MainThread): Parsing macros/materializations/table.sql
2021-06-07 07:23:11.155739 (MainThread): Parsing macros/materializations/copy.sql
2021-06-07 07:23:11.164389 (MainThread): Parsing macros/materializations/incremental.sql
2021-06-07 07:23:11.187506 (MainThread): Parsing macros/materializations/snapshot.sql
2021-06-07 07:23:11.194126 (MainThread): Parsing macros/core.sql
2021-06-07 07:23:11.202739 (MainThread): Parsing macros/materializations/helpers.sql
2021-06-07 07:23:11.218221 (MainThread): Parsing macros/materializations/snapshot/snapshot_merge.sql
2021-06-07 07:23:11.223007 (MainThread): Parsing macros/materializations/snapshot/strategies.sql
2021-06-07 07:23:11.255869 (MainThread): Parsing macros/materializations/snapshot/snapshot.sql
2021-06-07 07:23:11.317044 (MainThread): Parsing macros/materializations/seed/seed.sql
2021-06-07 07:23:11.355175 (MainThread): Parsing macros/materializations/incremental/helpers.sql
2021-06-07 07:23:11.358510 (MainThread): Parsing macros/materializations/incremental/incremental.sql
2021-06-07 07:23:11.370592 (MainThread): Parsing macros/materializations/common/merge.sql
2021-06-07 07:23:11.394872 (MainThread): Parsing macros/materializations/table/table.sql
2021-06-07 07:23:11.406273 (MainThread): Parsing macros/materializations/view/view.sql
2021-06-07 07:23:11.418493 (MainThread): Parsing macros/materializations/view/create_or_replace_view.sql
2021-06-07 07:23:11.426781 (MainThread): Parsing macros/etc/get_custom_alias.sql
2021-06-07 07:23:11.428483 (MainThread): Parsing macros/etc/query.sql
2021-06-07 07:23:11.430329 (MainThread): Parsing macros/etc/is_incremental.sql
2021-06-07 07:23:11.433364 (MainThread): Parsing macros/etc/datetime.sql
2021-06-07 07:23:11.446829 (MainThread): Parsing macros/etc/get_custom_schema.sql
2021-06-07 07:23:11.450012 (MainThread): Parsing macros/etc/get_custom_database.sql
2021-06-07 07:23:11.452601 (MainThread): Parsing macros/adapters/common.sql
2021-06-07 07:23:11.513228 (MainThread): Parsing macros/schema_tests/relationships.sql
2021-06-07 07:23:11.516758 (MainThread): Parsing macros/schema_tests/not_null.sql
2021-06-07 07:23:11.519478 (MainThread): Parsing macros/schema_tests/unique.sql
2021-06-07 07:23:11.522314 (MainThread): Parsing macros/schema_tests/accepted_values.sql
2021-06-07 07:23:11.533035 (MainThread): Partial parsing not enabled
2021-06-07 07:23:11.575933 (MainThread): Acquiring new bigquery connection "model.werkspot_technical_challenge.availibility_snapshot".
2021-06-07 07:23:11.590994 (MainThread): Acquiring new bigquery connection "model.werkspot_technical_challenge.dim_service".
2021-06-07 07:23:11.604784 (MainThread): Acquiring new bigquery connection "model.werkspot_technical_challenge.dim_professional".
2021-06-07 07:23:11.612310 (MainThread): Acquiring new bigquery connection "model.werkspot_technical_challenge.fct_fee".
2021-06-07 07:23:11.620388 (MainThread): Acquiring new bigquery connection "model.werkspot_technical_challenge.event_logs_stg".
2021-06-07 07:23:11.689606 (MainThread): Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '4444f956-e90a-46bc-8a8c-52de092504cf', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fce8a46a490>]}
2021-06-07 07:23:11.709302 (MainThread): Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '4444f956-e90a-46bc-8a8c-52de092504cf', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fce8a1c0bd0>]}
2021-06-07 07:23:11.709678 (MainThread): Found 5 models, 0 tests, 0 snapshots, 0 analyses, 156 macros, 0 operations, 0 seed files, 0 sources, 0 exposures
2021-06-07 07:23:11.710627 (MainThread): 
2021-06-07 07:23:11.711128 (MainThread): Acquiring new bigquery connection "master".
2021-06-07 07:23:11.712062 (ThreadPoolExecutor-0_0): Acquiring new bigquery connection "list_poetic-genius-315513".
2021-06-07 07:23:11.712330 (ThreadPoolExecutor-0_0): Opening a new connection, currently in state init
2021-06-07 07:23:16.044432 (ThreadPoolExecutor-1_0): Acquiring new bigquery connection "list_poetic-genius-315513_events_information".
2021-06-07 07:23:16.044790 (ThreadPoolExecutor-1_0): Opening a new connection, currently in state closed
2021-06-07 07:23:16.045099 (ThreadPoolExecutor-1_0): Client.dataset is deprecated and will be removed in a future version. Use a string like 'my_project.my_dataset' or a cloud.google.bigquery.DatasetReference object, instead.
2021-06-07 07:23:17.182156 (MainThread): 12:23:17 | Concurrency: 1 threads (target='dev')
2021-06-07 07:23:17.182465 (MainThread): 12:23:17 | 
2021-06-07 07:23:17.184881 (Thread-1): Began running node model.werkspot_technical_challenge.availibility_snapshot
2021-06-07 07:23:17.185311 (Thread-1): 12:23:17 | 1 of 1 START incremental model events_information.availibility_snapshot [RUN]
2021-06-07 07:23:17.185804 (Thread-1): Acquiring new bigquery connection "model.werkspot_technical_challenge.availibility_snapshot".
2021-06-07 07:23:17.186342 (Thread-1): unclosed <socket.socket fd=13, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('192.168.0.104', 61334), raddr=('142.250.185.42', 443)>
2021-06-07 07:23:17.186559 (Thread-1): Compiling model.werkspot_technical_challenge.availibility_snapshot
2021-06-07 07:23:17.190806 (Thread-1): Writing injected SQL for node "model.werkspot_technical_challenge.availibility_snapshot"
2021-06-07 07:23:17.191379 (Thread-1): finished collecting timing info
2021-06-07 07:23:17.262625 (Thread-1): Writing runtime SQL for node "model.werkspot_technical_challenge.availibility_snapshot"
2021-06-07 07:23:17.263283 (Thread-1): Opening a new connection, currently in state closed
2021-06-07 07:23:17.263489 (Thread-1): On model.werkspot_technical_challenge.availibility_snapshot: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "werkspot_technical_challenge", "target_name": "dev", "node_id": "model.werkspot_technical_challenge.availibility_snapshot"} */


  create or replace table `poetic-genius-315513`.`events_information`.`availibility_snapshot`
  
  
  OPTIONS()
  as (
    


SELECT
  CreatedAt,
  COUNT(DISTINCT CASE WHEN ProfessionalStatus IS TRUE THEN ProfessionalID END) AS ActiveProfessionals
FROM
(
  SELECT 
    DISTINCT
      EXTRACT(DATE FROM CREATEDAT) AS CreatedAt,
      Professionalid,
      FIRST_VALUE(ProfessionalStatus IGNORE NULLS) OVER 
        (PARTITION BY extract(date from cast(CreatedAt as datetime)), PROFESSIONALID ORDER BY cast(CreatedAt as datetime)
          ROWS BETWEEN UNBOUNDED PRECEDING AND UNBOUNDED FOLLOWING) AS ProfessionalStatus
  FROM 
  (
    select
      *,
      CASE   
        WHEN 
          EventType IN ('became_unable_to_propose') AND (NextEvent IS NULL) OR  NEXTEVENT='became_unable_to_propose'
          THEN False 

        WHEN 
          EventType IN ('became_able_to_propose') AND (NextEvent IS NULL OR NextEvent='proposed') OR NEXTEVENT='became_able_to_propose'
          THEN TRUE

        WHEN 
          EventType='proposed' AND NextEvent IS NULL
          THEN TRUE
      END AS ProfessionalStatus

    FROM 
    (
      SELECT
       DISTINCT
        CAST(CreatedAt AS DATETIME) AS CreatedAt,
        ProfessionalID,
        EventType,
        LEAD(EventType,1 ) OVER 
            (PARTITION By EXTRACT(DATE FROM CAST(CreatedAt AS DATETIME)),ProfessionalID 
              ORDER BY CreatedAt ASC) as NextEvent
      FROM
      (
        SELECT 

          DISTINCT
            CreatedAt,
            ProfessionalID,
            EventType

        FROM 
          `poetic-genius-315513`.`events_information`.`event_logs_stg`
        GROUP BY 1,2,3 
        HAVING CreatedAt BETWEEN MIN(CreatedAt) AND '2020-03-10 23:59:59'
      )
    )
  )
  ORDER BY 1,2
)
GROUP BY 1
ORDER BY 1 ASC
  );
  
2021-06-07 07:23:22.622288 (Thread-1): finished collecting timing info
2021-06-07 07:23:22.622913 (Thread-1): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '4444f956-e90a-46bc-8a8c-52de092504cf', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fce8a182b10>]}
2021-06-07 07:23:22.623415 (Thread-1): 12:23:22 | 1 of 1 OK created incremental model events_information.availibility_snapshot [CREATE TABLE (70.0 rows, 696.8 KB processed) in 5.44s]
2021-06-07 07:23:22.623605 (Thread-1): Finished running node model.werkspot_technical_challenge.availibility_snapshot
2021-06-07 07:23:22.661184 (MainThread): Acquiring new bigquery connection "master".
2021-06-07 07:23:22.661736 (MainThread): 12:23:22 | 
2021-06-07 07:23:22.662047 (MainThread): 12:23:22 | Finished running 1 incremental model in 10.95s.
2021-06-07 07:23:22.662293 (MainThread): Connection 'master' was properly closed.
2021-06-07 07:23:22.662420 (MainThread): Connection 'model.werkspot_technical_challenge.availibility_snapshot' was properly closed.
2021-06-07 07:23:22.674456 (MainThread): 
2021-06-07 07:23:22.674717 (MainThread): Completed successfully
2021-06-07 07:23:22.674983 (MainThread): 
Done. PASS=1 WARN=0 ERROR=0 SKIP=0 TOTAL=1
2021-06-07 07:23:22.675328 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fce8a41e3d0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fce8a431fd0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fce8a278f50>]}
2021-06-07 07:23:22.675589 (MainThread): Flushing usage events
